{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_7_IDL_NMT_Meghana.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "JEIAwPgokXk6",
        "S6LD6RwikuOw",
        "6UKOUGEX0Z75",
        "J1JQ2_On36HO",
        "0LiDrt7y3-lW",
        "VQujLhNg4BrF",
        "3HCh9PfH4oZK",
        "7reyM4fc4rmJ",
        "ijN0V-aI46-x",
        "XE7o0uJU4rh2",
        "XQI6bl3P65rr",
        "15SEZQ5062pY",
        "_JM4SVkfDE1C"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mannam95/Deep_Learning_Programming/blob/main/Assignment7/Assignment_7_IDL_NMT_Meghana.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6aef94d"
      },
      "source": [
        "# Team Assignment\n",
        "\n",
        "\n",
        "1.   Srinath Mannam (229750)\n",
        "2.   Meghana Rao (234907)\n",
        "3.   Govind Shukla (235192)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b1ec548"
      },
      "source": [
        "# Import statements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQCgf3jKQ8L3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db159d18-fffc-44b5-fbdb-a77911fa2d3c"
      },
      "source": [
        "pip install tensorflow_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_text in /usr/local/lib/python3.7/dist-packages (2.7.3)\n",
            "Requirement already satisfied: tensorflow<2.8,>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.19.5)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.13.3)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.1.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.37.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (12.0.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.22.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.42.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.10.0.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.17.3)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.8.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85eb7211"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.preprocessing.sequence as sequence\n",
        "import tensorflow_text as tf_text\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c34550c"
      },
      "source": [
        "# Change the directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M76lfytpuWuf",
        "outputId": "83319aca-9f76-4837-c9a0-f97f416f6906"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94b2626e"
      },
      "source": [
        "working_directory = '/content/drive/MyDrive/kan-eng'\n",
        "def colabDrive():\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "\n",
        "    if os.getcwd() !=  working_directory:\n",
        "      os.chdir(working_directory)\n",
        "    print(os.getcwd())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8540ed4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a98df93d-3dac-4bad-b5e7-146117f7577a"
      },
      "source": [
        "colabDrive()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/kan-eng\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjeunnuphktY"
      },
      "source": [
        "# Preamble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHbpSCdw8qnW"
      },
      "source": [
        "## Helper function which can be used to check the shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M15xw1ve8teI"
      },
      "source": [
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    if isinstance(names, str):\n",
        "      names = (names,)\n",
        "\n",
        "    shape = tf.shape(tensor)\n",
        "    rank = tf.rank(tensor)\n",
        "\n",
        "    if rank != len(names):\n",
        "      raise ValueError(f'Rank mismatch:\\n'\n",
        "                       f'    found {rank}: {shape.numpy()}\\n'\n",
        "                       f'    expected {len(names)}: {names}\\n')\n",
        "\n",
        "    for i, name in enumerate(names):\n",
        "      if isinstance(name, int):\n",
        "        old_dim = name\n",
        "      else:\n",
        "        old_dim = self.shapes.get(name, None)\n",
        "      new_dim = shape[i]\n",
        "\n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh0bPt7wkCHt"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvTtHPvjhqBC"
      },
      "source": [
        "def load_data(path):\n",
        "  #text = path.read_text(encoding='utf-8')\n",
        "  with open(path, \"r\", encoding='utf-8') as kan:\n",
        "    kannada_text=kan.read()\n",
        "\n",
        "  lines = kannada_text.splitlines()\n",
        "  pairs = [line.split('\\t')[:-1]  for line in lines]\n",
        "\n",
        "  inp = [inp for targ, inp in pairs]\n",
        "  targ = [targ for targ, inp in pairs]\n",
        "\n",
        "  return targ, inp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cOKg7mXhtw5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4e8dfcc-d01d-4c18-b25b-26651f1013c6"
      },
      "source": [
        "targ, inp = load_data(\"/content/drive/MyDrive/kan-eng/kan.txt\")\n",
        "print(inp)\n",
        "print(targ)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ಆರಾಮಾ?', 'ಹೇಗಿದ್ದೀರ', 'ಟಾಮ್ ಏಳಿದನು.', 'ಅರ್ಧ ನನಗೆ ಕೊಡು.', 'ನಮಗೆ ಬೇಕಾಗಿತ್ತು.', 'ನಾನು ತುಂಬಾ ಬಿಝಿ', 'ಟಾಮ್ ನಿನ್ನನ್ನು ಬಯಸಿದನು.', 'ಒಳಗೆ ಹೋಗು ಅಷ್ಟೇ.', 'ನಿಮಗೆ ನೆನಪು ಇದ್ಯಾ?', 'ನಾನು ಈಗ ತಾನೇ ವಾಪಸ್ಸು ಬಂದೆ.', 'ಎರಡು ವರೆಗೆ (೨.೩೦ ಗೆ) ನಿನ್ನನ್ನು ನೋಡುತ್ತೇನೆ.', 'ನಾವು ಒಳಗಡೆ ಹೋಗಬಹುದಾ?', 'ನಾನು ನಿನ್ನ ಮೇಲೆ ನಂಬಿಕೆ ಇಟ್ಟಿದ್ದೇನೆ.', 'ಮೇರಿ ಸೌಂದರ್ಯವಾಗಿದ್ದಾಳೆ.', 'ನಿಮ್ಮ ಮನೇಲಿ ಹೆಂಗಿದ್ದಾರೆ', 'ಪುಸ್ತಕ ಎಲ್ಲಿದೆ?', 'ಟಾಮ್ ನನ್ನ ಜೊತೆ ಉಳಿದುಕೊಂಡನು.', 'ಟೊಮನ್ನು ಅದನ್ನು ಮಾಡಕ್ಕೆ ಬಿಡಬೇಡಿ.', 'ಅವರು ಏನಕ್ಕೂ ಉಪಯೋಗವಿಲ್ಲ.', 'ನಾವು ಅದರ ಕುರಿತು ಕೆಲಸ ಮಾಡುತ್ತಾ ಇದ್ದೇವೆ.', 'ನಾನು ಒಂಟಿಯಾಗಿ ಪಯಣ ಮಾಡಿದೆ.', 'ಟಾಮ್ ತುಂಬಾನೇ ಅಸಡ್ಡೆ.', 'ಇಲ್ಲಿ ಏನು ನಡಿತಾಯಿದೆ?', 'ನೀವು ಟಾಮಿಗೆ ಹೇಳಲೇಬೇಕು.', 'ನೀನು ನನ್ನನು ನಿರಾಶೆ ಮಾಡುತ್ತೀಯ.', 'ಟಾಮ್ ನಿನ್ನನ್ನು ಯಾವಾಗಲಾದರೂ ನೋಯಿಸಿದ್ದಾನಾ?', 'ನಾನು ಟೊಮನ್ನು ಬಿಗಿಯಾಗಿ ತಬ್ಬಿಕೊಂಡೆ.', 'ಅದಷ್ಟೇ ಟಾಮಿಗೆ ಬೇಕಾಗಿದ್ದು.', 'ನಾನು ಮನೆಗೆ ಹೊರಡುತ್ತಾ ಇರಬೇಕು.', 'ಚನ್ನಾಗಿ ನಡೆಯಿತು ಅಂತ ಅನಿಸುತ್ತೆ.', 'ನಮ್ಮ ಅತಿಥಿಗಳನ್ನು ಸ್ವಾಗತಿಸೋಣ.', 'ಮೂರ್ಖತನಕ್ಕೆ ಯಾವ ಕ್ಷಮೆಯು ಇಲ್ಲ.', 'ನೀವು ಎಚ್ಚರವಾಗಿರಬೇಕು.', 'ಬಹಳ ತರಕಾರಿಗಳು ತಿನ್ನು.', 'ನಾನು ಸ್ವಲ್ಪ ದುಡ್ಡನ್ನು ತೆಗೆದುಕೊಂಡು ಬರಬೇಕಾಗಿತ್ತು.', 'ನಿಮ್ಮನ್ನು ಸಹಾಯ ಮಾಡುವುದಕ್ಕೆ ಆಶಿಸುತ್ತೇನೆ.', 'ನೀವು ಯಾಕೆ ನನಗೆ ಧನ್ಯವಾದ ಹೇಳುತ್ತೀರಾ?', 'ಅವನು ನದಿ ಅಡ್ಡಲಾಗಿ ಈಜಿದನು.', 'ನೆನ್ನೆ ರಾತ್ರಿ ಹೇಗೆ ನಡೆಯಿತು?', 'ನಾನು ಪ್ಯಾರಿಸಿಗೆ ಎಂದಿಗೂ ಹೋಗಿಲ್ಲ.', 'ಟಾಮ್ ಬಹುಮಟ್ಟಿಗೆ ಮರೆತುಬಿಟ್ಟಿದ್ದನು.', 'ಟಾಮ್ ಒಬ್ಬ ಒಳ್ಳೆಯ ಪ್ರತಿಸ್ಪರ್ಧಿ.', 'ಟಾಮ್ ಈಗ ನಿಮಗೆ ತಯಾರಾಗಿದ್ದಾನೆ.', 'ಟಾಮ್ ಮೂರು ಗಂಟೆಯ ಮುಂಚೇನೇ ಹೋದ.', 'ಟಾಮ್ ಮೇರಿಗೆ ಮನೆಗೆ ಹೋಗುವುದಕ್ಕೆ ಹೇಳಿದನು.', 'ನೀನು ಅವನನ್ನು ಪ್ರೀತಿಸುತ್ತಿದ್ದೀಯ.', 'ಅವನು ನನ್ನ ಅಭಿಪ್ರಾಯವನ್ನು ಸಮ್ಮತಿಸುತ್ತಾನೆ.', 'ಪ್ರತಿವರ್ಷ ಅವನು ವಿದೇಶಕ್ಕೆ ಹೋಗುತ್ತಾನೆ.', 'ಆ ಗಾಯ ಹೇಗೆ ಸಿಕ್ಕಿತು?', 'ನಾನು ಎಂದಿಗೂ ಅದನ್ನೇ ನಂಬಿದ್ದೇನೆ.', 'ನೆನ್ನೆ ರಾತ್ರಿ ನಾನು ಒಂದು ಪುಸ್ತಕವನ್ನು ಓದಿದೆ.', 'ನಮ್ಮಲ್ಲಿ ಒಬ್ಬರು ಹೋಗಲೇ ಬೇಕಾಗುತ್ತದೆ.', 'ಯುದ್ಧ ಇನ್ನೂ ನಡೆಯುತ್ತಿದೆ.', 'ಇವತ್ತು ವೆದರ್ ಚೆನ್ನಾಗಿದೆ', 'ಟಾಮ್ ಹೆಚ್ಚು ಮಾಂಸ ತಿನ್ನುವುದಿಲ್ಲ.', 'ನಾವು ಬಿರುಗಾಳಿಯಿಂದ ಸಿಕ್ಕಿಹಾಕಿಕೊಳ್ಳಿದ್ದೆವಿ.', 'ನೀವು ಯಾವ ತಂಡಕ್ಕೆ ಆಟ ಆಡುತ್ತೀರಾ?', 'ನೀವು ಇಲ್ಲಿ ಈಗ ಇರಬಾರದು.', 'ಕೆಲಸದಲ್ಲಿ ಅವನಿಗೆ ಅಪಘಾತವಾಯಿತು.', 'ನಾನು ದಡಕ್ಕೆ ಹೋಗಲು ಇಷ್ಟಪಡುತ್ತಿದೆ.', 'ನಮಗೆ ಅದೃಷ್ಟ ಸಿಕ್ಕಿತು ಅಂತ ಅನಿಸುತ್ತೆ.', 'ಅದಕ್ಕೇನೇ ಅವನು ಅವನ ಕೆಲಸ ಕಳೆದುಕೊಂಡ.', 'ಇದು ಭಯಾನಕವಾದ ದುರಂತ.', 'ಬೇರೆ ರೀತಿಯಲ್ಲಿ ಯೋಚನೆ ಮಾಡೋಣ.', 'ನಿಮಗೆ ಏನು ಅನ್ನಿಸುತ್ತೆ', 'ನಿಜವಾಗಿಯೂ ನಾನು ನಿಮಗೆ ಕ್ಷಮೆ ಕೋರಬೇಕು.', 'ನಾವು ಪ್ರಯತ್ನಿಸದೇ ಬೇಡ ಅಂತ ಸೂಚಿಸುತ್ತೇನೆ.', 'ನಿಮ್ಮ ಪುಸ್ತಕವನ್ನು ಒಂಬತ್ತನೆಯ ಪುಟಕ್ಕೆ ತೆರೆಯಿರಿ.', 'ಅವಳು ಎರಡು ಮಕ್ಕಳನ್ನು ಸಾಕಿದಳು.', 'ಟಾಮಿಗೆ ಯಾರು ಕೊಲೆಗಾರ ಅಂತ ಗೊತ್ತಿತ್ತು.', 'ನಾವು ಸತ್ಯವನ್ನು ಎಲ್ಲಿ ಕಂಡುಹಿಡಿಯಬಹುದು?', 'ನೀವು ಯಾವಾಗಲಾದರೂ ಕಚ್ಚಾ ಮೀನು ತಿಂದಿದ್ದೀರಾ?', 'ಪ್ರತಿದಿನ ನಾನು ಸುಧಾರಿಸುತ್ತಿದ್ದೇನೆ.', 'ಈ ಸಲ ನಾವು ಸರಿಯಾಗಿ ಮಾಡೋಣ.', 'ಅವಳು ಹದಿವಯಸ್ಸಿನಲ್ಲಿ ಮದುವೆಯಾಗಿದಳು.', 'ಅದು ಪರಿಹಾರ ಇಲ್ಲವೇ ಇಲ್ಲ.', 'ಟಾಮ್ ಮೇರಿ ಮೇಲೆ ಪ್ರೀತಿ ಇದ್ಯಾ?', 'ನಾನು ನಿಮಗೆ ಒಳ್ಳೆಯ ವಕೀಲರನ್ನು ಸೊಚಿಸಬಹುದು.', 'ಒಪ್ಪ೦ದವನ್ನು ನೋಡುವುದಕ್ಕೆ ನಾನು ಇಷ್ಟಪಡುತ್ತೇನೆ.', 'ಅವಳು ಅವಳ ಕೈಯಲ್ಲಿ ಏನೋ ಇಟ್ಟುಕೊಂಡಿದ್ದಾಳೆ.', 'ಬಾದಲಿಯಲ್ಲಿ ಏನೂ ಇಲ್ಲ.', 'ಈ ಕೊಠಡಿ ಹಂದಿಮನೆ ತರಹ ಇದೆ.', 'ನಾವು ಹುಡುಕಾಟವನ್ನು ರದ್ಧುಗೊಳಿಸಬೇಕು.', 'ಕುಡಿಯೋಕ್ಕೆ ಏನಾದ್ರು ಬೇಕಾ ?', 'ನಿಮ್ಮ ಕುಟುಂಬಕ್ಕೆ ನನ್ನ ಪರವಾಗಿ ಶುಭಾಕಾಂಕ್ಷೆಗಳನ್ನು ನೀಡಿ.', 'ನನಗೆ ಏನಾಯಿತು ಅಂತ ನನಗೇನೆ ಗೊತ್ತಿಲ್ಲ.', 'ಅದಕ್ಕೆ ಅರ್ಥ ಇದೆ ಎಂದು ನಿಮಗೆ ಅನಿಸುತ್ತಾ?', 'ನೀವೆಲ್ಲ ಬಂದಿದ್ದು ನನಗೆ ತುಂಬಾ ಸಂತೋಷ.', 'ಕ್ಷಮಿಸಿ ನಿಮ್ಮ ಕಛೇರಿಗೆ ಬರುವದಕ್ಕೆ ಆಗಲಿಲ್ಲ.', 'ಕೆಲವೊಂದು ಪ್ರಾಣಿಗಳು ಬೆಂಕಿಗೆ ಹೆದರುತ್ತವೆ.', 'ಟಾಮ್ ಬಗ್ಗೆ ಏನೆಲ್ಲಾ ಗೊತ್ತೋ ನಮಗೆ ಹೇಳಿ.', 'ಟಾಮ್ ಕಿಟಕಿಯ ಹೊರಗೆ ದುಃಖದಿಂದ ನೋಡುತ್ತಲಿರುತ್ತಿದ್ದನು.', 'ಇನ್ನೊಂದು ಪರಿಹಾರವನ್ನು ಸುಚಿಸುತ್ತೀರಾ?', 'ಬೆಂಕಿಯನ್ನು ನಂದಿಸುವುದಕ್ಕೆ ಮರೆಯಬೇಡಿ.', 'ಬೆಂಕಿಯನ್ನು ನಂದಿಸುವುದಕ್ಕೆ ಮರೆಯಬೇಡಿ.', 'ನನಗೆ ಕಾರನ್ನು ಖರೀದಿಸುವುದಕ್ಕೆ ಸಾಕಷ್ಟು ಹಣವಿದೆ.', 'ಅದೇ ಪ್ರಶ್ನೆ ನನ್ನನ್ನೇ ಕೇಳಿದೆ.', 'ನಿಮಗೆ ಅದನ್ನು ಹಂಗೇ ಬಿಡಬೇಕಾ?', 'ಅವನು ಠಾಣೆಗೆ ಐದು ಗಂಟೆಗೆ ತಲುಪಿದ.', 'ಆಹಾರಕ್ಕೆ ತುಂಬಾ ಎಣ್ಣೆ ಇತ್ತು ಅಂತ ಅನಿಸಿತು.', 'ನಿನ್ನನ್ನು ಕೆಲಸದಿಂದ ತೆಗೆದಿರುವುದಕ್ಕೆ ನಾನೇ ಕರಣ ಮತ್ತು ನಂದೇ ತಪ್ಪು.', 'ಇದನ್ನು ಎಲ್ಲಿ ಸಿಕ್ಕಿತ್ತೋ ಅಲ್ಲೇ ಇಡು.', 'ನನ್ನನ್ನು ಎಳೆಮಗು ತರಹ ಪರಿಗಣಿಸುತ್ತಾಳೆ.', 'ಅಪಘಾತದ ಕಾರಣದಿಂದ ಸಂಚಾರ ಸ್ತಂಭನ ಇತ್ತು.', 'ಇದು ಟಾಮಿನ ಕನ್ನಡಕ, ನನ್ನದಿಲ್ಲ.', 'ಪ್ರಾಮಾಣಿಕವಾಗಿ ಹೇಳಬೇಕೆಂದರೆ, ನಾನು ಗೊತ್ತಿಲ್ಲ', 'ಟಾಮ್ ಬೇರೆಯಾರನ್ನೂ ಕೊಲ್ಲಲ್ಲ.', 'ನಿಮಗೆ ತೊಂದರೆ ಇಲ್ಲವೆಂದರೆ ನಿಮ್ಮ ಕಾರನ್ನು ಜರಗಿಸುತ್ತೀರಾ?', 'ನೀವು ಪತ್ರಿಕೆಯನ್ನು ಓದಿ ಮುಗಿಸಿದ್ದೀರಾ?', 'ಅವನು ಅವನ ಮಗಳಿಗೆ ಹೊಸ ಬಟ್ಟೆಯನ್ನು ಖರೀದಿಸಿದನು.', 'ಅದೇ ನಾವು ಮಾಡ್ಬೇಕು ಅಲ್ಲವ?', 'ಅವರು ಅವರ ನಿಶ್ಚಿತಾರ್ಥದವನ್ನು ಪ್ರಕಟಿಸಿದ್ದಾರೆ.', 'ನಿಮಗೆ ಒಂದೇ ಬಾರಿ ಎರಡು ಜಾಗದಲ್ಲಿ ಇರುವುದಕ್ಕೆ ಆಗಲ್ಲ.', 'ನಾವು ಮುಂಚೆ ಎಂದಿಗೂ ಭೇಟಿಯಾಗಿಲ್ಲವೆಂದು ಖಚಿತವಾಗಿ ಹೇಳುತ್ತೀರಾ?', 'ಟಮಿನ ಉಪನಾಮ ಏನು ಅಂತ ನಿಮಗೆ ಗೊತ್ತ?', 'ನನಗೆ ಟಾಮ್ ಫ್ರೆಂಚ್ ಮಾತಾಡುತ್ತಾನೆ ಅಂತ ಗೊತ್ತೇ ಇರಲಿಲ್ಲ.', 'ನಾನು ತಪ್ಪು ಮಾಡಿದೆ ಎಂದು ಹೇಳಬೇಕು.', 'ನಾನು ನಿನನ್ನು ಇನ್ನು ಮುಂದೆ ಅದೇ ರೀತಿಯಲ್ಲಿ ಭಾವಿಸುವುದಿಲ್ಲ.', 'ಅದನ್ನು ಎಂದಿಗೂ ಮಾಡಬೇಡವೆಂದು ನಂಬೋಣ.', 'ಜೋಡಿ ಇಬ್ಬರು ಫೋಟೋಗೆ ನಿಲ್ಲಿದರು.', 'ತಪ್ಪು ಆಗುವುದಕ್ಕೆ ಹೇಗೆ ಸಾಧ್ಯ?', 'ಟಾಮ್ ಸಾಮಾನ್ಯವಾಗಿ ಯಾವಾಗ ಜಿಮ್ಮಿಗೆ ಹೋಗುತ್ತಾನೆ?', 'ಇದು ನಿಮಗೆ ಕಷ್ಟವಿದೆ ಎಂದು ನನಗೆ ತಿಳಿದು ಬರುತ್ತದೆ.', 'ಯಾರೂ ನೋಡುತ್ತಿರಲಿಲ್ಲವೆಂದು ನಾನು ಖಚಿತಪಡಿಸಿಕೊಂಡೆ.', 'ನಾವು ಎಷ್ಟು ನಿರೀಕ್ಷಿಸುತ್ತಾ ಇದ್ದವೋ ಅದಕ್ಕಿಂತ ಎರಡರಷ್ಟು ಬೆಲೆ ಆಯಿತು.', 'ಏನೆಲ್ಲಾ ಅವಳಿಗೆ ಬೇಕಿತ್ತೋ ಅದನ್ನು ಖರೀದಿಸುವುದಕ್ಕೆ ಪ್ರಯತ್ನಿಸಿದಳು.', 'ಅವಳನ್ನು ನ್ಯೂ ಜಿಲಂಡಿಗೆ ಸ್ಥಳಾಂತರಿಸುತ್ತಾರೆ.', 'ಅಪಘಾತದ ಕಾರಣವೇ ಗೊತ್ತಿಲ್ಲ.', 'ಆ ಕಥೆ ಇನ್ನಷ್ಟು ಹೆಚ್ಚು ಅದ್ಭುತವಾಯಿತು.', 'ಅವರು ಅವರ ನಿಶ್ಚಿತಾರ್ಥದವನ್ನು ಪ್ರಕಟಿಸಿದ್ದಾರೆ.', 'ನಿಮಗೆ ಹೇಗೆ ಧನ್ಯವಾದ ಹೇಳಕ್ಕೆ ಗೊತ್ತಾಗುತ್ತಾ ಇಲ್ಲ.', 'ಬಹುಷಃ ಟಾಮ್ ನಿನಗೆ ಎಲ್ಲದರ ಬಗ್ಗೆ ಹೇಳಲ್ಲ.', 'ಪ್ರವಚನ ನಡೆಯುತ್ತಿರುವಾಗ ನನಗೆ ತುಂಬಾ ಬೇಸರವಾಗಿತ್ತು.', 'ಅವರು ನಿಯಮಗಳನ್ನು ನೇರವೇರಿಸುವುದಕ್ಕೆ ಆಗಲಿಲ್ಲ.', 'ನೀನು ಇದನ್ನು ಮಾಡಕ್ಕೆ ಆಗುವುದಿಲ್ಲವೆಂದು ನಂಬಿದ್ದೀಯಾ ಅಲ್ವ?', 'ಜಾಸ್ತಿ ಹೊತ್ತು ಅವನಿಗೆ ಅವನ ಕೋಪ ತಡೆಯುವುದಕ್ಕೆ ಆಗಲಿಲ್ಲ.', 'ಟಾಮ್ ಸಹಾಯ ನೀಡುತ್ತಾನೆಂದು ನನಗೆ ಭರವಸೆ ಕೊಟ್ಟನು ಆದರೆ ಕೊಡಲಿಲ್ಲ.', 'ಅಪಾಯ ಇರುವುದಕ್ಕೆ ಬಹಳ ಸಾಧ್ಯತೆ ಇದೆ.', 'ಬ್ರಸಿಲು ಅರ್ಜೆಂಟೀನದ ಮೇಲೆ ಯುದ್ಧವನ್ನು ಪ್ರಕಟಿಸಿದರು.', 'ಅಂದಿನಿಂದ ಬಹಳಷ್ಟು ಘಟನೆಗಳು ನಡೆದಿವೆ.', 'ಎಲ್ಲಿ ಡಾಲರ್ಗಳನ್ನು ಪೌಂಡ್ಸ್ಗೆ ಬದಲಾಯಿಸಬಹುದು?', 'ಕೆಲವೊಂದು ಅಗ್ನಿಶಾಮಕರು ಗಾಯ ಪಟ್ಟರು.', 'ನಾನು ಇವತ್ತು ಬೆಳಿಗ್ಗೆ ಬೇಗ ಏಳಬೇಕಾಗಿತ್ತು.', 'ನನ್ನ ತಂದೆ ಹಾಗು ನನ್ನ ಅಣ್ಣ ಈ ಕಾರ್ಖಾನೆಯಲ್ಲಿ ಕೆಲಸ ಮಾಡುತ್ತಾರೆ.', 'ನಾನು ಏನನ್ನು ಮಾಡಬೇಕೆಂದು ಸರಿಯಾಗಿ ನೀವು ಹೇಳಬೇಕು.', 'ಏನೋ ಆಕರ್ಷಕವಾಗಿದ್ದರೆ ನಾನು ನಿನಗೆ ತಿಳಿಸುತ್ತೇನೆ.', 'ಬರುವ ವಸಂತಕಾಲದಲ್ಲಿ ನೋಡುವುದಕ್ಕೆ ಹಲವರು ಕಾರ್ಯಕ್ರಮಗಳು ಇವೆ.', 'ಅವನ ತಂದೆಯ ಮರಣಾನಂತರ ಅವನು ಸಂಸ್ಥೆಯ ಅಧಿಕಾರ ವಹಿಸಿಕೊಂಡಿದನು.', 'ಅವನ ಪಯಣ ಅವನನ್ನು ಆಫೀಸಿನಿಂದ ದೂರ ಇಡತ್ತೆ.', 'ಅವರು ಜನಸಮೊಹದ ನಡುವೆ ಅವನನ್ನು ಕಂಡಿದರು.', 'ಎಚ್ಚರವಾಗಿರಲು ನಾನು ಇನ್ನು ಸ್ವಲ್ಪ ಕಾಫಿ ಕುಡಿಯಬೇಕು ಅಂತ ಅನಿಸುತ್ತೆ.', 'ಯಾವಾಗ ನಿನಗೆ ದುಡ್ಡು ಬೇಕಾದರೆ ಮಾತ್ರ ನೀನು ನನ್ನ ಜೊತೆ ಮಾತನಾಡುತ್ತೇಯ.', 'ಸರಾಯಿ ನೆಲಮಾಳಿಗೆಗೆ ಹೋಗಿ ಎರಡು ಬಾಟಲಿ ವೈನು ತೆಗೆದುಕೊಂಡು ಬನ್ನಿ.', 'ಅವನಿಗೆ ಹುಷಾರು ಇರಲಿಲ್ಲ ಅಂತ ಅವನು ಮನಗೆ ವಾಪಸ್ಸು ಬರವುದಕ್ಕೆ ನಿರ್ದರಿಸಿದ.', 'ನಾನು ಮತ್ತು ನನ್ನ ತಂದೆ ಮೊದಲ ಬಾರಿಗೆ ಸಂಗ್ರಾಲಯಕ್ಕೆ ಹೋದ್ವಿ.', 'ಒಂದು ವೇಳೆ ಟಾಮ್ ನಿನ್ನ ಬಗ್ಗೆ ಹೇಳಲಿಲ್ಲವೆಂದರೆ ತಪ್ಪಿಸಿಕೊಳ್ಳಬಹುದಾಗಿತ್ತು.', 'ಯಾವಾಗಲಾದರು ನೀವು ನನ್ನ ಕಾರನ್ನು ಬೇಕೆಂದರೆ, ಬರಿ ಕೇಳಿ.', 'ಟಾಮ್ ನಿಮಗೆ ಗಿಟಾರ್ ಭಾರಿಸುವುದಕ್ಕೆ ಹೇಳಿಕೊಟ್ಟನೆಂದು ನನಗೆ ಮರೆತುಹೋಯಿತು.']\n",
            "[\"What's up?\", 'How are you?', 'Tom woke up.', 'Give me half.', 'We needed it.', \"I'm very busy.\", 'Tom liked you.', 'Just go inside.', 'Do you remember?', 'I just got back.', 'See you at 2:30.', 'Can we go inside?', 'I believe in you.', 'Mary is gorgeous.', \"How's your family?\", 'Where is the book?', 'Tom stayed with me.', \"Don't let Tom do it.\", \"They're useless now.\", \"We're working on it.\", 'I traveled by myself.', 'Tom is very careless.', \"What's going on here?\", 'You have to tell Tom.', 'You let me down, Tom.', 'Did Tom ever hurt you?', 'I gave Tom a huge hug.', \"That's all Tom needed.\", 'I must be getting home.', 'I think that went well.', \"Let's greet our guests.\", 'Stupidity is no excuse.', 'You need to stay awake.', 'Eat a lot of vegetables.', 'I had to get some money.', 'I only wish to help you.', 'Why are you thanking me?', 'He swam across the river.', 'How did it go last night?', \"I've never been to Paris.\", 'Tom had almost forgotten.', 'Tom is a real competitor.', 'Tom is ready for you now.', 'Tom left three hours ago.', 'Tom told Mary to go home.', 'You are in love with him.', 'He agrees with my opinion.', 'He goes abroad every year.', 'How did you get that scar?', \"I've always believed that.\", 'Last night, I read a book.', 'One of us will have to go.', 'The war is still going on.', 'The weather is nice today.', \"Tom doesn't eat much meat.\", 'We were caught in a storm.', 'What team do you play for?', \"You shouldn't be here now.\", 'He had an accident at work.', 'I loved going to the beach.', 'It looks like we got lucky.', \"That's why he lost his job.\", 'This is a horrible tragedy.', \"We'll think of another way.\", 'What do you think about it?', 'I really owe you an apology.', \"I suggest we don't even try.\", 'Open your book on page nine.', 'She brought up two children.', 'Tom knew who the killer was.', 'Where can we find the truth?', 'Have you ever eaten raw fish?', \"I'm getting better every day.\", \"Let's get it right this time.\", 'She got married in her teens.', \"That's not really a solution.\", 'Does Tom have a crush on Mary?', 'I can recommend a good lawyer.', \"I'd like to see the agreement.\", 'She has something in her hand.', \"There's nothing in the bucket.\", 'This room looks like a pigsty.', 'We should call off the search.', 'Do you need something to drink?', 'Give my regards to your family.', \"I don't know what came over me.\", 'Do you think it means something?', \"I'm glad you guys could make it.\", \"I'm sorry I missed your concert.\", 'Some animals are afraid of fire.', 'Tell us what you know about Tom.', 'Tom stared sadly out the window.', 'Can you suggest another solution?', \"Don't forget to put out the fire.\", \"Don't forget to put the fire out.\", 'I have enough money to buy a car.', 'I wondered the same thing myself.', 'Do you want to leave it like that?', 'He arrived at the station at five.', 'I thought the food was too greasy.', \"It's my fault that you were fired.\", 'Put it back where you got it from.', 'She treats me as if I were a baby.', 'The accident caused a traffic jam.', \"These are Tom's glasses, not mine.\", \"To be honest, I really don't know.\", \"Tom won't be killing anybody else.\", 'Would you mind my moving your car?', 'Are you finished reading the paper?', 'He bought his daughter a new dress.', \"Isn't that what we should be doing?\", \"They've announced their engagement.\", \"You can't be in two places at once.\", \"Are you sure we've never met before?\", \"Do you know what Tom's last name is?\", \"I didn't know that Tom spoke French.\", 'I just want to say that I was wrong.', 'I no longer feel that way about you.', \"Let's hope we never have to do that.\", 'The couple posed for the photograph.', 'What could possibly have gone wrong?', 'When does Tom usually go to the gym?', 'I can tell this is difficult for you.', 'I made sure that no one was watching.', 'It cost twice as much as we expected.', 'She tried to get whatever she wanted.', 'She will be relocated to New Zealand.', 'The cause of the accident is unknown.', 'The story got more and more exciting.', 'They have announced their engagement.', \"I don't know how I can ever thank you.\", \"Maybe Tom doesn't tell you everything.\", 'She was very bored during the lecture.', 'They failed to fulfill the conditions.', \"You don't think I can do this, do you?\", \"He couldn't keep his temper any longer.\", \"Tom promised to help me, but he didn't.\", 'It very likely is going to be dangerous.', 'Brazil declared war on Argentina in 1825.', 'A great deal has happened since that time.', 'Where can dollars be exchanged for pounds?', 'A few firefighters suffered minor injuries.', \"I should've gotten up earlier this morning.\", 'My father and my brother work in this factory.', 'You have to tell me exactly what I need to do.', \"I'll let you know if I find anything interesting.\", 'There are many new programs to watch this spring.', \"He took charge of the firm after his father's death.\", 'His trip will keep him away from the office for a week.', 'They caught sight of the man among the crowd of people.', 'In order to stay awake, I may have to drink more coffee.', 'The only time you talk to me is when you need some money.', 'Go to the wine cellar and get a couple of bottles of wine.', 'It was because he was sick that he decided to return home.', 'Both my father and I went to the museum for the first time.', \"You would've gotten away with it if Tom hadn't told on you.\", 'Any time you want to borrow my car, all you have to do is ask.', 'I forgot Tom was the one who taught you how to play the guitar.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEIAwPgokXk6"
      },
      "source": [
        "## Create dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvwzLTtIkU--"
      },
      "source": [
        "BUFFER_SIZE = len(inp)\n",
        "BATCH_SIZE = 60\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((inp, targ)).shuffle(BUFFER_SIZE)\n",
        "\n",
        "test_dataset = dataset.take(20) \n",
        "train_dataset = dataset.skip(20)\n",
        "\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(20).shuffle(10, seed=45)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrxWy_-3kbCL",
        "outputId": "fdeb157c-2ccc-46ab-97a2-9d7f6fd305d6"
      },
      "source": [
        "for example_input_batch, example_target_batch in train_dataset.take(1):\n",
        "  print(example_input_batch[:5])\n",
        "  print()\n",
        "  print(example_target_batch[:5])\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'\\xe0\\xb2\\x95\\xe0\\xb3\\x86\\xe0\\xb2\\xb2\\xe0\\xb2\\xb8\\xe0\\xb2\\xa6\\xe0\\xb2\\xb2\\xe0\\xb3\\x8d\\xe0\\xb2\\xb2\\xe0\\xb2\\xbf \\xe0\\xb2\\x85\\xe0\\xb2\\xb5\\xe0\\xb2\\xa8\\xe0\\xb2\\xbf\\xe0\\xb2\\x97\\xe0\\xb3\\x86 \\xe0\\xb2\\x85\\xe0\\xb2\\xaa\\xe0\\xb2\\x98\\xe0\\xb2\\xbe\\xe0\\xb2\\xa4\\xe0\\xb2\\xb5\\xe0\\xb2\\xbe\\xe0\\xb2\\xaf\\xe0\\xb2\\xbf\\xe0\\xb2\\xa4\\xe0\\xb3\\x81.'\n",
            " b'\\xe0\\xb2\\xa8\\xe0\\xb2\\xbe\\xe0\\xb2\\xa8\\xe0\\xb3\\x81 \\xe0\\xb2\\x87\\xe0\\xb2\\xb5\\xe0\\xb2\\xa4\\xe0\\xb3\\x8d\\xe0\\xb2\\xa4\\xe0\\xb3\\x81 \\xe0\\xb2\\xac\\xe0\\xb3\\x86\\xe0\\xb2\\xb3\\xe0\\xb2\\xbf\\xe0\\xb2\\x97\\xe0\\xb3\\x8d\\xe0\\xb2\\x97\\xe0\\xb3\\x86 \\xe0\\xb2\\xac\\xe0\\xb3\\x87\\xe0\\xb2\\x97 \\xe0\\xb2\\x8f\\xe0\\xb2\\xb3\\xe0\\xb2\\xac\\xe0\\xb3\\x87\\xe0\\xb2\\x95\\xe0\\xb2\\xbe\\xe0\\xb2\\x97\\xe0\\xb2\\xbf\\xe0\\xb2\\xa4\\xe0\\xb3\\x8d\\xe0\\xb2\\xa4\\xe0\\xb3\\x81.'\n",
            " b'\\xe0\\xb2\\x85\\xe0\\xb2\\xb5\\xe0\\xb2\\xa8\\xe0\\xb3\\x81 \\xe0\\xb2\\xa0\\xe0\\xb2\\xbe\\xe0\\xb2\\xa3\\xe0\\xb3\\x86\\xe0\\xb2\\x97\\xe0\\xb3\\x86 \\xe0\\xb2\\x90\\xe0\\xb2\\xa6\\xe0\\xb3\\x81 \\xe0\\xb2\\x97\\xe0\\xb2\\x82\\xe0\\xb2\\x9f\\xe0\\xb3\\x86\\xe0\\xb2\\x97\\xe0\\xb3\\x86 \\xe0\\xb2\\xa4\\xe0\\xb2\\xb2\\xe0\\xb3\\x81\\xe0\\xb2\\xaa\\xe0\\xb2\\xbf\\xe0\\xb2\\xa6.'\n",
            " b'\\xe0\\xb2\\xa8\\xe0\\xb2\\xa8\\xe0\\xb3\\x8d\\xe0\\xb2\\xa8\\xe0\\xb2\\xa8\\xe0\\xb3\\x8d\\xe0\\xb2\\xa8\\xe0\\xb3\\x81 \\xe0\\xb2\\x8e\\xe0\\xb2\\xb3\\xe0\\xb3\\x86\\xe0\\xb2\\xae\\xe0\\xb2\\x97\\xe0\\xb3\\x81 \\xe0\\xb2\\xa4\\xe0\\xb2\\xb0\\xe0\\xb2\\xb9 \\xe0\\xb2\\xaa\\xe0\\xb2\\xb0\\xe0\\xb2\\xbf\\xe0\\xb2\\x97\\xe0\\xb2\\xa3\\xe0\\xb2\\xbf\\xe0\\xb2\\xb8\\xe0\\xb3\\x81\\xe0\\xb2\\xa4\\xe0\\xb3\\x8d\\xe0\\xb2\\xa4\\xe0\\xb2\\xbe\\xe0\\xb2\\xb3\\xe0\\xb3\\x86.'\n",
            " b'\\xe0\\xb2\\xa8\\xe0\\xb2\\xbe\\xe0\\xb2\\xb5\\xe0\\xb3\\x81 \\xe0\\xb2\\xae\\xe0\\xb3\\x81\\xe0\\xb2\\x82\\xe0\\xb2\\x9a\\xe0\\xb3\\x86 \\xe0\\xb2\\x8e\\xe0\\xb2\\x82\\xe0\\xb2\\xa6\\xe0\\xb2\\xbf\\xe0\\xb2\\x97\\xe0\\xb3\\x82 \\xe0\\xb2\\xad\\xe0\\xb3\\x87\\xe0\\xb2\\x9f\\xe0\\xb2\\xbf\\xe0\\xb2\\xaf\\xe0\\xb2\\xbe\\xe0\\xb2\\x97\\xe0\\xb2\\xbf\\xe0\\xb2\\xb2\\xe0\\xb3\\x8d\\xe0\\xb2\\xb2\\xe0\\xb2\\xb5\\xe0\\xb3\\x86\\xe0\\xb2\\x82\\xe0\\xb2\\xa6\\xe0\\xb3\\x81 \\xe0\\xb2\\x96\\xe0\\xb2\\x9a\\xe0\\xb2\\xbf\\xe0\\xb2\\xa4\\xe0\\xb2\\xb5\\xe0\\xb2\\xbe\\xe0\\xb2\\x97\\xe0\\xb2\\xbf \\xe0\\xb2\\xb9\\xe0\\xb3\\x87\\xe0\\xb2\\xb3\\xe0\\xb3\\x81\\xe0\\xb2\\xa4\\xe0\\xb3\\x8d\\xe0\\xb2\\xa4\\xe0\\xb3\\x80\\xe0\\xb2\\xb0\\xe0\\xb2\\xbe?'], shape=(5,), dtype=string)\n",
            "\n",
            "tf.Tensor(\n",
            "[b'He had an accident at work.'\n",
            " b\"I should've gotten up earlier this morning.\"\n",
            " b'He arrived at the station at five.'\n",
            " b'She treats me as if I were a baby.'\n",
            " b\"Are you sure we've never met before?\"], shape=(5,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6LD6RwikuOw"
      },
      "source": [
        "## Unicode Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpgbPhcfkw4V"
      },
      "source": [
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accecented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, and select punctuation.\n",
        "  #text = tf.strings.regex_replace(text, '[^ a-z$ఀ-౿.?!,¿]', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UKOUGEX0Z75"
      },
      "source": [
        "## Text Vectorization\n",
        "\n",
        "Creating a word to index dictionary and an index to word dictionary for all unique source and target words in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1JQ2_On36HO"
      },
      "source": [
        "### For Kannada language"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnStPmuy0ci5",
        "outputId": "944864ef-ee5c-47af-8f9e-fe25bb51cf36"
      },
      "source": [
        "max_vocab_size = 5000\n",
        "\n",
        "input_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size)\n",
        "\n",
        "input_text_processor.adapt(inp)\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "input_text_processor.get_vocabulary()[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', '[START]', '[END]', '.', '?', 'ನಾನು', 'ಟಾಮ್', 'ನಿಮಗೆ', 'ನಾವು']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LiDrt7y3-lW"
      },
      "source": [
        "### For English language"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2n7U_B00ebs",
        "outputId": "8f671c3c-ed99-4c87-e673-a73fc4bd2a9c"
      },
      "source": [
        "output_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size)\n",
        "\n",
        "output_text_processor.adapt(targ)\n",
        "output_text_processor.get_vocabulary()[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', '[START]', '[END]', '.', 'you', 'to', 'the', 'i', '?']"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQujLhNg4BrF"
      },
      "source": [
        "### See some tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DubharMb1QAt",
        "outputId": "d053100a-e116-4345-d096-249f844ea36d"
      },
      "source": [
        "example_inp_tokens = input_text_processor('ಆರಾಮಾ?')\n",
        "example_inp_tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int64, numpy=array([  2, 447,   5,   3])>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ef80Q88-1aEa",
        "outputId": "0c6323ce-7974-47a1-ce87-ce080855739a"
      },
      "source": [
        "example_tar_tokens = output_text_processor('Whats up?')\n",
        "example_tar_tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=int64, numpy=array([ 2,  1, 48,  9,  3])>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BWNVkXh74dU"
      },
      "source": [
        "## Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z-Q4E8A78xB"
      },
      "source": [
        "embedding_dim = 256\n",
        "units = 1024"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HCh9PfH4oZK"
      },
      "source": [
        "# Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfVSM8z87_ok"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, input_vocab_size, embedding_dim, enc_units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.enc_units = enc_units\n",
        "    self.input_vocab_size = input_vocab_size\n",
        "\n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.input_vocab_size,\n",
        "                                               embedding_dim)\n",
        "\n",
        "    # The GRU RNN layer processes those vectors sequentially.\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   # Return the sequence and state\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, tokens, state=None):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(tokens, ('batch', 's'))\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding for each token.\n",
        "    vectors = self.embedding(tokens)\n",
        "    shape_checker(vectors, ('batch', 's', 'embed_dim'))\n",
        "\n",
        "    # 3. The GRU processes the embedding sequence.\n",
        "    #    output shape: (batch, s, enc_units)\n",
        "    #    state shape: (batch, enc_units)\n",
        "    output, state = self.gru(vectors, initial_state=state)\n",
        "    shape_checker(output, ('batch', 's', 'enc_units'))\n",
        "    shape_checker(state, ('batch', 'enc_units'))\n",
        "\n",
        "    # 4. Returns the new sequence and its state.\n",
        "    return output, state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaAwgen08g35",
        "outputId": "f309e246-b153-4a53-aca4-9ae28ff94bac"
      },
      "source": [
        "# Convert the input text to tokens.\n",
        "example_tokens = input_text_processor(example_input_batch)\n",
        "\n",
        "# Encode the input sequence.\n",
        "encoder = Encoder(input_text_processor.vocabulary_size(),\n",
        "                  embedding_dim, units)\n",
        "example_enc_output, example_enc_state = encoder(example_tokens)\n",
        "\n",
        "print(f'Input batch, shape (batch): {example_input_batch.shape}')\n",
        "print(f'Input batch tokens, shape (batch, s): {example_tokens.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {example_enc_output.shape}')\n",
        "print(f'Encoder state, shape (batch, units): {example_enc_state.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch, shape (batch): (60,)\n",
            "Input batch tokens, shape (batch, s): (60, 11)\n",
            "Encoder output, shape (batch, s, units): (60, 11, 1024)\n",
            "Encoder state, shape (batch, units): (60, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7reyM4fc4rmJ"
      },
      "source": [
        "# Attention Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijN0V-aI46-x"
      },
      "source": [
        "## Bahdanau Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nMlsrbr4ud7"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super().__init__()\n",
        "    # For Eqn. (4), the  Bahdanau attention\n",
        "    self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "    self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "\n",
        "    self.attention = tf.keras.layers.AdditiveAttention()\n",
        "\n",
        "  def call(self, query, value, mask):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(query, ('batch', 't', 'query_units'))\n",
        "    shape_checker(value, ('batch', 's', 'value_units'))\n",
        "    shape_checker(mask, ('batch', 's'))\n",
        "\n",
        "    # From Eqn. (4), `W1@ht`.\n",
        "    w1_query = self.W1(query)\n",
        "    shape_checker(w1_query, ('batch', 't', 'attn_units'))\n",
        "\n",
        "    # From Eqn. (4), `W2@hs`.\n",
        "    w2_key = self.W2(value)\n",
        "    shape_checker(w2_key, ('batch', 's', 'attn_units'))\n",
        "\n",
        "    query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
        "    value_mask = mask\n",
        "\n",
        "    context_vector, attention_weights = self.attention(\n",
        "        inputs = [w1_query, value, w2_key],\n",
        "        mask=[query_mask, value_mask],\n",
        "        return_attention_scores = True,\n",
        "    )\n",
        "    shape_checker(context_vector, ('batch', 't', 'value_units'))\n",
        "    shape_checker(attention_weights, ('batch', 't', 's'))\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBvCY4fWz4Zm"
      },
      "source": [
        "#Luong's Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U98GyTqgz3v3"
      },
      "source": [
        "class LuongsAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super().__init__()\n",
        "    # For Eqn. (4), the  Bahdanau attention\n",
        "    self.W = tf.keras.layers.Dense(units, use_bias=False)\n",
        "\n",
        "    self.attention = tf.keras.layers.Attention()\n",
        "\n",
        "  def call(self, query, value, mask):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(query, ('batch', 't', 'query_units'))\n",
        "    shape_checker(value, ('batch', 's', 'value_units'))\n",
        "    shape_checker(mask, ('batch', 's'))\n",
        "\n",
        "    # From Eqn. (4), `W`.\n",
        "    w_query = self.W(query)\n",
        "    shape_checker(w_query, ('batch', 't', 'attn_units'))\n",
        "\n",
        "    query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
        "    value_mask = mask\n",
        "\n",
        "    context_vector, attention_weights = self.attention(\n",
        "        inputs = [w_query, value],\n",
        "        mask=[query_mask, value_mask],\n",
        "        return_attention_scores = True,\n",
        "    )\n",
        "    shape_checker(context_vector, ('batch', 't', 'value_units'))\n",
        "    shape_checker(attention_weights, ('batch', 't', 's'))\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwXBo95d5Puv"
      },
      "source": [
        "attention_layer = BahdanauAttention(units)\n",
        "attention_layer_2 = LuongsAttention(units)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az3SlShz5caC",
        "outputId": "3f27f5e0-bdf1-485c-8618-8d64337b5146"
      },
      "source": [
        "# Later, the decoder will generate this attention query\n",
        "example_attention_query = tf.random.normal(shape=[len(example_tokens), 2, 10])\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "\n",
        "context_vector, attention_weights = attention_layer(\n",
        "    query=example_attention_query,\n",
        "    value=example_enc_output,\n",
        "    mask=(example_tokens != 0))\n",
        "\n",
        "#context_vector, attention_weights = attention_layer_2(\n",
        "    #query=example_attention_query,\n",
        "    #value=example_enc_output,\n",
        "    #mask=(example_tokens != 0))--------------Luong's Attention\n",
        "\n",
        "print(f'Attention result shape: (batch_size, query_seq_length, units):           {context_vector.shape}')\n",
        "print(f'Attention weights shape: (batch_size, query_seq_length, value_seq_length): {attention_weights.shape}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention result shape: (batch_size, query_seq_length, units):           (60, 2, 1024)\n",
            "Attention weights shape: (batch_size, query_seq_length, value_seq_length): (60, 2, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE7o0uJU4rh2"
      },
      "source": [
        "# Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2LzXKtk6JtR"
      },
      "source": [
        "class DecoderInput(typing.NamedTuple):\n",
        "  new_tokens: Any\n",
        "  enc_output: Any\n",
        "  mask: Any\n",
        "\n",
        "class DecoderOutput(typing.NamedTuple):\n",
        "  logits: Any\n",
        "  attention_weights: Any"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xq5z9qVo50Wt"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, output_vocab_size, embedding_dim, dec_units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.dec_units = dec_units\n",
        "    self.output_vocab_size = output_vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "\n",
        "    # For Step 1. The embedding layer convets token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.output_vocab_size,\n",
        "                                               embedding_dim)\n",
        "\n",
        "    # For Step 2. The RNN keeps track of what's been generated so far.\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # For step 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    # For step 4. Eqn. (3): converting `ct` to `at`\n",
        "    self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\n",
        "                                    use_bias=False)\n",
        "\n",
        "    # For step 5. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.fc = tf.keras.layers.Dense(self.output_vocab_size)\n",
        "\n",
        "  def call(self,\n",
        "         inputs: DecoderInput,\n",
        "         state=None) -> Tuple[DecoderOutput, tf.Tensor]:\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(inputs.new_tokens, ('batch', 't'))\n",
        "    shape_checker(inputs.enc_output, ('batch', 's', 'enc_units'))\n",
        "    shape_checker(inputs.mask, ('batch', 's'))\n",
        "\n",
        "    if state is not None:\n",
        "      shape_checker(state, ('batch', 'dec_units'))\n",
        "\n",
        "    # Step 1. Lookup the embeddings\n",
        "    vectors = self.embedding(inputs.new_tokens)\n",
        "    shape_checker(vectors, ('batch', 't', 'embedding_dim'))\n",
        "\n",
        "    # Step 2. Process one step with the RNN\n",
        "    rnn_output, state = self.gru(vectors, initial_state=state)\n",
        "\n",
        "    shape_checker(rnn_output, ('batch', 't', 'dec_units'))\n",
        "    shape_checker(state, ('batch', 'dec_units'))\n",
        "\n",
        "    # Step 3. Use the RNN output as the query for the attention over the\n",
        "    # encoder output.\n",
        "    context_vector, attention_weights = self.attention(\n",
        "        query=rnn_output, value=inputs.enc_output, mask=inputs.mask)\n",
        "    shape_checker(context_vector, ('batch', 't', 'dec_units'))\n",
        "    shape_checker(attention_weights, ('batch', 't', 's'))\n",
        "\n",
        "    # Step 4. Eqn. (3): Join the context_vector and rnn_output\n",
        "    #     [ct; ht] shape: (batch t, value_units + query_units)\n",
        "    context_and_rnn_output = tf.concat([context_vector, rnn_output], axis=-1)\n",
        "\n",
        "    # Step 4. Eqn. (3): `at = tanh(Wc@[ct; ht])`\n",
        "    attention_vector = self.Wc(context_and_rnn_output)\n",
        "    shape_checker(attention_vector, ('batch', 't', 'dec_units'))\n",
        "\n",
        "    # Step 5. Generate logit predictions:\n",
        "    logits = self.fc(attention_vector)\n",
        "    shape_checker(logits, ('batch', 't', 'output_vocab_size'))\n",
        "\n",
        "    return DecoderOutput(logits, attention_weights), state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwSvsa4R56GQ"
      },
      "source": [
        "decoder = Decoder(output_text_processor.vocabulary_size(),\n",
        "                  embedding_dim, units)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQpJ5Xej607m"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQI6bl3P65rr"
      },
      "source": [
        "## Loss function\n",
        "\n",
        "Summary:\n",
        "\n",
        "\n",
        "*   Sparse Categorical crossentropy is the loss function\n",
        "*   Not computing the loss where padding is applied\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOPAFtbb637r"
      },
      "source": [
        "class MaskedLoss(tf.keras.losses.Loss):\n",
        "  def __init__(self):\n",
        "    self.name = 'masked_loss'\n",
        "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "\n",
        "  def __call__(self, y_true, y_pred):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(y_true, ('batch', 't'))\n",
        "    shape_checker(y_pred, ('batch', 't', 'logits'))\n",
        "\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss = self.loss(y_true, y_pred)\n",
        "    shape_checker(loss, ('batch', 't'))\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    shape_checker(mask, ('batch', 't'))\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcnrzfLV6_BN"
      },
      "source": [
        "## Train Model\n",
        "\n",
        "Summary\n",
        "\n",
        "\n",
        "1.   A constructor which will initialise Encoder, Decoder etc\n",
        "2.   A **train_step** function which will choose which function to run whether the train step function which is wrapped with tf or the normal train step function.\n",
        "3.   A  **_preprocess** function which will preprocess the data.\n",
        "4.   A  **_train_step** function.\n",
        "5.   A  **_tf_train_step** function wrapped like a tf function.\n",
        "6.   A  **_loop_step** function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjNgJCTe7Bb_"
      },
      "source": [
        "class TrainTranslator(tf.keras.Model):\n",
        "  ## --------------------------------------------------Start of the Constructor----------------------------------------------------------\n",
        "  def __init__(self, embedding_dim, units,\n",
        "               input_text_processor,\n",
        "               output_text_processor, \n",
        "               use_tf_function=True):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(input_text_processor.vocabulary_size(),\n",
        "                      embedding_dim, units)\n",
        "    decoder = Decoder(output_text_processor.vocabulary_size(),\n",
        "                      embedding_dim, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.input_text_processor = input_text_processor\n",
        "    self.output_text_processor = output_text_processor\n",
        "    self.use_tf_function = use_tf_function\n",
        "    self.shape_checker = ShapeChecker()\n",
        "  ## --------------------------------------------------End of the Constructor----------------------------------------------------------\n",
        "\n",
        "  ## --------------------------------------------------Start of the Call----------------------------------------------------------\n",
        "  def call(self, inputs):\n",
        "    return self._test_step(inputs)\n",
        "  ## --------------------------------------------------End of the Call----------------------------------------------------------\n",
        "\n",
        "  ## --------------------------------------------------Start of the train step----------------------------------------------------------\n",
        "  #Choose which train step to run\n",
        "  def train_step(self, inputs):\n",
        "    self.shape_checker = ShapeChecker()\n",
        "    if self.use_tf_function:\n",
        "      return self._tf_train_step(inputs)\n",
        "    else:\n",
        "      return self._train_step(inputs)\n",
        "  ## --------------------------------------------------End of the train step----------------------------------------------------------\n",
        "\n",
        "  ## --------------------------------------------------Start of the Preprocess data function----------------------------------------------------------\n",
        "  def _preprocess(self, input_text, target_text):\n",
        "    self.shape_checker(input_text, ('batch',))\n",
        "    self.shape_checker(target_text, ('batch',))\n",
        "\n",
        "    # Convert the text to token IDs\n",
        "    input_tokens = self.input_text_processor(input_text)\n",
        "    target_tokens = self.output_text_processor(target_text)\n",
        "    self.shape_checker(input_tokens, ('batch', 's'))\n",
        "    self.shape_checker(target_tokens, ('batch', 't'))\n",
        "\n",
        "    # Convert IDs to masks.\n",
        "    input_mask = input_tokens != 0\n",
        "    self.shape_checker(input_mask, ('batch', 's'))\n",
        "\n",
        "    target_mask = target_tokens != 0\n",
        "    self.shape_checker(target_mask, ('batch', 't'))\n",
        "\n",
        "    return input_tokens, input_mask, target_tokens, target_mask\n",
        "  ## --------------------------------------------------End of the Preprocess data function----------------------------------------------------------\n",
        "\n",
        "  ## --------------------------------------------------Start of the train step function definition----------------------------------------------------------\n",
        "  def _train_step(self, inputs):\n",
        "    input_text, target_text = inputs  \n",
        "\n",
        "    (input_tokens, input_mask,\n",
        "    target_tokens, target_mask) = self._preprocess(input_text, target_text)\n",
        "\n",
        "    max_target_length = tf.shape(target_tokens)[1]\n",
        "    \n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      # Encode the input\n",
        "      enc_output, enc_state = self.encoder(input_tokens)\n",
        "      self.shape_checker(enc_output, ('batch', 's', 'enc_units'))\n",
        "      self.shape_checker(enc_state, ('batch', 'enc_units'))\n",
        "\n",
        "      # Initialize the decoder's state to the encoder's final state.\n",
        "      # This only works if the encoder and decoder have the same number of\n",
        "      # units.\n",
        "      dec_state = enc_state\n",
        "      loss = tf.constant(0.0)\n",
        "\n",
        "      for t in tf.range(max_target_length-1):\n",
        "        # Pass in two tokens from the target sequence:\n",
        "        # 1. The current input to the decoder.\n",
        "        # 2. The target for the decoder's next prediction.\n",
        "        new_tokens = target_tokens[:, t:t+2]\n",
        "        step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
        "                                              enc_output, dec_state)\n",
        "        loss = loss + step_loss\n",
        "\n",
        "      # Average the loss over all non padding tokens.\n",
        "      average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
        "\n",
        "\n",
        "    # Apply an optimization step\n",
        "    variables = self.trainable_variables \n",
        "    gradients = tape.gradient(average_loss, variables)\n",
        "    self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    # Return a dict mapping metric names to current value\n",
        "    return {'batch_loss': average_loss}\n",
        "  ## --------------------------------------------------End of the train step function definition----------------------------------------------------------\n",
        "\n",
        "\n",
        "  ## --------------------------------------------------Start of the test step evaluate function definition----------------------------------------------------------\n",
        "  @tf.function(input_signature=[[tf.TensorSpec(dtype=tf.string, shape=[None]),\n",
        "                               tf.TensorSpec(dtype=tf.string, shape=[None])]])\n",
        "  def _test_step(self, inputs):\n",
        "    input_text, target_text = inputs  \n",
        "    \n",
        "    (input_tokens, input_mask,\n",
        "    target_tokens, target_mask) = self._preprocess(input_text, target_text)\n",
        "\n",
        "    max_target_length = tf.shape(target_tokens)[1]\n",
        "    \n",
        "    # Encode the input\n",
        "    enc_output, enc_state = self.encoder(input_tokens)\n",
        "    self.shape_checker(enc_output, ('batch', 's', 'enc_units'))\n",
        "    self.shape_checker(enc_state, ('batch', 'enc_units'))\n",
        "\n",
        "    # Initialize the decoder's state to the encoder's final state.\n",
        "    # This only works if the encoder and decoder have the same number of\n",
        "    # units.\n",
        "    dec_state = enc_state\n",
        "    loss = tf.constant(0.0)\n",
        "\n",
        "    for t in tf.range(max_target_length-1):\n",
        "      # Pass in two tokens from the target sequence:\n",
        "      # 1. The current input to the decoder.\n",
        "      # 2. The target for the decoder's next prediction.\n",
        "      new_tokens = target_tokens[:, t:t+2]\n",
        "      step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
        "                                            enc_output, dec_state)\n",
        "      loss = loss + step_loss\n",
        "\n",
        "    # Average the loss over all non padding tokens.\n",
        "    average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
        "\n",
        "    # Return a dict mapping metric names to current value\n",
        "    return {'batch_loss': average_loss}\n",
        "  ## --------------------------------------------------End of the test step evaluate function definition----------------------------------------------------------\n",
        "\n",
        "  ## --------------------------------------------------Start of the tf train step function ----------------------------------------------------------\n",
        "  # wrap train step into tf function to speed up the process\n",
        "  @tf.function(input_signature=[[tf.TensorSpec(dtype=tf.string, shape=[None]),\n",
        "                               tf.TensorSpec(dtype=tf.string, shape=[None])]])\n",
        "  def _tf_train_step(self, inputs):\n",
        "    return self._train_step(inputs)\n",
        "  ## --------------------------------------------------Start of the tf train step function ----------------------------------------------------------\n",
        "\n",
        "\n",
        "  ## --------------------------------------------------Start of the train loop function----------------------------------------------------------\n",
        "  #The _loop_step method, added below, executes the decoder and calculates the incremental loss and new decoder state (dec_state).\n",
        "  def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n",
        "    input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n",
        "\n",
        "    # Run the decoder one step.\n",
        "    decoder_input = DecoderInput(new_tokens=input_token,\n",
        "                                enc_output=enc_output,\n",
        "                                mask=input_mask)\n",
        "\n",
        "    dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n",
        "    self.shape_checker(dec_result.logits, ('batch', 't1', 'logits'))\n",
        "    self.shape_checker(dec_result.attention_weights, ('batch', 't1', 's'))\n",
        "    self.shape_checker(dec_state, ('batch', 'dec_units'))\n",
        "\n",
        "    # `self.loss` returns the total for non-padded tokens\n",
        "    y = target_token\n",
        "    y_pred = dec_result.logits\n",
        "    step_loss = self.loss(y, y_pred)\n",
        "\n",
        "    return step_loss, dec_state\n",
        "   ## --------------------------------------------------End of the train loop function----------------------------------------------------------"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIWxhEMq-hxK"
      },
      "source": [
        "## Test the Model to see whether it works or not for a single batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PBoLFRi7k-P"
      },
      "source": [
        "translator = TrainTranslator(\n",
        "    embedding_dim, units,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        "    use_tf_function=True)\n",
        "\n",
        "# Configure the loss and optimizer\n",
        "translator.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=MaskedLoss(),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "923fPXrO9Gz9",
        "outputId": "0a885e40-eff3-405c-cbfa-bb1aaee1fc9c"
      },
      "source": [
        "losses = []\n",
        "for n in range(100):\n",
        "  print('.', end='')\n",
        "  logs = translator.train_step([example_input_batch, example_target_batch])\n",
        "  losses.append(logs['batch_loss'].numpy())\n",
        "\n",
        "print()\n",
        "plt.plot(losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "....................................................................................................\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fadc2c89bd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_InTuIU-lTG"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIJF1cdi-pbe"
      },
      "source": [
        "train_translator = TrainTranslator(\n",
        "    embedding_dim, units,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        "    use_tf_function=True)\n",
        "\n",
        "# Configure the loss and optimizer\n",
        "train_translator.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=MaskedLoss(),\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuAmK76A_BX0"
      },
      "source": [
        "class BatchLogs(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, key):\n",
        "    self.key = key\n",
        "    self.logs = []\n",
        "\n",
        "  def on_train_batch_end(self, n, logs):\n",
        "    self.logs.append(logs[self.key])\n",
        "\n",
        "batch_loss = BatchLogs('batch_loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pliFuhCm_DP7",
        "outputId": "4b31c929-2f1c-4130-e25f-3e170af63148"
      },
      "source": [
        "train_translator.fit(train_dataset, epochs=100, callbacks=[batch_loss])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 9s 382ms/step - batch_loss: 5.3361\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 1s 365ms/step - batch_loss: 5.7169\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 1s 402ms/step - batch_loss: 4.5481\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 1s 389ms/step - batch_loss: 4.6335\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 1s 411ms/step - batch_loss: 4.3830\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 1s 409ms/step - batch_loss: 4.0240\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 1s 369ms/step - batch_loss: 4.0825\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 1s 392ms/step - batch_loss: 4.0373\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 1s 390ms/step - batch_loss: 3.8578\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 1s 383ms/step - batch_loss: 3.7316\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 1s 353ms/step - batch_loss: 3.7170\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 1s 420ms/step - batch_loss: 3.5849\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 1s 365ms/step - batch_loss: 3.4649\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 1s 376ms/step - batch_loss: 3.5134\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 1s 368ms/step - batch_loss: 3.3930\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 1s 391ms/step - batch_loss: 3.3691\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 1s 390ms/step - batch_loss: 3.1731\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 1s 369ms/step - batch_loss: 3.0924\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 1s 403ms/step - batch_loss: 3.0150\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 1s 338ms/step - batch_loss: 3.0537\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 1s 338ms/step - batch_loss: 2.9095\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 1s 391ms/step - batch_loss: 2.8092\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 1s 353ms/step - batch_loss: 2.6235\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 1s 318ms/step - batch_loss: 2.5389\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 1s 407ms/step - batch_loss: 2.3174\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 1s 425ms/step - batch_loss: 2.3963\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 1s 393ms/step - batch_loss: 2.2573\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 1s 348ms/step - batch_loss: 2.1853\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 1s 373ms/step - batch_loss: 2.0568\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 1s 359ms/step - batch_loss: 1.8721\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 1s 366ms/step - batch_loss: 1.9052\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 1s 405ms/step - batch_loss: 1.7514\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 1s 409ms/step - batch_loss: 1.6981\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 1s 345ms/step - batch_loss: 1.5279\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 1s 385ms/step - batch_loss: 1.4182\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 1s 311ms/step - batch_loss: 1.3747\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 1s 384ms/step - batch_loss: 1.3284\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 1s 393ms/step - batch_loss: 1.1423\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 1s 370ms/step - batch_loss: 1.0337\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 1s 350ms/step - batch_loss: 0.9138\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 1s 384ms/step - batch_loss: 0.8685\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 1s 338ms/step - batch_loss: 0.8138\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 1s 380ms/step - batch_loss: 0.7257\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 1s 380ms/step - batch_loss: 0.6221\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 1s 353ms/step - batch_loss: 0.5688\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 1s 410ms/step - batch_loss: 0.4874\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 1s 406ms/step - batch_loss: 0.4696\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 1s 400ms/step - batch_loss: 0.3813\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 1s 387ms/step - batch_loss: 0.3602\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 1s 383ms/step - batch_loss: 0.3053\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 1s 354ms/step - batch_loss: 0.2777\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 1s 361ms/step - batch_loss: 0.2250\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 1s 384ms/step - batch_loss: 0.2126\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 1s 377ms/step - batch_loss: 0.1692\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 1s 398ms/step - batch_loss: 0.1534\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 1s 335ms/step - batch_loss: 0.1364\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 1s 401ms/step - batch_loss: 0.1195\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 1s 318ms/step - batch_loss: 0.1368\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 1s 397ms/step - batch_loss: 0.0944\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 1s 373ms/step - batch_loss: 0.0853\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 1s 362ms/step - batch_loss: 0.0732\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 1s 376ms/step - batch_loss: 0.0807\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 1s 375ms/step - batch_loss: 0.0709\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 1s 388ms/step - batch_loss: 0.0551\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 1s 307ms/step - batch_loss: 0.0633\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 1s 344ms/step - batch_loss: 0.0539\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 1s 365ms/step - batch_loss: 0.0375\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 1s 387ms/step - batch_loss: 0.0390\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 1s 369ms/step - batch_loss: 0.0521\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 1s 424ms/step - batch_loss: 0.0362\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 1s 340ms/step - batch_loss: 0.0304\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 1s 380ms/step - batch_loss: 0.0447\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 1s 413ms/step - batch_loss: 0.0281\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 1s 370ms/step - batch_loss: 0.0258\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 1s 401ms/step - batch_loss: 0.0248\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 1s 350ms/step - batch_loss: 0.0211\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 1s 354ms/step - batch_loss: 0.0226\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 1s 352ms/step - batch_loss: 0.0189\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 1s 377ms/step - batch_loss: 0.0210\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 1s 346ms/step - batch_loss: 0.0190\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 1s 403ms/step - batch_loss: 0.0165\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 1s 395ms/step - batch_loss: 0.0159\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 1s 339ms/step - batch_loss: 0.0175\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 1s 320ms/step - batch_loss: 0.0287\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 1s 356ms/step - batch_loss: 0.0201\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 1s 359ms/step - batch_loss: 0.0154\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 1s 375ms/step - batch_loss: 0.0162\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 1s 336ms/step - batch_loss: 0.0150\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 1s 358ms/step - batch_loss: 0.0135\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 1s 355ms/step - batch_loss: 0.0131\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 1s 426ms/step - batch_loss: 0.0186\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 1s 392ms/step - batch_loss: 0.0171\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 1s 299ms/step - batch_loss: 0.0131\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 1s 363ms/step - batch_loss: 0.0115\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 1s 376ms/step - batch_loss: 0.0131\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 1s 386ms/step - batch_loss: 0.0236\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 1s 351ms/step - batch_loss: 0.0122\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 1s 366ms/step - batch_loss: 0.0127\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 1s 341ms/step - batch_loss: 0.0122\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 1s 367ms/step - batch_loss: 0.0112\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fadc2c407d0>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFCAm2xqAdx4",
        "outputId": "49b0e0b8-9772-4957-fd67-ed1ed3108f06"
      },
      "source": [
        "losses = []\n",
        "for test_input_batch, test_target_batch in test_dataset:\n",
        "  logs = train_translator._test_step([test_input_batch, test_target_batch])\n",
        "  losses.append(logs['batch_loss'].numpy())\n",
        "print(\"Test loss: \",losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss:  [0.0074260985]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15SEZQ5062pY"
      },
      "source": [
        "# Create a Translater"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pboiGcpcDPww"
      },
      "source": [
        "class Translator(tf.Module):\n",
        "\n",
        "  def __init__(self, encoder, decoder, input_text_processor,\n",
        "               output_text_processor):\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.input_text_processor = input_text_processor\n",
        "    self.output_text_processor = output_text_processor\n",
        "\n",
        "    self.output_token_string_from_index = (\n",
        "        tf.keras.layers.StringLookup(\n",
        "            vocabulary=output_text_processor.get_vocabulary(),\n",
        "            mask_token='',\n",
        "            invert=True))\n",
        "\n",
        "    # The output should never generate padding, unknown, or start.\n",
        "    index_from_string = tf.keras.layers.StringLookup(\n",
        "        vocabulary=output_text_processor.get_vocabulary(), mask_token='')\n",
        "    token_mask_ids = index_from_string(['', '[UNK]', '[START]']).numpy()\n",
        "\n",
        "    token_mask = np.zeros([index_from_string.vocabulary_size()], dtype=np.bool)\n",
        "    token_mask[np.array(token_mask_ids)] = True\n",
        "    self.token_mask = token_mask\n",
        "\n",
        "    self.start_token = index_from_string(tf.constant('[START]'))\n",
        "    self.end_token = index_from_string(tf.constant('[END]'))\n",
        "\n",
        "  def tokens_to_text(self, result_tokens):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(result_tokens, ('batch', 't'))\n",
        "    result_text_tokens = self.output_token_string_from_index(result_tokens)\n",
        "    shape_checker(result_text_tokens, ('batch', 't'))\n",
        "\n",
        "    result_text = tf.strings.reduce_join(result_text_tokens,\n",
        "                                        axis=1, separator=' ')\n",
        "    shape_checker(result_text, ('batch'))\n",
        "\n",
        "    result_text = tf.strings.strip(result_text)\n",
        "    shape_checker(result_text, ('batch',))\n",
        "    return result_text\n",
        "\n",
        "  def sample(self, logits, temperature):\n",
        "    shape_checker = ShapeChecker()\n",
        "    # 't' is usually 1 here.\n",
        "    shape_checker(logits, ('batch', 't', 'vocab'))\n",
        "    shape_checker(self.token_mask, ('vocab',))\n",
        "\n",
        "    token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n",
        "    shape_checker(token_mask, ('batch', 't', 'vocab'), broadcast=True)\n",
        "\n",
        "    # Set the logits for all masked tokens to -inf, so they are never chosen.\n",
        "    logits = tf.where(self.token_mask, -np.inf, logits)\n",
        "\n",
        "    if temperature == 0.0:\n",
        "      new_tokens = tf.argmax(logits, axis=-1)\n",
        "    else: \n",
        "      logits = tf.squeeze(logits, axis=1)\n",
        "      new_tokens = tf.random.categorical(logits/temperature,\n",
        "                                          num_samples=1)\n",
        "\n",
        "    shape_checker(new_tokens, ('batch', 't'))\n",
        "\n",
        "    return new_tokens\n",
        "\n",
        "  def translate_unrolled(self,\n",
        "                       input_text, *,\n",
        "                       max_length=50,\n",
        "                       return_attention=True,\n",
        "                       temperature=1.0):\n",
        "    batch_size = tf.shape(input_text)[0]\n",
        "    input_tokens = self.input_text_processor(input_text)\n",
        "    enc_output, enc_state = self.encoder(input_tokens)\n",
        "\n",
        "    dec_state = enc_state\n",
        "    new_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "\n",
        "    result_tokens = []\n",
        "    attention = []\n",
        "    done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "\n",
        "    for _ in range(max_length):\n",
        "      dec_input = DecoderInput(new_tokens=new_tokens,\n",
        "                              enc_output=enc_output,\n",
        "                              mask=(input_tokens!=0))\n",
        "\n",
        "      dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n",
        "\n",
        "      attention.append(dec_result.attention_weights)\n",
        "\n",
        "      new_tokens = self.sample(dec_result.logits, temperature)\n",
        "\n",
        "      # If a sequence produces an `end_token`, set it `done`\n",
        "      done = done | (new_tokens == self.end_token)\n",
        "      # Once a sequence is done it only produces 0-padding.\n",
        "      new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)\n",
        "\n",
        "      # Collect the generated tokens\n",
        "      result_tokens.append(new_tokens)\n",
        "\n",
        "      if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "        break\n",
        "\n",
        "    # Convert the list of generates token ids to a list of strings.\n",
        "    result_tokens = tf.concat(result_tokens, axis=-1)\n",
        "    result_text = self.tokens_to_text(result_tokens)\n",
        "\n",
        "    if return_attention:\n",
        "      attention_stack = tf.concat(attention, axis=1)\n",
        "      return {'text': result_text, 'attention': attention_stack}\n",
        "    else:\n",
        "      return {'text': result_text}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4UwhwiNDRU6"
      },
      "source": [
        "translator = Translator(\n",
        "    encoder=train_translator.encoder,\n",
        "    decoder=train_translator.decoder,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5-Ln_ZcQDgI"
      },
      "source": [
        "kan1, kan2, kan3, kan4, kan5, eng1, eng2, eng3, eng4, eng5 = \"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"\n",
        "\n",
        "t1 = 'ಹೇಗಿದ್ದೀರ'\n",
        "for test_input_batch, test_target_batch in test_dataset:\n",
        "  kan1 = test_input_batch[0].numpy().decode()\n",
        "  eng1 = test_target_batch[0].numpy().decode()\n",
        "  kan2 = test_input_batch[1].numpy().decode()\n",
        "  eng2 = test_target_batch[1].numpy().decode()\n",
        "  kan3 = test_input_batch[6].numpy().decode()\n",
        "  eng3 = test_target_batch[6].numpy().decode()\n",
        "  kan4 = test_input_batch[8].numpy().decode()\n",
        "  eng4 = test_target_batch[8].numpy().decode()\n",
        "  kan5 = test_input_batch[13].numpy().decode()\n",
        "  eng5 = test_target_batch[13].numpy().decode()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcmMwMfkDbAR",
        "outputId": "a85e7ce4-5a5f-4606-f580-e3405d996fdf"
      },
      "source": [
        "%%time\n",
        "input_text = tf.constant([kan1, kan2, kan3, kan4, kan5, t1])\n",
        "\n",
        "result = translator.translate_unrolled(\n",
        "    input_text = input_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 804 ms, sys: 13.6 ms, total: 818 ms\n",
            "Wall time: 810 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Yq5nBjmU585"
      },
      "source": [
        "## Kannada to English Translation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIRuKnDW9fsu",
        "outputId": "c3d4e7cf-cf54-4167-89ef-22d90de6aede"
      },
      "source": [
        "print(kan1)\n",
        "print(result['text'][0].numpy().decode())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ಆಹಾರಕ್ಕೆ ತುಂಬಾ ಎಣ್ಣೆ ಇತ್ತು ಅಂತ ಅನಿಸಿತು.\n",
            "both my father and i went to the one who taught you was factory .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVkHgKum9mh-",
        "outputId": "af8f7be7-4e6b-4969-ebde-e9fb011986d4"
      },
      "source": [
        "print(kan2)\n",
        "print(result['text'][1].numpy().decode())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ಅದು ಪರಿಹಾರ ಇಲ್ಲವೇ ಇಲ್ಲ.\n",
            "that's not really a solution .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eL81cHuIUONC",
        "outputId": "afb8d95f-645c-482d-c89e-f9e1ba914ac1"
      },
      "source": [
        "print(kan3)\n",
        "print(result['text'][2].numpy().decode())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ನಾನು ಏನನ್ನು ಮಾಡಬೇಕೆಂದು ಸರಿಯಾಗಿ ನೀವು ಹೇಳಬೇಕು.\n",
            "you have to tell me exactly what i need to do .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANHafcabUnz1",
        "outputId": "81c48996-433a-48f1-9ccd-a4f5566ebad6"
      },
      "source": [
        "print(kan4)\n",
        "print(result['text'][3].numpy().decode())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ಕುಡಿಯೋಕ್ಕೆ ಏನಾದ್ರು ಬೇಕಾ ?\n",
            "do you need something to drink ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfgEBV13UoA6",
        "outputId": "b37633f7-20e6-4184-f8be-01710cb56dc6"
      },
      "source": [
        "print(kan5)\n",
        "print(result['text'][4].numpy().decode())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ಅಪಘಾತದ ಕಾರಣವೇ ಗೊತ್ತಿಲ್ಲ.\n",
            "the cause of the accident is unknown .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKBgrvdPydc6",
        "outputId": "154f6394-f96b-412d-c8b4-2f2ae779f4a8"
      },
      "source": [
        "print(t1)\n",
        "print(result['text'][5].numpy().decode())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ಹೇಗಿದ್ದೀರ\n",
            "how are you ?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JM4SVkfDE1C"
      },
      "source": [
        "# Weights Analyse"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwObt7u4EI0c"
      },
      "source": [
        "a = result['attention'][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "pYh7LdveEKAv",
        "outputId": "cc7d5909-ec74-4ef4-f963-5cf703d55050"
      },
      "source": [
        "_ = plt.bar(range(len(a[0, :])), a[0, :])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1YUpD10ERuj"
      },
      "source": [
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  sentence = tf_lower_and_split_punct(sentence).numpy().decode().split()\n",
        "  predicted_sentence = predicted_sentence.numpy().decode().split() + ['[END]']\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  attention = attention[:len(predicted_sentence), :len(sentence)]\n",
        "\n",
        "  #ax.matshow(attention, cmap='viridis', vmin=0.0)\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0, vmax = 1)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')\n",
        "  plt.suptitle('Attention weights')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pfcb0ZEfES7i",
        "outputId": "992b4a1a-ace2-4565-8a32-d7ae5be0f750"
      },
      "source": [
        "i=1\n",
        "plot_attention(result['attention'][i], input_text[i], result['text'][i])\n",
        "print(input_text[i].numpy().decode())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ಅದು ಪರಿಹಾರ ಇಲ್ಲವೇ ಇಲ್ಲ.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3205 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3238 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3265 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3242 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3248 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3263 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3257 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3262 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3207 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3250 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3277 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3253 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3270 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3285 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3205 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3238 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3265 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3242 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3248 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3263 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3257 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3262 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3207 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3250 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3277 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3253 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3270 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3285 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnoAAAKDCAYAAACNN6fdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd7ysZ1k3+t+103YSAggBCbxSBaS3EDpEUEEPFkDhPfRyiKhYQEQU9aiAVM+LIK8QlGKkqYCIVBUCEqI0KRKKlAABAoSWhEDqdf6Y2S+LxS6zZq+1Zube3+/nM589z/3c8zzX3Lus376fVt0dAADGs2PRBQAAsDUEPQCAQQl6AACDEvQAAAYl6AEADErQAwAYlKAHMKOqem5V/f6i69idqrpDVX1sxr7HV9UZW10TsHiCHrDUqurkqvp6VR22rv30qvqxNctXr6quqoM3ab8Prqp3rG3r7kd09xM2Y/ubrbv/rbuvuxnbqqoXVdUTN2NbwGIJesDSqqqrJ7lDkk7yMwstBmAFCXrAMntgkn9P8qIkD9rVWFUnJblqktdW1blV9dgkb5+u/sa07TbTvg+tqo9MZwXfVFVXW7OdrqpHVNV/V9U3quo5NXG9JM9Ncpvptr4x7f89M11V9fCq+kRVfa2q/rGqrryvba//glW1s6q+XVVHT5cfX1UXVdWlp8tPqKpnTt8fVlXPqKrPVtWXpoeSD5+u+57DsVV186r6z6o6p6r+rqpesX6Wrqp+s6q+XFVfrKqHTNtOSHK/JI+dfvfXTtt/u6o+P93ex6rqLhv5jQQWQ9ADltkDk7xk+rprVf1gknT3A5J8NslPd/eluvtpSe44/cxlp22nVtXPJvndJPdMcoUk/5bkZev2cfckt0xy4yT3TnLX7v5IkkckOXW6rcuuL6yq7pzkydPPHJPkM0levq9tr99Od38nybuT3GnadKfptm63Zvlt0/dPSXKdJDdN8sNJrpLkD3ZT26FJXp1JQL7c9DvfY123KyW5zHQbD0vynKr6ge4+MZPxftr0u/90VV03ySOT3LK7j5p+j9PX7xdYPoIesJSq6vZJrpbkb7v7vUk+meS+G9zMI5I8ubs/0t0XJfmTJDddO6uX5Cnd/Y3u/mySt2YSomZxvyQv6O73dff5SX4nkxnAq8+x7bcludP0/MIbJ3nWdHlnJkHx7dPZwBOSPKq7v9bd50y/z//czfZuneTgJM/q7gu7+1VJ3rWuz4VJ/ni6/vVJzk2yp3P8Lk5yWJLrV9Uh3X16d39yTwMDLA9BD1hWD0ry5u4+a7r80qw5fDujqyX5s+mh028k+VqSymQWa5cz17w/L8mlZtz2lTOZeUuSdPe5Sb4657bfluT4JDdP8qEk/5zJTN6tk3yiu7+ayYzkEUneu+b7vHHavrvaPt/dvabtc+v6fHUafvdZX3d/IslvJPnDJF+uqpevPUwNLC9BD1g60/PO7p3JrNaZVXVmkkcluUlV3WTardd9bP1yMgk3v9jdl13zOry73zlDGbvb3lpfyCRI7qr5yCSXT/L5Gba93jszmU27R5K3dfdpmZyD+FP57mHbs5J8O8kN1nyXy3T37sLZF5NcZd05gT+0gXq+77t390u7e9csayd56ga2ByyIoAcso5/L5HDh9TM53HnTJNfL5By7B077fCnJNdd85itJLlnX9twkv1NVN0iSqrpMVf3CjDV8Kcn/mJ7vtjsvS/KQqrrp9NYvf5LkP7r79Bm3/39093lJ3pvkV/LdYPfOTA49v23a55Ikz0/yv6rqitPvc5Wq+r7z/pKcmsn4PbKqDp6eq3jcBkr6nrGtqutW1Z2n3/M7mQTOSzawPWBBBD1gGT0oyQu7+7PdfeauV5I/T3K/6blsT07ye9PDmI+ZhqUnJTll2nbr7n51JjNPL6+qs5P8V5KfnLGGtyT5cJIzq+qs9Su7+1+S/H6SV2Yyg3at7P58ue9RVR+vqneuf2Uyg3dkkqdNl2+R5Kgkj1vz8d9O8okk/z79Pv+S3ZxX190XZHIBysOSfCPJ/ZP8U5LzZ/zuf5XJ+XjfqKp/yOT8vKdkMqt4ZpIrZnJOIrDk6ntP4QBgK1XVf3b3zTbQ/93dfctN2O9/JHlud79wf7cFrA4zegDba6P/u57rf+NVdaequtL00O2DMrma943zbAtYXZvyqCAAls51k/xtJoeDP5Xk57v7i4stCdhugh7AgKY3Pj5x0XUAiyXoDaaq7jnHx97Q3d/e9GIAgIVyMcZgqmqjtzzoJNfu7k9tRT3A96qq/87k/n7f99zbdXra51KbcTEGcGAyozemK3X3l2fpWFXnbHUxwPe4QfYd8tZyvzpgboLeeF6cyc1MZ/U3Sc7eoloYXFU9LcnRG/jIp7v7CVtVz4p4YjY2Zp+afgZgwxy6BeZWVe/P5FFls8xQVZK/7u6NPKFhOFX1gUzGbKbuMWbAfjCjN6CqujjJMbMevoX90N398Vk7r3v26oHqku7+2KydjRmwP9wweUx+MLBdtuXmv4MxZsC2EfQAAAbl0O247j196Pkedfdfb1cxAMD2E/TG9ZTs/ZBPJxH02F+HVdUDZ+xbcVpBYsyAbeSq2wFNb5o88730YF5Vdd8kR23gI1/u7ldvVT2rwJgB28mM3pikd7bLJ5Ls3EB/N+g2ZsA2MqM3IDN6bJeqOi3JP2T2w4t3OdDvCWfMgO1kRm9Me306RlUdm+SJ3X237SuJQZ3f3b87a+eqevdWFrMijBkssaq63EY/091f24paNoOgN6DufkhV/XhV/USSC5P8ZXd/qqquk+TpSe6e5J8XWiSjcE+4jTNmsNzOysb+3nVVXae7P7VVBe0PQW9AVfWgJC9M8rUkl0vysKr69STPS/KqJDft7g8tsEQAWGY/n8nP0H2pJK/f4lr2i6A3pkcl+d3ufkpV3TvJy5P8VpKbd/cnF1saACy1zyR5e3d/dZbOVfWpTI6eLSVBb0zXSvKK6fu/T3JxkkcLeSwB94TbOGMG26i7r7HB/jfcqlo2g6A3piOTfCtJuvuSqvpOks8ttiQG9ZmqOnUD/Z0yYMyAbeT2KgOa3l7lYUm+OW06Kcljknxpbb/uftU2lwYAK6GqKskDk9wryTUzuUDjU0n+LslLekUClKA3oGnQ25fu7oO2vBiGVlUnJzl0Ax/5UnffY4vKWQnGbD4bHLdKcqZxY39U1auS/Fwms+qnZfLn6vpJbpjk1d19rwWWNzOHbgfU3TsWXQMHjMt0981m7eyecEmM2byMG9umqu6X5CeS3K2737xu3V2TvLKq7tvdL11IgRsgEBygqurHFl0DQ3BPuI0zZvMxbmyn+yd56vqQlyTd/aZM7kl7/22vag6C3gGkqq5SVb83vRT8TYuuBwCW1E2y9/vjvS7JTbeplv0i6A2uqg6qqntW1euSnJ7kHkmem+SHF1oYACyvyyf54l7WfzGTBxIsPefoDaqqrpvk/8nkiqFvJXlpJucbPKC7T1tkbQCw5A7J3m+CfNG0z9IT9AZUVf+WyVVBr0xy7+5+27T9txdaGCM6sqpeMGPfipv/JsZsXsaN7fbkqjpvD+uO2NZK9oOgN6bbJHlOkhO7+8OLLoah/WQ29r/ab29VISvEmM3HuLGd3p7JU6b21WfpCXpjumUmh23fUVWnJ/nrJC9baEVLrqp+LcllN/CRL3T3X25VPSvk7tnguCU50MfNmM3HuLFtuvv4RdewWdwweWBVtTPJLyR5aJLbZ3LxzeOS/GV3f32RtS2bqvpgJk8PmfVwzxO6+7gtLGklGLeNM2bzMW4wH0FvQFV11SSfW/t4lqr64Xz34ozLJ3lLd//kgkpcOlX1nxu9GWt333Ira1oFxm3jjNl8jBvbqaoePUu/7v7/trqW/eXQ7Zg+neSYJF/e1dDdn0jyuKp6fCaHQB66oNqWlZuxzse4bZwxm49xYzv96l7WdZIrJTksiaDHQuzx0EZ3X5zkNdMXALBOd19jd+1Vdc0kT8rktKi/29ai5uSGyQAAe1FVl6+qZyY5LckVk9y6u//ngsuaiRm9cT2mqs7dW4fu/uPtKmYFHFJVd5yxr3t0fZdx2zhjNh/jxrarqsOTPDrJYzN9ulR3v2GhRW2QizEGVFWXJPlYJnfu3pPu7htvU0lLr6oem+QHNvCRM7r7OVtVz6owbhtnzOZj3NhOVbUjycOS/FEmT8j4/SQn9QqGJkFvQNOgd6Xu/vI+O5MkqaorZ2Mz3Od395e2qp5VYdw2zpjNx7ixnarqtCRXS/KsJM9O8p3d9evur21nXfMQ9AZUVRcnOUbQm11VfTTJ+zI53LOvvxSV5Fru0WXc5mHM5mPc2E7TCZNddvfnrTI5MnbQNpU0N+fojcm5KRv37e6+76ydq+rdW1nMCjFuG2fM5mPc2E4/uugCNougN6Y/SrLXCzH4Pu7RNR/jtnHGbD7GjW3T3W9bdA2bxe1VxvSnSQ5f21BV16uqF1TV31bVSlwSDgCLUFUnVNVha5ZvUFUHr1k+sqpW4s4Vgt6Y/iKTWb0kSVUdneTfMnkixnWTvKSqZj4EAgAHmL9Icpk1y6cmueqa5Uslefy2VjQnQW9Mt0ny6jXLD0hyQZJrd/dNkjwjySMXUdhAnAc5H+O2ccZsPsaN/bH+z8/K/nlyjt6YjknyyTXLP5rkld39zenyi+NZt+tdUFXv3ED/r2xZJavFuG2cMZuPcYM5CHpjOi/JkWuWj0vyijXL30lyxLZWtPw+nclDqmf1ma0qZMUYt40zZvMxbjAHQW9MH0jykEweg3Z8kiskecua9ddK8oUF1LXMrpvk1plter6SvH1ry1kZxm3jjNl8jBvb7f+qql1HwnYkuWtV7boJ92UXVNOGCXpjekKSN1TVvTMJeS/q7i+uWX+PJO9YSGXLq7r7gpk7V63s+RqbzLhtnDGbj3Fju/3VuuX1j9RbiVv4CHoD6u63VdUtkvxEkjOT/N26Lu9P8q5tL2y5uUfXfIzbxhmz+Rg3tk13D3OxqqA3mKo6Lsl7u/sjST6yuz7dfeKa/rdI8sHuvnCbSgSApbXm5+jFM/Zf6p+jwyRW/o9Tk1xuA/3fmuSHtqgWAFg1Q/0cNaM3nkry5Ko6b8b+h25lMSvk8Kr6gxn7Ovfnu4zbxhmz+Ri3LVJVH8nkPqsywcRQP0f9po7n7ZlcVTurU5N8e4tqWSW/mHWPjduHN21VISvGuG2cMZuPcds6z0ly+UUXsUSG+jla3c5XBQAYkXP0AAAGJegdQKrqhEXXsGqM2XyM23yM28YZs/kYt/ms4rgJegeWlfsDugSM2XyM23yM28YZs/kYt/ms3LgJegAAg3IxxiY7tA7rnTly0WXs1oU5P4fksEWXsVKM2XyWedyW+clYF+T8HLqk45YdyzkvcEF/O4fWRi7G3T5Xvv7Ziy5hj77xtYtz2csdtOgyduvzH1rOn6HJcv/bdk6+flZ3X2F9u9urbLKdOTK3qrssugwOBEscWJbZjsOW8x/pZVc7jdtGPeG1/7zoElbS717juEWXsJL+pf/+M7trX87/ogEAsN8EPQCAQQl6AACDEvQAAAYl6AEADErQAwAYlKAHADAoQQ8AYFCCHgDAoAQ9AIBBCXoAAIMS9AAABiXoAQAMStADABiUoAcAMChBDwBgUIIeAMCgBD0AgEEJegAAgxL0AAAGJegBAAxK0AMAGJSgBwAwKEEPAGBQgh4AwKAEPQCAQQl6AACDEvQAAAYl6AEADErQAwAYlKAHADAoQQ8AYFCCHgDAoFYq6FXV8VXVVXX0omsBAFh2Sx30qurkqvrz7dhuVV29qnqz9wUAsChLHfQAAJjf0ga9qnpRkjsl+ZXp4dpOcvXp6ptU1X9U1XlV9Z6quvmaz12+ql5WVWdU1ber6sNV9ZC9bbeqdm137f4vU1UnVdWXq+o7VfWpqvqNLfvCAACbbGmDXpJfT3JqkhcmOWb6+tx03ZOTPC7JzZN8NclLqqqm63YmeV+Suye5QZI/S/K8qrrLDNtd64lJbjTdznWTPDTJ53dXaFWdMA2c77kw58/7fQEANtXBiy5gT7r7m1V1QZLzuvvMJKmqH5mu/v3ufuu07Y+TvCPJVZKc0d2fT/L0NZs6sarunOT/TvKvu9vu1OlJas3y1ZK8r7vfNV3+zF5qPTHJiUly6bqc8/wAgKWwzDN6e/PBNe+/MP31iklSVQdV1eOr6oNV9dWqOjfJPZNcdYP7+Isk96mqD1TVM6rqTvtfNgDA9lnVoHfhmve7ZtB2fZfHJPnNTGb17pLkpkn+IcmhG9lBd78hk1m9ZyQ5OsnrquqF+1EzAMC2Wvagd0GSgzb4mdsneW13n9Td70/yySTXmWe73X3WdDsPTvKwJA+qqsM2WA8AwEIs7Tl6U6cnOW56Vey5mS2YfjyTQ663T3JWkl9Nco0k/7mX7X6tuy9Zu5HpuX/vS/LhTMbpnkk+1d2utgAAVsKyz+g9I5PZt9OSfCWznWf3xCTvSvKGJG9P8q0kL5lju+cneVKSDyQ5JclRSX56w98AAGBBlnpGr7s/nuQ265pftK7P6VlztWx3fz2T2beNbnd9nydlEvQAAFbSss/oAQAwJ0EPAGBQgh4AwKAEPQCAQQl6AACDEvQAAAYl6AEADErQAwAYlKAHADAoQQ8AYFCCHgDAoAQ9AIBBCXoAAIMS9AAABiXoAQAMStADABiUoAcAMChBDwBgUIIeAMCgBD0AgEEJegAAgxL0AAAGJegBAAxK0AMAGJSgBwAwKEEPAGBQgh4AwKAEPQCAQQl6AACDEvQAAAYl6AEADOrgRRcASZIdBy26gpWzY+dhiy5hJdVRl1p0CSupjjxi0SWsnP/9pTsvuoSVtOOoWnQJq+ns3Teb0QMAGJSgBwAwKEEPAGBQgh4AwKAEPQCAQQl6AACDEvQAAAYl6AEADErQAwAYlKAHADAoQQ8AYFCCHgDAoAQ9AIBBCXoAAIMS9AAABiXoAQAMStADABiUoAcAMChBDwBgUIIeAMCgBD0AgEEJegAAgxL0AAAGJegBAAxK0AMAGJSgBwAwKEEPAGBQgh4AwKAEPQCAQQl6AACDEvQAAAYl6AEADErQAwAYlKAHADAoQW8vqurBVXXuousAAJiHoAcAMKihg15VnVxV/7uq/qSqzqqqL1fVM6pqx3T9D1TVi6vq61X17ar6l6q6wXTd8UlemOTIqurp6w8X920AADZm6KA3db8kFyW5bZJHJvmNJPeZrntRklsl+dkkxyU5L8kbq+rwJO+c9j0vyTHT1zO2s3AAgP1x8KIL2AandfcfTN9/vKoenuQuVfWeJD+T5E7d/fYkqaoHJPlskvt1919W1TeTdHefubcdVNUJSU5Ikp05Yqu+BwDAhhwIM3ofXLf8hSRXTHK9JJckOXXXiu7+ZpIPJbn+RnbQ3Sd297HdfewhOWw/ywUA2BwHQtC7cN1yZ9/fu7eoFgCAbXMgBL09+Ugm3/82uxqq6tJJbpTktGnTBUkO2v7SAAD23wEb9Lr7v5O8JsnzquoOVXWjJH+T5OwkL512Oz3Jzqr68ao6uqqcgAcArIwDNuhNPSTJu5L84/TXI5Lcrbu/nSTd/c4kz03ysiRfSfLYBdUJALBhQ191293H76btwWvefz3Jg/axjV9K8kubXRsAwFY70Gf0AACGJegBAAxK0AMAGJSgBwAwKEEPAGBQgh4AwKAEPQCAQQl6AACDEvQAAAYl6AEADErQAwAYlKAHADAoQQ8AYFCCHgDAoAQ9AIBBCXoAAIMS9AAABiXoAQAMStADABiUoAcAMChBDwBgUIIeAMCgBD0AgEEJegAAgxL0AAAGJegBAAxK0AMAGJSgBwAwKEEPAGBQgh4AwKAEPQCAQR286AIgSdKXLLqCldMXX7zoElZSGbf5dC+6gpVz2UPOW3QJK+kLOXLRJQzFjB4AwKAEPQCAQQl6AACDEvQAAAYl6AEADErQAwAYlKAHADAoQQ8AYFCCHgDAoAQ9AIBBCXoAAIMS9AAABiXoAQAMStADABiUoAcAMChBDwBgUIIeAMCgBD0AgEEJegAAgxL0AAAGJegBAAxK0AMAGJSgBwAwKEEPAGBQgh4AwKAEPQCAQQl6AACDEvQAAAYl6AEADErQAwAYlKAHADAoQQ8AYFCCHgDAoAQ9AIBBHZBBr6pOr6rH7GkZAGAEB2TQAwA4EKxU0KuqQxddAwDAqljqoFdVJ1fVX1TVM6rqK0lOqarrV9XrquqcqvpyVb2sqq605jO3rKo3V9VZVXV2Vb2jqm6zgX2+oKr+aV3bjqr6bFU9ehO/HgDAllrqoDd1/ySV5A5Jfi3J25P8V5LjkvxYkksleU1V7fouRyU5adr/uCTvT/L6qrr8jPt7fpK7VdUxa9p+PMmVptv9PlV1QlW9p6rec2HO38h3AwDYMqsQ9D7d3b/Z3R9N8pNJPtDdv93dH+nuDyZ5YCaB7tgk6e63dPdJ0/UfTfKrSb4z/ew+dfepST6a5EFrmh+a5B+7+yt7+MyJ3X1sdx97SA6b93sCAGyqVQh6713z/hZJ7lhV5+56JfncdN21kqSqrlhVz6uqj1fVN5Ock+SKSa66gX0+P8lDptu7XJKfTfJX+/k9AAC21cGLLmAG31rzfkeS1yXZ3a1QvjT99cVJfjDJo5KcnuT8JP+aZCMXcpyU5KlVdfskN0vylSRv2lDVAAALtgpBb633Jbl3ks9094V76HP7JL/W3a9Lkqr6wSTH7KHvbnX316rqVZkcsr1Zkhd39yXzlw0AsP1W4dDtWs9Jcpkkr6iqW1XVNavqx6rqxKo6atrn40nuP70695ZJXp7kgjn29fwk90tykyQv2IziAQC200oFve7+QpLbJbkkyRuTfDiT8Hf+9JVMZuEulcm5fS/PJKSdPsfuTk5yRpKTu/tT+1M3AMAiLPWh2+4+fjdt/53k5/fymQ8kudW65pPW9bn63pandib5gSR/MFOxAABLZqmD3iJM78d3dJJfT/LtJH+72IoAAOYj6H2/qyb5dCaHbR+yl4s+AACWmqC3TnefnsmTOAAAVtpKXYwBAMDsBD0AgEEJegAAgxL0AAAGJegBAAxK0AMAGJSgBwAwKEEPAGBQgh4AwKAEPQCAQQl6AACDEvQAAAYl6AEADErQAwAYlKAHADAoQQ8AYFCCHgDAoAQ9AIBBCXoAAIMS9AAABiXoAQAMStADABiUoAcAMChBDwBgUIIeAMCgBD0AgEEJegAAgxL0AAAGdfCiCxhS1aIrWDkHHXXUoktYOXVpYzaPSy5n3OZx0aUOW3QJK+e1b77yoktYSde+whcXXcJqOnv3zWb0AAAGJegBAAxK0AMAGJSgBwAwKEEPAGBQgh4AwKAEPQCAQQl6AACDEvQAAAYl6AEADErQAwAY1D6DXlV93wMOd9cGAMBymWVG79QZ2wAAWCIH72lFVV0pyVWSHF5VN0tS01WXTnLENtQGAMB+2GPQS3LXJA9O8j+S/Gm+G/TOTvK7W1sWAAD7a49Br7tfnOTFVXWv7n7lNtYEAMAmmOUcvZ+rqsvsWqiqq1XVv25hTQAAbIJZgt47kvxHVf1UVT08yT8neebWlgUAwP7a2zl6SZLufl5VfTjJW5OcleRm3X3mllcGAMB+meU+eg9I8oIkD0zyoiSvr6qbbHFdAADsp33O6CW5V5Lbd/eXk7ysql6d5MVJbrqllQEAsF9mOXT7c0lSVUd093nd/a6qOm7rSwMAYH/Mcuj2NlV1WpKPTpdvEhdjAAAsvVmuun1mJjdP/mqSdPcHktxxK4sCAGD/zRL00t2fW9d08RbUAgDAJprlYozPVdVtk3RVHZLk15N8ZGvLAgBgf80yo/eIJL+S5CpJPp/J1ba/vJVFAQCw/2aZ0btud99vbUNV3S7JKVtTEgAAm2GWGb1nz9gGAMAS2eOMXlXdJsltk1yhqh69ZtWlkxy01YUBALB/9nbo9tAkl5r2OWpN+9lJfn4riwIAYP/tMeh199uSvK2qXtTdn9nGmgAA2AT7PEdPyAMAWE0z3TAZAIDVM8uzbm83SxsAAMvF7VUAAAbl9ip7UFV3S/L4JDdM0kneneQ3utvj3wCAlbC3Gb31t1fZ9TpQbq9yZJJnJjkuyfFJvpnktVV16CKLAgCYldur7EF3v3LtclU9JJOQe1ySd6xbd0KSE5JkZ47YrhIBAPZqlmfdvqiqen1jd995C+pZGlV1rSRPSHKrJFfIZPZzR5Krru/b3ScmOTFJLl2X+76xAgBYhFmC3mPWvN+Z5F5JLtqacpbKPyU5I8kvJvl8Jt/5tEwOaQMALL19Br3ufu+6plOq6l1bVM9SqKrLJ/mRJL/c3W+dtt08swVjAIClsM/gUlWXW7O4I8ktklxmyypaDl9PclaSh1fV55JcJcnTc2DMZAIAg5hlhuq9mdxepDIJOp9O8rCtLGrRuvuSqrpPkmcl+a8kn0jym0leudcPAgAskVkO3V5jOwpZNt39lkzuobfWpRZRCwDAPGY5dLszyS8nuX0mM3v/luS53f2dLa4NAID9MMuh279Ock6++9iz+yY5KckvbFVRAADsv1mC3g27+/prlt9aVadtVUEAAGyOvT0CbZf3VdWtdy1U1a2SvGfrSgIAYDPMMqN3iyTvrKrPTpevmuRjVfWhJN3dN96y6gAAmNssQe9uW14FAACbbpag98TufsDahqo6aX0bAADLZZZz9G6wdqGqDs7kcC4AAEtsj0Gvqn6nqs5JcuOqOruqzpkufynJa7atQgAA5rLHoNfdT+7uo5I8vbsv3d1HTV+X7+7f2cYaAQCYwyzn6L2hqu64vrG7374F9QAAsElmCXq/teb9ziTHJXlvkjtvSUUAAGyKfQa97v7ptctV9UNJnrllFQEAsClmuep2vTOSXG+zCwEAYHPtc0avqp6dpKeLO5LcNMn7trIoAAD23yzn6K19ru1FSV7W3adsUT0AAGySWYLeK5L88PT9J7r7O1tYDwAAm2RvN0w+uKqelsk5eS9O8tdJPldVT6uqQ7arQAAA5rO3izGenuRySa7R3bfo7psnuVaSyyZ5xnYUBwDA/PYW9O6e5OHdfc6uhu4+O8kvJfmpre/sU+kAAA1YSURBVC4MAID9s7eg193du2m8ON+9ChcAgCW1t6B3WlU9cH1jVd0/yUe3riQAADbD3q66/ZUkr6qqh2byyLMkOTbJ4UnusdWFAQCwf/YY9Lr780luVVV3TnKDafPru/tft6UyAAD2yyzPun1LkrdsQy0AAGyieZ51CwDAChD0AAAGJegBAAxK0AMAGJSgBwAwKEEPAGBQgh4AwKD2eR89NqaqsuOwwxZdxsq58MbXXHQJK+fiI/z1nceOCy9ZdAkr6ZCvnrfoElbOMaf4WTCPi07/3KJLGIoZPQCAQQl6AACDEvQAAAYl6AEADErQAwAYlKAHADAoQQ8AYFCCHgDAoAQ9AIBBCXoAAIMS9AAABiXoAQAMStADABiUoAcAMChBDwBgUIIeAMCgBD0AgEEJegAAgxL0AAAGJegBAAxK0AMAGJSgBwAwKEEPAGBQgh4AwKAEPQCAQQl6AACDEvQAAAYl6AEADErQAwAYlKAHADAoQQ8AYFCCHgDAoAQ9AIBBLW3Qq6qTq+rPN2E7x1dVV9XRm1EXAMCqWNqgN4+qOr2qHrOu+Z1Jjkny1QWUBACwMAcvuoCt1t0XJDlz0XUAAGy3LZ3Rq6o7VtW/V9W5VfXNqnpXVd1wuu6eVfWhqjq/qj5XVY+vqtrLtr5vtm7t4d2qOjnJ1ZI8fXqotqft33fodl/7nu7r96rqeVV1dlWdUVW/tamDAwCwxbYs6FXVwUlek+QdSW6S5FZJnpnk4qq6RZK/S/KqJDdK8rgkv5Pkkfuxy3smOSPJH2dyqPaYPdQ1674fleRDSW6e5KlJnlZVt9mP+gAAttVWHrq9dJLLJnltd39y2vbRJKmqlyR5W3f/v9P2j1fVtZP8dpJnz7Oz7v5aVV2c5Jzu3tuh2kfPuO83d/eui0GeXVW/luQuSU5dv8GqOiHJCUmys46cp3wAgE23ZTN63f21JC9K8qaqel1VPbqqrjpdfb0kp6z7yDuSXKWqLr1VNW1w3x9c1+cLSa64uw1294ndfWx3H3toDtu8SgEA9sOWnqPX3Q/J5JDt25P8TJKPVdVd9/WxPbRfkmT9OXyH7F+Fe933hbtZN9RVygDA2LY8uHT3B7r7qd19fJKTkzwoyUeS3G5d19snOaO7z9nDpr6SNefdVdXOJD+yrs8FSQ7aR0nz7BsAYOVs5cUY16iqp1TVbavqalX1o0lunOS0JH+a5E5V9YdVdZ2qul+S30zytL1s8i1J7je9ivYGSV6Q7z/H8PQkd6iqq+zlBsnz7BsAYOVs5cUY5yW5TiZXuB6d5EtJXpLkqd19YVX9QpI/SvK703VPSbK3J2E8OcnVM7mS99wkT0py5XV9/iDJ85J8Mslh+f5Dvenu982xbwCAlVPdezoljnlcZsfl+9Y7f2rRZayci45dfxSefbn4iOHvd74ldlx4yaJLWEmHfPW8RZewcs676lZfWzimna9/76JLWEn/cvEr3tvdx65vd3EBAMCgBD0AgEEJegAAgxL0AAAGJegBAAxK0AMAGJSgBwAwKEEPAGBQgh4AwKAEPQCAQQl6AACDEvQAAAYl6AEADErQAwAYlKAHADAoQQ8AYFCCHgDAoAQ9AIBBCXoAAIMS9AAABiXoAQAMStADABiUoAcAMChBDwBgUIIeAMCgBD0AgEEJegAAgxL0AAAGJegBAAxK0AMAGJSgBwAwqIMXXcBwduxIHX74oqtYOdWLrmD11EUGbS6GbS6X7Dxk0SWsnEPPuXDRJaykHYfvXHQJq+nc3Teb0QMAGJSgBwAwKEEPAGBQgh4AwKAEPQCAQQl6AACDEvQAAAYl6AEADErQAwAYlKAHADAoQQ8AYFCCHgDAoAQ9AIBBCXoAAIMS9AAABiXoAQAMStADABiUoAcAMChBDwBgUIIeAMCgBD0AgEEJegAAgxL0AAAGJegBAAxK0AMAGJSgBwAwKEEPAGBQgh4AwKAEPQCAQQl6AACDEvQAAAYl6AEADErQAwAYlKAHADAoQQ8AYFCCHgDAoAQ9AIBBCXoAAIM6eNEFjKCqTkhyQpLs3HGpBVcDADBhRm8TdPeJ3X1sdx97aO1cdDkAAEkEPQCAYQl6AACDEvQAAAYl6M2oqh5ZVR9ddB0AALMS9GZ3dJLrLroIAIBZCXoz6u4/7O5adB0AALMS9AAABiXoAQAMStADABiUoAcAMChBDwBgUIIeAMCgBD0AgEEJegAAgxL0AAAGJegBAAxK0AMAGJSgBwAwKEEPAGBQgh4AwKAEPQCAQQl6AACDEvQAAAYl6AEADErQAwAYlKAHADAoQQ8AYFCCHgDAoAQ9AIBBCXoAAIMS9AAABiXoAQAMStADABiUoAcAMChBDwBgUIIeAMCgBD0AgEEdvOgCRtM7D83F1/2hRZexci46/KBFl7ByDrrwkkWXsJJ2fPuiRZewknZ858JFl7ByDv7K2YsuYSX1oYcuuoShmNEDABiUoAcAMChBDwBgUIIeAMCgBD0AgEEJegAAgxL0AAAGJegBAAxK0AMAGJSgBwAwKEEPAGBQgh4AwKAEPQCAQQl6AACDEvQAAAYl6AEADErQAwAYlKAHADAoQQ8AYFCCHgDAoAQ9AIBBCXoAAIMS9AAABiXoAQAMStADABiUoAcAMChBDwBgUIIeAMCgBD0AgEEJegAAgxL0AAAGJegBAAxK0AMAGJSgBwAwqKUMelV1clX19HXrBddy+ppajl5kLQAAG7GUQW/qhUmOSfLeJFkTtta/HjFdf/x0+aNVdfDaDU3D2mPWLK8NkhdU1Rer6o1Vdf+qqnV13DLJvbb2qwIAbL5lDnrndfeZ3X3hmraHZxL+1r5evO5zV0vysBm2vytIXjPJzyQ5Ncnzkry6qg7a1am7v5Lka/N+CQCARTl4312Wyje6+8x99HlWkj+sqr/p7m/tpd95a7Z1RpJ3V9W/J3ljkgdmEgQBAFbWMs/ozevZSS5M8uiNfrC735TkQ9ngodqqOqGq3lNV77nwwr1lSwCA7bNqQe+kqjp33etG6/p8J8nvJ/mtqrrCHPs4LZPDuTPr7hO7+9juPvaQQ46cY5cAAJtv1YLebyW56brXx3bT76Qkp2cS+DaqkvSc9QEALI1VO0fvzO7+xL46dfclVfW4JP9QVX+2wX1cP8mn5qoOAGCJrNqM3sy6+/VJTknypFk/U1V3TXLDJH+/VXUBAGyXVZvRu2xVXWld27ndfe4e+j82yb9ncnHGekdMt3VwJrdZ+alp/9ck+ZtNqhcAYGFWbUbv+Um+uO71uD117u53ZzI7d9huVj9k+vlPJXltktskeUSSe3T3xZtbNgDA9luZGb3uXv/EivXrT87kQor17fdJcp91bcdvZm0AAMtomWf0TpjePuWWiyyiqj6c5A2LrAEAYB7LOqN3vySHT99/bpGFZHLu3iHT9x6FBgCsjKUMet39+UXXsEt3f2bRNQAAzGOZD90CALAfBD0AgEEJegAAgxL0AAAGJegBAAxK0AMAGJSgBwAwKEEPAGBQgh4AwKAEPQCAQQl6AACDEvQAAAYl6AEADErQAwAYlKAHADAoQQ8AYFCCHgDAoAQ9AIBBCXoAAIMS9AAABiXoAQAMStADABiUoAcAMChBDwBgUIIeAMCgBD0AgEEJegAAgxL0AAAGVd296BqGUlVfSfKZRdexB0cnOWvRRawYYzYf4zYf47Zxxmw+xm0+yzxuV+vuK6xvFPQOIFX1nu4+dtF1rBJjNh/jNh/jtnHGbD7GbT6rOG4O3QIADErQAwAYlKB3YDlx0QWsIGM2H+M2H+O2ccZsPsZtPis3bs7RA5hRVZ3b3Zfa5G1ePcltu/ulG1k347aPT3JBd79z/gqBVWZGD2Cxrp7kvnOsm8XxSW67H58HVpygB7BBVXV8VZ1cVX9fVR+tqpdUVU3XnV5VT6uqD1XVu6rqh6ftL6qqn1+zjXOnb5+S5A5V9f6qetS6XX3Puqo6qKqeXlXvrqoPVtUvTrf1qKp6wfT9jarqv6rq+kkekeRR08/fYWtHBVhGBy+6AIAVdbMkN0jyhSSnJLldkndM132zu29UVQ9M8swkd9/Ldh6X5DHdvbs+37Ouqk6YbvuWVXVYklOq6s1J/izJyVV1jySPT/KL3X1aVT03ybnd/Yz9/rbASjKjBzCfd3X3Gd19SZL3Z3KYdZeXrfn1Npu4z59I8sCqen+S/0hy+STXntbw4CQnJXlbd5+yifsEVpgZPYD5nL/m/cX53n9PezfvL8r0P9dVtSPJoXPss5L8ane/aTfrrp3k3CRXnmO7wKDM6AFsvvus+fXU6fvTk9xi+v5nkhwyfX9OkqP2sJ31696U5Jeq6pAkqarrVNWRVXWZJM9Kcsckl19zLuDetg0cAAQ9gM33A1X1wSS/nmTXBRbPT3KnqvpAJodzvzVt/2CSi6vqA7u5GGP9ur9MclqS91XVfyV5XiYzif8ryXO6++NJHpbkKVV1xSSvTXIPF2PAgct99AA2UVWdnuTY7l7WB58DBxAzegAAgzKjBwAwKDN6AACDEvQAAAYl6AEADErQAwAYlKAHADCo/x9Qd5H+tid95wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1lBga5tbDy4"
      },
      "source": [
        "# Questions & Answers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJlNcedYbJFi"
      },
      "source": [
        "Q1-)Which parts of the sentence are used as a token? Each character, each word, or are some words split up?\n",
        "\n",
        "Ans-) Each word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSFabVhgb6NA"
      },
      "source": [
        "Q-2) Do the same tokens in different language have the same ID?\n",
        "e.g. Would the same token index map to the German word die and to the English word die?\n",
        "\n",
        "\n",
        "Ans-) No. \n",
        "\n",
        "As example we can see below:\n",
        "\n",
        "*  inp = 'die hallo morgen guten tag'\n",
        "*  tar = 'Someone might die because of the situation'\n",
        "*  inp_voc = [0 1 2 3 4 5]\n",
        "*  tar_voc = [0 1 2 3 4 5 6]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43vetYtVdNt0"
      },
      "source": [
        "Q-3)What is the relation between the encoder output and the encoder hidden state which is used to initialize the decoder hidden state (for the architecture used in the tutorial)?\n",
        "\n",
        "Ans-) Encoder ouput is dependent on encoder hidden state whereas vice-versa isn't the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtXk0eDdfIgC"
      },
      "source": [
        "Q-4) Is the decoder attending to all previous positions, including the previous decoder predictions?\n",
        "\n",
        "Ans-) No it will attend to just the previous decoder state and predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiRXSZ3zfxpc"
      },
      "source": [
        "Q-5) Does the encoder output change in different decoding steps?\n",
        "\n",
        "Ans-) Yes it computes attention weights dynamically for every decoder step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgrMHrqvgNxN"
      },
      "source": [
        "Q-6) Does the context vector change in different decoding steps?\n",
        "\n",
        "Ans-) Yes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "molLOQfNgStB"
      },
      "source": [
        "Q-7) The decoder uses teacher forcing. Does this mean the time steps can be computed in parallel?\n",
        "\n",
        "Ans-) No because even the previous decoder state is also connected to the current decoder state."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnFce_9CgeTR"
      },
      "source": [
        "Q-8) Why is a mask applied to the loss function?\n",
        "\n",
        "Ans-) To skip the zero padded cells in the sequences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5KlAkttgwos"
      },
      "source": [
        "Q-9) When translating the same sentence multiple times, do you get the same result? Why (not)? If not, what changes need to be made to get the same result each time?\n",
        "\n",
        "Ans-) The output is not consistent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGd5aFjjm4zZ"
      },
      "source": [
        "# References\n",
        "\n",
        "\n",
        "\n",
        "1.   https://www.tensorflow.org/text/tutorials/nmt_with_attention\n",
        "2.   https://ovgu-ailab.github.io/idl2021/ass7.html\n",
        "\n"
      ]
    }
  ]
}