{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_7_NMT_Srinath.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9b1ec548",
        "0c34550c",
        "mjeunnuphktY",
        "sHbpSCdw8qnW",
        "yh0bPt7wkCHt",
        "JEIAwPgokXk6",
        "S6LD6RwikuOw",
        "6UKOUGEX0Z75",
        "J1JQ2_On36HO",
        "0LiDrt7y3-lW",
        "VQujLhNg4BrF",
        "3HCh9PfH4oZK",
        "7reyM4fc4rmJ",
        "ijN0V-aI46-x",
        "459_QH_87E7C",
        "XE7o0uJU4rh2",
        "XQI6bl3P65rr",
        "HcnrzfLV6_BN",
        "qIWxhEMq-hxK",
        "1_InTuIU-lTG",
        "4GTgPppn8XVy",
        "i5kjXuzK8cim",
        "15SEZQ5062pY",
        "fH9bV6qL_az8",
        "afmwjeFX819S",
        "0Yq5nBjmU585",
        "_JM4SVkfDE1C",
        "Q1lBga5tbDy4"
      ],
      "machine_shape": "hm",
      "mount_file_id": "156VNP0l29aIE4p0WHewhNZn95t-7XKvN",
      "authorship_tag": "ABX9TyNKwLTWD/EcM5F9dio2yqn6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mannam95/Deep_Learning_Programming/blob/main/Assignment7/Assignment_7_NMT_Srinath.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6aef94d"
      },
      "source": [
        "# Team Assignment\n",
        "\n",
        "\n",
        "1.   Srinath Mannam (229750)\n",
        "2.   Meghana Rao (234907)\n",
        "3.   Govind Shukla (235192)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b1ec548"
      },
      "source": [
        "# import statements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQCgf3jKQ8L3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46623da4-a5e1-4302-cf3f-b8de73119061"
      },
      "source": [
        "pip install tensorflow_text"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_text\n",
            "  Downloading tensorflow_text-2.7.3-cp37-cp37m-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<2.8,>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.19.5)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.22.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (12.0.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.1.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.42.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.37.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.13.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.10.0.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.8.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.35.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.1.1)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-2.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85eb7211"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.preprocessing.sequence as sequence\n",
        "import tensorflow_text as tf_text\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c34550c"
      },
      "source": [
        "# Change the directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94b2626e"
      },
      "source": [
        "working_directory = '/content/drive/My Drive/Colab Notebooks/OVGU/Deep_Learning/07_Assignment'\n",
        "def colabDrive():\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "\n",
        "    if os.getcwd() !=  working_directory:\n",
        "      os.chdir(working_directory)\n",
        "    print(os.getcwd())"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8540ed4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7560c3f1-68b0-4be6-fe77-91a344f82e97"
      },
      "source": [
        "colabDrive()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/Colab Notebooks/OVGU/Deep_Learning/07_Assignment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjeunnuphktY"
      },
      "source": [
        "# Preamble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHbpSCdw8qnW"
      },
      "source": [
        "## Helper function which can be used to check the shapes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M15xw1ve8teI"
      },
      "source": [
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    if isinstance(names, str):\n",
        "      names = (names,)\n",
        "\n",
        "    shape = tf.shape(tensor)\n",
        "    rank = tf.rank(tensor)\n",
        "\n",
        "    if rank != len(names):\n",
        "      raise ValueError(f'Rank mismatch:\\n'\n",
        "                       f'    found {rank}: {shape.numpy()}\\n'\n",
        "                       f'    expected {len(names)}: {names}\\n')\n",
        "\n",
        "    for i, name in enumerate(names):\n",
        "      if isinstance(name, int):\n",
        "        old_dim = name\n",
        "      else:\n",
        "        old_dim = self.shapes.get(name, None)\n",
        "      new_dim = shape[i]\n",
        "\n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh0bPt7wkCHt"
      },
      "source": [
        "## A function that will read the data and return"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvTtHPvjhqBC"
      },
      "source": [
        "def load_data(path):\n",
        "  # text = path.read_text(encoding='utf-8')\n",
        "  with open(\"tel-eng/tel.txt\", \"r\", encoding='utf-8') as tel:\n",
        "     telugu=tel.read()\n",
        "\n",
        "  lines = telugu.splitlines()\n",
        "  pairs = [line.split('\\t')[:-1] for line in lines]\n",
        "\n",
        "  inp = [inp for targ, inp in pairs]\n",
        "  targ = [targ for targ, inp in pairs]\n",
        "\n",
        "  return targ, inp"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cOKg7mXhtw5"
      },
      "source": [
        "targ, inp = load_data(\"tel-eng/tel.txt\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoZqzF-_kMe-",
        "outputId": "f6f82fed-21ec-4a0c-ecf4-55bf1f9f8830"
      },
      "source": [
        "print(inp[-1])\n",
        "print(targ[-1])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "టామ్ తనకు తాను చేయటానికి అనుమతించకపోవచ్చని అనుకున్నాడు.\n",
            "Tom thought he might not be permitted to do that by himself.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEIAwPgokXk6"
      },
      "source": [
        "## Create dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvwzLTtIkU--"
      },
      "source": [
        "BUFFER_SIZE = len(inp)\n",
        "BATCH_SIZE = 60\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((inp, targ)).shuffle(BUFFER_SIZE)\n",
        "\n",
        "test_dataset = dataset.take(20) \n",
        "train_dataset = dataset.skip(20)\n",
        "\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.batch(20).shuffle(10, seed=45)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrxWy_-3kbCL",
        "outputId": "562eb391-3f52-42d0-94a0-525240128c83"
      },
      "source": [
        "for example_input_batch, example_target_batch in train_dataset.take(1):\n",
        "  print(example_input_batch[:5])\n",
        "  print()\n",
        "  print(example_target_batch[:5])\n",
        "  break"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'\\xe0\\xb0\\x85\\xe0\\xb0\\xa6\\xe0\\xb0\\xbf \\xe0\\xb0\\x85\\xe0\\xb0\\x82\\xe0\\xb0\\xa4 \\xe0\\xb0\\xa4\\xe0\\xb1\\x87\\xe0\\xb0\\xb2\\xe0\\xb0\\xbf\\xe0\\xb0\\x95 \\xe0\\xb0\\x95\\xe0\\xb0\\xbe\\xe0\\xb0\\xa6\\xe0\\xb1\\x81, \\xe0\\xb0\\xa4\\xe0\\xb1\\x86\\xe0\\xb0\\xb2\\xe0\\xb1\\x81\\xe0\\xb0\\xb8\\xe0\\xb0\\xbe'\n",
            " b'\\xe0\\xb0\\xa8\\xe0\\xb1\\x81\\xe0\\xb0\\xb5\\xe0\\xb1\\x8d\\xe0\\xb0\\xb5\\xe0\\xb1\\x81 \\xe0\\xb0\\x97\\xe0\\xb0\\x9f\\xe0\\xb1\\x8d\\xe0\\xb0\\x9f\\xe0\\xb0\\xbf\\xe0\\xb0\\x97\\xe0\\xb0\\xbe \\xe0\\xb0\\xae\\xe0\\xb0\\xbe\\xe0\\xb0\\x9f\\xe0\\xb1\\x8d\\xe0\\xb0\\xb2\\xe0\\xb0\\xbe\\xe0\\xb0\\xa1\\xe0\\xb0\\xbe\\xe0\\xb0\\xb2\\xe0\\xb0\\xbf'\n",
            " b'\\xe0\\xb0\\x9f\\xe0\\xb0\\xbe\\xe0\\xb0\\xae\\xe0\\xb1\\x8d \\xe0\\xb0\\xae\\xe0\\xb0\\xb0\\xe0\\xb0\\xbf\\xe0\\xb0\\xaf\\xe0\\xb1\\x81 \\xe0\\xb0\\xa8\\xe0\\xb1\\x87\\xe0\\xb0\\xa8\\xe0\\xb1\\x81 \\xe0\\xb0\\xa4\\xe0\\xb0\\xb0\\xe0\\xb0\\x9a\\xe0\\xb1\\x81\\xe0\\xb0\\x97\\xe0\\xb0\\xbe \\xe0\\xb0\\xac\\xe0\\xb0\\xb8\\xe0\\xb1\\x8d\\xe0\\xb0\\xb8\\xe0\\xb1\\x81\\xe0\\xb0\\xb2\\xe0\\xb1\\x8b \\xe0\\xb0\\xae\\xe0\\xb1\\x81\\xe0\\xb0\\x9a\\xe0\\xb1\\x8d\\xe0\\xb0\\x9a\\xe0\\xb0\\x9f\\xe0\\xb0\\xbf\\xe0\\xb0\\xb8\\xe0\\xb1\\x8d\\xe0\\xb0\\xa4\\xe0\\xb1\\x81\\xe0\\xb0\\x82\\xe0\\xb0\\x9f\\xe0\\xb0\\xbe\\xe0\\xb0\\xae\\xe0\\xb1\\x81.'\n",
            " b'\\xe0\\xb0\\xb5\\xe0\\xb1\\x8a\\xe0\\xb0\\x82\\xe0\\xb0\\x9f\\xe0\\xb1\\x8d\\xe0\\xb0\\xb2\\xe0\\xb1\\x8b \\xe0\\xb0\\x8e\\xe0\\xb0\\xb2\\xe0\\xb0\\xbe \\xe0\\xb0\\xb5\\xe0\\xb1\\x81\\xe0\\xb0\\x82\\xe0\\xb0\\xa6\\xe0\\xb0\\xbf'\n",
            " b'\\xe0\\xb0\\x87\\xe0\\xb0\\xa6\\xe0\\xb0\\x82\\xe0\\xb0\\xa4\\xe0\\xb0\\xbe \\xe0\\xb0\\xa8\\xe0\\xb0\\xbf\\xe0\\xb0\\x9c\\xe0\\xb0\\x82\\xe0\\xb0\\x97\\xe0\\xb0\\xbe \\xe0\\xb0\\x9c\\xe0\\xb0\\xb0\\xe0\\xb0\\xbf\\xe0\\xb0\\x97\\xe0\\xb0\\xbf\\xe0\\xb0\\x82\\xe0\\xb0\\xa6\\xe0\\xb0\\xbe ?'], shape=(5,), dtype=string)\n",
            "\n",
            "tf.Tensor(\n",
            "[b\"That wasn't easy, you know.\" b'You must speak in a loud voice.'\n",
            " b'Tom and I often chat on the bus.' b'Are you feeling OK?'\n",
            " b'Did all this really happen?'], shape=(5,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6LD6RwikuOw"
      },
      "source": [
        "## Unicode Normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpgbPhcfkw4V"
      },
      "source": [
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accecented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Keep space, a to z, ఀ-౿(telugu text) and select punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[^ a-z$ఀ-౿.?!,¿]', '')\n",
        "  # Add spaces around punctuation.\n",
        "  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UKOUGEX0Z75"
      },
      "source": [
        "## Text Vectorization\n",
        "\n",
        "Creating a word to index dictionary and an index to word dictionary for all unique source and target words in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1JQ2_On36HO"
      },
      "source": [
        "### For Telugu language"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnStPmuy0ci5",
        "outputId": "600721b6-ff39-4ced-bd5d-d11aa8610e80"
      },
      "source": [
        "max_vocab_size = 5000\n",
        "\n",
        "input_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size)\n",
        "\n",
        "input_text_processor.adapt(inp)\n",
        "\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "input_text_processor.get_vocabulary()[:10]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', '[START]', '[END]', '?', '.', 'నువ్వు', 'నేను', 'అది', 'నాకు']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LiDrt7y3-lW"
      },
      "source": [
        "### For English language"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2n7U_B00ebs",
        "outputId": "dde2c01a-b40f-4157-d94e-646fa1d8fb47"
      },
      "source": [
        "output_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size)\n",
        "\n",
        "output_text_processor.adapt(targ)\n",
        "output_text_processor.get_vocabulary()[:10]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', '[START]', '[END]', '.', 'you', '?', 'to', 'i', 'the']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQujLhNg4BrF"
      },
      "source": [
        "### See some tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DubharMb1QAt",
        "outputId": "c263adb5-1811-455c-d271-f6a0f7094155"
      },
      "source": [
        "example_inp_tokens = input_text_processor('నువ్వు అది చూసావా?')\n",
        "example_inp_tokens"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(6,), dtype=int64, numpy=array([  2,   6,   8, 311,   4,   3])>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ef80Q88-1aEa",
        "outputId": "1f9a1a57-17c6-478a-f43c-2e3a865acbdc"
      },
      "source": [
        "example_tar_tokens = output_text_processor('Can you see that?')\n",
        "example_tar_tokens"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(7,), dtype=int64, numpy=array([  2,  30,   5, 199,  10,   6,   3])>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BWNVkXh74dU"
      },
      "source": [
        "## Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Z-Q4E8A78xB"
      },
      "source": [
        "embedding_dim = 256\n",
        "units = 1024"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HCh9PfH4oZK"
      },
      "source": [
        "# Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfVSM8z87_ok"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, input_vocab_size, embedding_dim, enc_units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.enc_units = enc_units\n",
        "    self.input_vocab_size = input_vocab_size\n",
        "\n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.input_vocab_size,\n",
        "                                               embedding_dim)\n",
        "\n",
        "    # The GRU RNN layer processes those vectors sequentially.\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   # Return the sequence and state\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, tokens, state=None):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(tokens, ('batch', 's'))\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding for each token.\n",
        "    vectors = self.embedding(tokens)\n",
        "    shape_checker(vectors, ('batch', 's', 'embed_dim'))\n",
        "\n",
        "    # 3. The GRU processes the embedding sequence.\n",
        "    #    output shape: (batch, s, enc_units)\n",
        "    #    state shape: (batch, enc_units)\n",
        "    output, state = self.gru(vectors, initial_state=state)\n",
        "    shape_checker(output, ('batch', 's', 'enc_units'))\n",
        "    shape_checker(state, ('batch', 'enc_units'))\n",
        "\n",
        "    # 4. Returns the new sequence and its state.\n",
        "    return output, state"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaAwgen08g35",
        "outputId": "f22ab6f3-4d95-468e-9e51-6d50435f0007"
      },
      "source": [
        "# Convert the input text to tokens.\n",
        "example_tokens = input_text_processor(example_input_batch)\n",
        "\n",
        "# Encode the input sequence.\n",
        "encoder = Encoder(input_text_processor.vocabulary_size(),\n",
        "                  embedding_dim, units)\n",
        "example_enc_output, example_enc_state = encoder(example_tokens)\n",
        "\n",
        "print(f'Input batch, shape (batch): {example_input_batch.shape}')\n",
        "print(f'Input batch tokens, shape (batch, s): {example_tokens.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {example_enc_output.shape}')\n",
        "print(f'Encoder state, shape (batch, units): {example_enc_state.shape}')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input batch, shape (batch): (60,)\n",
            "Input batch tokens, shape (batch, s): (60, 10)\n",
            "Encoder output, shape (batch, s, units): (60, 10, 1024)\n",
            "Encoder state, shape (batch, units): (60, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7reyM4fc4rmJ"
      },
      "source": [
        "# Attention Layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijN0V-aI46-x"
      },
      "source": [
        "## Bahdanau Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nMlsrbr4ud7"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super().__init__()\n",
        "    # For Eqn. (4), the  Bahdanau attention\n",
        "    self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "    self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "\n",
        "    self.attention = tf.keras.layers.AdditiveAttention()\n",
        "\n",
        "  def call(self, query, value, mask):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(query, ('batch', 't', 'query_units'))\n",
        "    shape_checker(value, ('batch', 's', 'value_units'))\n",
        "    shape_checker(mask, ('batch', 's'))\n",
        "\n",
        "    # From Eqn. (4), `W1@ht`.\n",
        "    w1_query = self.W1(query)\n",
        "    shape_checker(w1_query, ('batch', 't', 'attn_units'))\n",
        "\n",
        "    # From Eqn. (4), `W2@hs`.\n",
        "    w2_key = self.W2(value)\n",
        "    shape_checker(w2_key, ('batch', 's', 'attn_units'))\n",
        "\n",
        "    query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
        "    value_mask = mask\n",
        "\n",
        "    context_vector, attention_weights = self.attention(\n",
        "        inputs = [w1_query, value, w2_key],\n",
        "        mask=[query_mask, value_mask],\n",
        "        return_attention_scores = True,\n",
        "    )\n",
        "    shape_checker(context_vector, ('batch', 't', 'value_units'))\n",
        "    shape_checker(attention_weights, ('batch', 't', 's'))\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwXBo95d5Puv"
      },
      "source": [
        "attention_layer = BahdanauAttention(units)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az3SlShz5caC",
        "outputId": "b9fbd6a2-6e1f-4986-c7f7-02088af3abf5"
      },
      "source": [
        "# Later, the decoder will generate this attention query\n",
        "example_attention_query = tf.random.normal(shape=[len(example_tokens), 2, 10])\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "\n",
        "context_vector, attention_weights = attention_layer(\n",
        "    query=example_attention_query,\n",
        "    value=example_enc_output,\n",
        "    mask=(example_tokens != 0))\n",
        "\n",
        "print(f'Attention result shape: (batch_size, query_seq_length, units):           {context_vector.shape}')\n",
        "print(f'Attention weights shape: (batch_size, query_seq_length, value_seq_length): {attention_weights.shape}')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention result shape: (batch_size, query_seq_length, units):           (60, 2, 1024)\n",
            "Attention weights shape: (batch_size, query_seq_length, value_seq_length): (60, 2, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "459_QH_87E7C"
      },
      "source": [
        "## Luong Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOjR5XXC5E5n"
      },
      "source": [
        "class LuongAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super().__init__()\n",
        "    # For Eqn. (4), the  Luong attention\n",
        "    self.W = tf.keras.layers.Dense(units, use_bias=False)\n",
        "\n",
        "    self.attention = tf.keras.layers.Attention()\n",
        "\n",
        "  def call(self, query, value, mask):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(query, ('batch', 't', 'query_units'))\n",
        "    shape_checker(value, ('batch', 's', 'value_units'))\n",
        "    shape_checker(mask, ('batch', 's'))\n",
        "\n",
        "    # # From Eqn. (4), `W@ht`.\n",
        "    w_query = self.W(query)\n",
        "    shape_checker(w_query, ('batch', 't', 'attn_units'))\n",
        "\n",
        "    query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
        "    value_mask = mask\n",
        "\n",
        "    context_vector, attention_weights = self.attention(\n",
        "        inputs = [w_query, value],\n",
        "        mask=[query_mask, value_mask],\n",
        "        return_attention_scores = True,\n",
        "    )\n",
        "    shape_checker(context_vector, ('batch', 't', 'value_units'))\n",
        "    shape_checker(attention_weights, ('batch', 't', 's'))\n",
        "\n",
        "    return context_vector, attention_weights"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Etu8-L8Y6VK3"
      },
      "source": [
        "luongattention_layer = LuongAttention(units)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKeZRPns6aWE",
        "outputId": "8179f1c3-8415-44e3-9fa5-7a336ae0f7c1"
      },
      "source": [
        "# Later, the decoder will generate this attention query\n",
        "example_attention_query = tf.random.normal(shape=[len(example_tokens), 2, 10])\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "\n",
        "context_vector, attention_weights = luongattention_layer(\n",
        "    query=example_attention_query,\n",
        "    value=example_enc_output,\n",
        "    mask=(example_tokens != 0))\n",
        "\n",
        "print(f'Attention result shape: (batch_size, query_seq_length, units):           {context_vector.shape}')\n",
        "print(f'Attention weights shape: (batch_size, query_seq_length, value_seq_length): {attention_weights.shape}')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attention result shape: (batch_size, query_seq_length, units):           (60, 2, 1024)\n",
            "Attention weights shape: (batch_size, query_seq_length, value_seq_length): (60, 2, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE7o0uJU4rh2"
      },
      "source": [
        "# Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2LzXKtk6JtR"
      },
      "source": [
        "class DecoderInput(typing.NamedTuple):\n",
        "  new_tokens: Any\n",
        "  enc_output: Any\n",
        "  mask: Any\n",
        "\n",
        "class DecoderOutput(typing.NamedTuple):\n",
        "  logits: Any\n",
        "  attention_weights: Any"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xq5z9qVo50Wt"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, output_vocab_size, embedding_dim, dec_units, att_Layer='B'):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.dec_units = dec_units\n",
        "    self.output_vocab_size = output_vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "\n",
        "    # For Step 1. The embedding layer convets token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.output_vocab_size,\n",
        "                                               embedding_dim)\n",
        "\n",
        "    # For Step 2. The RNN keeps track of what's been generated so far.\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # For step 3. The RNN output will be the query for the attention layer.\n",
        "    if att_Layer == 'B':\n",
        "      self.attention = BahdanauAttention(self.dec_units)\n",
        "    elif att_Layer == 'L':\n",
        "      self.attention = LuongAttention(self.dec_units)\n",
        "    # For step 4. Eqn. (3): converting `ct` to `at`\n",
        "    self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\n",
        "                                    use_bias=False)\n",
        "\n",
        "    # For step 5. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.fc = tf.keras.layers.Dense(self.output_vocab_size)\n",
        "\n",
        "  def call(self,\n",
        "         inputs: DecoderInput,\n",
        "         state=None) -> Tuple[DecoderOutput, tf.Tensor]:\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(inputs.new_tokens, ('batch', 't'))\n",
        "    shape_checker(inputs.enc_output, ('batch', 's', 'enc_units'))\n",
        "    shape_checker(inputs.mask, ('batch', 's'))\n",
        "\n",
        "    if state is not None:\n",
        "      shape_checker(state, ('batch', 'dec_units'))\n",
        "\n",
        "    # Step 1. Lookup the embeddings\n",
        "    vectors = self.embedding(inputs.new_tokens)\n",
        "    shape_checker(vectors, ('batch', 't', 'embedding_dim'))\n",
        "\n",
        "    # Step 2. Process one step with the RNN\n",
        "    rnn_output, state = self.gru(vectors, initial_state=state)\n",
        "\n",
        "    shape_checker(rnn_output, ('batch', 't', 'dec_units'))\n",
        "    shape_checker(state, ('batch', 'dec_units'))\n",
        "\n",
        "    # Step 3. Use the RNN output as the query for the attention over the\n",
        "    # encoder output.\n",
        "    context_vector, attention_weights = self.attention(\n",
        "        query=rnn_output, value=inputs.enc_output, mask=inputs.mask)\n",
        "    shape_checker(context_vector, ('batch', 't', 'dec_units'))\n",
        "    shape_checker(attention_weights, ('batch', 't', 's'))\n",
        "\n",
        "    # Step 4. Eqn. (3): Join the context_vector and rnn_output\n",
        "    #     [ct; ht] shape: (batch t, value_units + query_units)\n",
        "    context_and_rnn_output = tf.concat([context_vector, rnn_output], axis=-1)\n",
        "\n",
        "    # Step 4. Eqn. (3): `at = tanh(Wc@[ct; ht])`\n",
        "    attention_vector = self.Wc(context_and_rnn_output)\n",
        "    shape_checker(attention_vector, ('batch', 't', 'dec_units'))\n",
        "\n",
        "    # Step 5. Generate logit predictions:\n",
        "    logits = self.fc(attention_vector)\n",
        "    shape_checker(logits, ('batch', 't', 'output_vocab_size'))\n",
        "\n",
        "    return DecoderOutput(logits, attention_weights), state"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwSvsa4R56GQ"
      },
      "source": [
        "decoder = Decoder(output_text_processor.vocabulary_size(),\n",
        "                  embedding_dim, units)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQpJ5Xej607m"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQI6bl3P65rr"
      },
      "source": [
        "## Loss function\n",
        "\n",
        "Summary:\n",
        "\n",
        "\n",
        "*   Sparse Categorical crossentropy is the loss function\n",
        "*   Not computing the loss where padding is applied\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOPAFtbb637r"
      },
      "source": [
        "class MaskedLoss(tf.keras.losses.Loss):\n",
        "  def __init__(self):\n",
        "    self.name = 'masked_loss'\n",
        "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "\n",
        "  def __call__(self, y_true, y_pred):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(y_true, ('batch', 't'))\n",
        "    shape_checker(y_pred, ('batch', 't', 'logits'))\n",
        "\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss = self.loss(y_true, y_pred)\n",
        "    shape_checker(loss, ('batch', 't'))\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    shape_checker(mask, ('batch', 't'))\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcnrzfLV6_BN"
      },
      "source": [
        "## Train Model\n",
        "\n",
        "Summary\n",
        "\n",
        "\n",
        "1.   A constructor which will initialise Encoder, Decoder etc\n",
        "2.   A **train_step** function which will choose which function to run whether the train step function which is wrapped with tf or the normal train step function.\n",
        "3.   A  **_preprocess** function which will preprocess the data.\n",
        "4.   A  **_train_step** function.\n",
        "5.   A  **_tf_train_step** function wrapped like a tf function.\n",
        "6.   A  **_loop_step** function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjNgJCTe7Bb_"
      },
      "source": [
        "class TrainTranslator(tf.keras.Model):\n",
        "  ## --------------------------------------------------Start of the Constructor----------------------------------------------------------\n",
        "  def __init__(self, embedding_dim, units,\n",
        "               input_text_processor,\n",
        "               output_text_processor, \n",
        "               use_tf_function=True,\n",
        "               att_Layer='B'):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(input_text_processor.vocabulary_size(),\n",
        "                      embedding_dim, units)\n",
        "    decoder = Decoder(output_text_processor.vocabulary_size(),\n",
        "                      embedding_dim, units, att_Layer)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.input_text_processor = input_text_processor\n",
        "    self.output_text_processor = output_text_processor\n",
        "    self.use_tf_function = use_tf_function\n",
        "    self.shape_checker = ShapeChecker()\n",
        "  ## --------------------------------------------------End of the Constructor----------------------------------------------------------\n",
        "\n",
        "  ## --------------------------------------------------Start of the train step----------------------------------------------------------\n",
        "  #Choose which train step to run\n",
        "  def train_step(self, inputs):\n",
        "    self.shape_checker = ShapeChecker()\n",
        "    if self.use_tf_function:\n",
        "      return self._tf_train_step(inputs)\n",
        "    else:\n",
        "      return self._train_step(inputs)\n",
        "  ## --------------------------------------------------End of the train step----------------------------------------------------------\n",
        "\n",
        "  ## --------------------------------------------------Start of the Preprocess data function----------------------------------------------------------\n",
        "  def _preprocess(self, input_text, target_text):\n",
        "    self.shape_checker(input_text, ('batch',))\n",
        "    self.shape_checker(target_text, ('batch',))\n",
        "\n",
        "    # Convert the text to token IDs\n",
        "    input_tokens = self.input_text_processor(input_text)\n",
        "    target_tokens = self.output_text_processor(target_text)\n",
        "    self.shape_checker(input_tokens, ('batch', 's'))\n",
        "    self.shape_checker(target_tokens, ('batch', 't'))\n",
        "\n",
        "    # Convert IDs to masks.\n",
        "    input_mask = input_tokens != 0\n",
        "    self.shape_checker(input_mask, ('batch', 's'))\n",
        "\n",
        "    target_mask = target_tokens != 0\n",
        "    self.shape_checker(target_mask, ('batch', 't'))\n",
        "\n",
        "    return input_tokens, input_mask, target_tokens, target_mask\n",
        "  ## --------------------------------------------------End of the Preprocess data function----------------------------------------------------------\n",
        "\n",
        "  ## --------------------------------------------------Start of the train step function definition----------------------------------------------------------\n",
        "  def _train_step(self, inputs):\n",
        "    input_text, target_text = inputs  \n",
        "\n",
        "    (input_tokens, input_mask,\n",
        "    target_tokens, target_mask) = self._preprocess(input_text, target_text)\n",
        "\n",
        "    max_target_length = tf.shape(target_tokens)[1]\n",
        "    \n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      # Encode the input\n",
        "      enc_output, enc_state = self.encoder(input_tokens)\n",
        "      self.shape_checker(enc_output, ('batch', 's', 'enc_units'))\n",
        "      self.shape_checker(enc_state, ('batch', 'enc_units'))\n",
        "\n",
        "      # Initialize the decoder's state to the encoder's final state.\n",
        "      # This only works if the encoder and decoder have the same number of\n",
        "      # units.\n",
        "      dec_state = enc_state\n",
        "      loss = tf.constant(0.0)\n",
        "\n",
        "      for t in tf.range(max_target_length-1):\n",
        "        # Pass in two tokens from the target sequence:\n",
        "        # 1. The current input to the decoder.\n",
        "        # 2. The target for the decoder's next prediction.\n",
        "        new_tokens = target_tokens[:, t:t+2]\n",
        "        step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
        "                                              enc_output, dec_state)\n",
        "        loss = loss + step_loss\n",
        "\n",
        "      # Average the loss over all non padding tokens.\n",
        "      average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
        "\n",
        "\n",
        "    # Apply an optimization step\n",
        "    variables = self.trainable_variables \n",
        "    gradients = tape.gradient(average_loss, variables)\n",
        "    self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    # Return a dict mapping metric names to current value\n",
        "    return {'batch_loss': average_loss}\n",
        "  ## --------------------------------------------------End of the train step function definition----------------------------------------------------------\n",
        "\n",
        "\n",
        "  ## --------------------------------------------------Start of the test step evaluate function definition----------------------------------------------------------\n",
        "  @tf.function(input_signature=[[tf.TensorSpec(dtype=tf.string, shape=[None]),\n",
        "                               tf.TensorSpec(dtype=tf.string, shape=[None])]])\n",
        "  def _test_step(self, inputs):\n",
        "    input_text, target_text = inputs  \n",
        "    \n",
        "    (input_tokens, input_mask,\n",
        "    target_tokens, target_mask) = self._preprocess(input_text, target_text)\n",
        "\n",
        "    max_target_length = tf.shape(target_tokens)[1]\n",
        "    \n",
        "    # Encode the input\n",
        "    enc_output, enc_state = self.encoder(input_tokens)\n",
        "    self.shape_checker(enc_output, ('batch', 's', 'enc_units'))\n",
        "    self.shape_checker(enc_state, ('batch', 'enc_units'))\n",
        "\n",
        "    # Initialize the decoder's state to the encoder's final state.\n",
        "    # This only works if the encoder and decoder have the same number of\n",
        "    # units.\n",
        "    dec_state = enc_state\n",
        "    loss = tf.constant(0.0)\n",
        "\n",
        "    for t in tf.range(max_target_length-1):\n",
        "      # Pass in two tokens from the target sequence:\n",
        "      # 1. The current input to the decoder.\n",
        "      # 2. The target for the decoder's next prediction.\n",
        "      new_tokens = target_tokens[:, t:t+2]\n",
        "      step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
        "                                            enc_output, dec_state)\n",
        "      loss = loss + step_loss\n",
        "\n",
        "    # Average the loss over all non padding tokens.\n",
        "    average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
        "\n",
        "    # Return a dict mapping metric names to current value\n",
        "    return {'batch_loss': average_loss}\n",
        "  ## --------------------------------------------------End of the test step evaluate function definition----------------------------------------------------------\n",
        "\n",
        "  ## --------------------------------------------------Start of the tf train step function ----------------------------------------------------------\n",
        "  # wrap train step into tf function to speed up the process\n",
        "  @tf.function(input_signature=[[tf.TensorSpec(dtype=tf.string, shape=[None]),\n",
        "                               tf.TensorSpec(dtype=tf.string, shape=[None])]])\n",
        "  def _tf_train_step(self, inputs):\n",
        "    return self._train_step(inputs)\n",
        "  ## --------------------------------------------------Start of the tf train step function ----------------------------------------------------------\n",
        "\n",
        "\n",
        "  ## --------------------------------------------------Start of the train loop function----------------------------------------------------------\n",
        "  #The _loop_step method, added below, executes the decoder and calculates the incremental loss and new decoder state (dec_state).\n",
        "  def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n",
        "    input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n",
        "\n",
        "    # Run the decoder one step.\n",
        "    decoder_input = DecoderInput(new_tokens=input_token,\n",
        "                                enc_output=enc_output,\n",
        "                                mask=input_mask)\n",
        "\n",
        "    dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n",
        "    self.shape_checker(dec_result.logits, ('batch', 't1', 'logits'))\n",
        "    self.shape_checker(dec_result.attention_weights, ('batch', 't1', 's'))\n",
        "    self.shape_checker(dec_state, ('batch', 'dec_units'))\n",
        "\n",
        "    # `self.loss` returns the total for non-padded tokens\n",
        "    y = target_token\n",
        "    y_pred = dec_result.logits\n",
        "    step_loss = self.loss(y, y_pred)\n",
        "\n",
        "    return step_loss, dec_state\n",
        "   ## --------------------------------------------------End of the train loop function----------------------------------------------------------"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIWxhEMq-hxK"
      },
      "source": [
        "## Test the Model to see whether it works or not for a single batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PBoLFRi7k-P"
      },
      "source": [
        "translator = TrainTranslator(\n",
        "    embedding_dim, units,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        "    use_tf_function=True,\n",
        "    att_Layer='B')\n",
        "\n",
        "# Configure the loss and optimizer\n",
        "translator.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=MaskedLoss(),\n",
        ")"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "923fPXrO9Gz9",
        "outputId": "c1ae74c6-437b-4282-f4b6-4561e4046c25"
      },
      "source": [
        "losses = []\n",
        "for n in range(100):\n",
        "  print('.', end='')\n",
        "  logs = translator.train_step([example_input_batch, example_target_batch])\n",
        "  losses.append(logs['batch_loss'].numpy())\n",
        "\n",
        "print()\n",
        "plt.plot(losses)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "....................................................................................................\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe691a8f690>]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_InTuIU-lTG"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GTgPppn8XVy"
      },
      "source": [
        "### Bahdanau's Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIJF1cdi-pbe"
      },
      "source": [
        "train_translator_B = TrainTranslator(\n",
        "    embedding_dim, units,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        "    use_tf_function=True,\n",
        "    att_Layer='B')\n",
        "\n",
        "# Configure the loss and optimizer\n",
        "train_translator_B.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=MaskedLoss(),\n",
        ")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuAmK76A_BX0"
      },
      "source": [
        "class BatchLogs_B(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, key):\n",
        "    self.key = key\n",
        "    self.logs = []\n",
        "\n",
        "  def on_train_batch_end(self, n, logs):\n",
        "    self.logs.append(logs[self.key])\n",
        "\n",
        "batch_loss_B = BatchLogs_B('batch_loss')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pliFuhCm_DP7",
        "outputId": "09b9c02c-6dcf-48d2-a8c3-a874029d499b"
      },
      "source": [
        "train_translator_B.fit(train_dataset, epochs=100, callbacks=[batch_loss_B])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 7s 244ms/step - batch_loss: 5.1957\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 227ms/step - batch_loss: 4.8789\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 259ms/step - batch_loss: 4.7723\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 242ms/step - batch_loss: 4.3039\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 189ms/step - batch_loss: 4.3734\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 253ms/step - batch_loss: 4.1543\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 192ms/step - batch_loss: 3.9037\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 233ms/step - batch_loss: 3.9529\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 256ms/step - batch_loss: 3.7764\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 196ms/step - batch_loss: 3.6801\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 240ms/step - batch_loss: 3.6478\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 188ms/step - batch_loss: 3.5413\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 187ms/step - batch_loss: 3.5487\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 219ms/step - batch_loss: 3.4651\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 196ms/step - batch_loss: 3.4156\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 254ms/step - batch_loss: 3.3696\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 254ms/step - batch_loss: 3.3287\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 186ms/step - batch_loss: 3.2568\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 184ms/step - batch_loss: 3.1742\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 182ms/step - batch_loss: 3.1518\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 248ms/step - batch_loss: 3.0650\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 206ms/step - batch_loss: 2.9262\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 246ms/step - batch_loss: 2.9246\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 204ms/step - batch_loss: 2.8408\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 211ms/step - batch_loss: 2.7040\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 246ms/step - batch_loss: 2.6222\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 219ms/step - batch_loss: 2.5666\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 183ms/step - batch_loss: 2.4723\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 200ms/step - batch_loss: 2.3253\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 256ms/step - batch_loss: 2.2212\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 248ms/step - batch_loss: 2.1981\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 213ms/step - batch_loss: 2.0445\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 210ms/step - batch_loss: 1.9535\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 249ms/step - batch_loss: 1.9012\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 246ms/step - batch_loss: 1.7847\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 188ms/step - batch_loss: 1.6765\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 237ms/step - batch_loss: 1.5796\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 229ms/step - batch_loss: 1.4317\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 195ms/step - batch_loss: 1.3606\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 214ms/step - batch_loss: 1.2637\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 196ms/step - batch_loss: 1.1413\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 211ms/step - batch_loss: 1.0219\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 255ms/step - batch_loss: 0.9356\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 230ms/step - batch_loss: 0.8263\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 173ms/step - batch_loss: 0.7647\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 238ms/step - batch_loss: 0.6644\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 240ms/step - batch_loss: 0.5713\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 238ms/step - batch_loss: 0.5202\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 172ms/step - batch_loss: 0.4529\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 259ms/step - batch_loss: 0.4019\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 253ms/step - batch_loss: 0.3643\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 195ms/step - batch_loss: 0.3051\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 212ms/step - batch_loss: 0.2791\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 251ms/step - batch_loss: 0.2184\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 190ms/step - batch_loss: 0.1977\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 188ms/step - batch_loss: 0.1717\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 257ms/step - batch_loss: 0.1435\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 174ms/step - batch_loss: 0.1318\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 240ms/step - batch_loss: 0.1150\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 238ms/step - batch_loss: 0.1036\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 240ms/step - batch_loss: 0.0822\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 242ms/step - batch_loss: 0.0721\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 205ms/step - batch_loss: 0.0640\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 246ms/step - batch_loss: 0.0520\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 197ms/step - batch_loss: 0.0489\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 246ms/step - batch_loss: 0.0417\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 206ms/step - batch_loss: 0.0412\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 222ms/step - batch_loss: 0.0414\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 253ms/step - batch_loss: 0.0309\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 240ms/step - batch_loss: 0.0290\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 224ms/step - batch_loss: 0.0255\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 247ms/step - batch_loss: 0.0235\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 250ms/step - batch_loss: 0.0214\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 251ms/step - batch_loss: 0.0190\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 183ms/step - batch_loss: 0.0189\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 251ms/step - batch_loss: 0.0172\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 212ms/step - batch_loss: 0.0157\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 241ms/step - batch_loss: 0.0149\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 250ms/step - batch_loss: 0.0140\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 192ms/step - batch_loss: 0.0134\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 234ms/step - batch_loss: 0.0121\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 242ms/step - batch_loss: 0.0117\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 224ms/step - batch_loss: 0.0112\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 209ms/step - batch_loss: 0.0107\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 219ms/step - batch_loss: 0.0102\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 193ms/step - batch_loss: 0.0117\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 209ms/step - batch_loss: 0.0096\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 205ms/step - batch_loss: 0.0090\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 187ms/step - batch_loss: 0.0090\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 191ms/step - batch_loss: 0.0089\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 248ms/step - batch_loss: 0.0081\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 197ms/step - batch_loss: 0.0078\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 246ms/step - batch_loss: 0.0079\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 188ms/step - batch_loss: 0.0076\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 229ms/step - batch_loss: 0.0072\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 247ms/step - batch_loss: 0.0072\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 237ms/step - batch_loss: 0.0069\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 226ms/step - batch_loss: 0.0067\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 243ms/step - batch_loss: 0.0065\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 191ms/step - batch_loss: 0.0065\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe7104bf1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFCAm2xqAdx4",
        "outputId": "3ae6d90c-01c7-456f-8a42-79cb4e1720fc"
      },
      "source": [
        "losses = []\n",
        "for test_input_batch, test_target_batch in test_dataset:\n",
        "  logs = train_translator_B._test_step([test_input_batch, test_target_batch])\n",
        "  losses.append(logs['batch_loss'].numpy())\n",
        "print(\"Test loss: \",losses)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss:  [0.0064684595]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5kjXuzK8cim"
      },
      "source": [
        "### Luong Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fBne53N8gLA"
      },
      "source": [
        "train_translator_L = TrainTranslator(\n",
        "    embedding_dim, units,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        "    use_tf_function=True,\n",
        "    att_Layer='L')\n",
        "\n",
        "# Configure the loss and optimizer\n",
        "train_translator_L.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=MaskedLoss(),\n",
        ")"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LfDJdNj_t4M"
      },
      "source": [
        "class BatchLogs_L(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, key):\n",
        "    self.key = key\n",
        "    self.logs = []\n",
        "\n",
        "  def on_train_batch_end(self, n, logs):\n",
        "    self.logs.append(logs[self.key])\n",
        "\n",
        "batch_loss_L = BatchLogs_L('batch_loss')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPLHKQaL8j_v",
        "outputId": "cb868c8c-5f1a-4cb1-927c-7d236284adec"
      },
      "source": [
        "train_translator_L.fit(train_dataset, epochs=100, callbacks=[batch_loss_L])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 7s 202ms/step - batch_loss: 5.1830\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 176ms/step - batch_loss: 4.9079\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 173ms/step - batch_loss: 4.5130\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 181ms/step - batch_loss: 4.2340\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 223ms/step - batch_loss: 4.2321\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 181ms/step - batch_loss: 3.9830\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 201ms/step - batch_loss: 3.9936\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 207ms/step - batch_loss: 3.8047\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 202ms/step - batch_loss: 3.7360\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 167ms/step - batch_loss: 3.6657\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 184ms/step - batch_loss: 3.6470\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 215ms/step - batch_loss: 3.5550\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 204ms/step - batch_loss: 3.4777\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 199ms/step - batch_loss: 3.4937\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 192ms/step - batch_loss: 3.3840\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 214ms/step - batch_loss: 3.3459\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 225ms/step - batch_loss: 3.2830\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 178ms/step - batch_loss: 3.2004\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 208ms/step - batch_loss: 3.1478\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 187ms/step - batch_loss: 3.0363\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 181ms/step - batch_loss: 2.9569\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 173ms/step - batch_loss: 2.9073\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 155ms/step - batch_loss: 2.7739\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 186ms/step - batch_loss: 2.7148\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 163ms/step - batch_loss: 2.6120\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 219ms/step - batch_loss: 2.4691\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 192ms/step - batch_loss: 2.4299\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 228ms/step - batch_loss: 2.3016\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 213ms/step - batch_loss: 2.2073\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 232ms/step - batch_loss: 2.0992\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 227ms/step - batch_loss: 2.0117\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 200ms/step - batch_loss: 1.8596\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 235ms/step - batch_loss: 1.7936\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 236ms/step - batch_loss: 1.6898\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 234ms/step - batch_loss: 1.5757\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 186ms/step - batch_loss: 1.4738\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 189ms/step - batch_loss: 1.3695\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 165ms/step - batch_loss: 1.2919\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 172ms/step - batch_loss: 1.1687\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 230ms/step - batch_loss: 1.0804\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 190ms/step - batch_loss: 0.9696\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 187ms/step - batch_loss: 0.9092\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 202ms/step - batch_loss: 0.8332\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 208ms/step - batch_loss: 0.7407\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 225ms/step - batch_loss: 0.6450\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 176ms/step - batch_loss: 0.5863\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 184ms/step - batch_loss: 0.5127\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 232ms/step - batch_loss: 0.4512\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 220ms/step - batch_loss: 0.3991\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 223ms/step - batch_loss: 0.3663\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 189ms/step - batch_loss: 0.3414\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 174ms/step - batch_loss: 0.2862\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 233ms/step - batch_loss: 0.2525\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 236ms/step - batch_loss: 0.2220\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 192ms/step - batch_loss: 0.1834\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 171ms/step - batch_loss: 0.1787\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 221ms/step - batch_loss: 0.1569\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 209ms/step - batch_loss: 0.1244\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 215ms/step - batch_loss: 0.1218\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 229ms/step - batch_loss: 0.1002\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 208ms/step - batch_loss: 0.0918\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 196ms/step - batch_loss: 0.0757\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 183ms/step - batch_loss: 0.0741\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 214ms/step - batch_loss: 0.0815\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 168ms/step - batch_loss: 0.0810\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 193ms/step - batch_loss: 0.0684\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 210ms/step - batch_loss: 0.0734\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 233ms/step - batch_loss: 0.0630\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 232ms/step - batch_loss: 0.0558\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 225ms/step - batch_loss: 0.0408\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 235ms/step - batch_loss: 0.0359\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 195ms/step - batch_loss: 0.0348\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 222ms/step - batch_loss: 0.0351\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 196ms/step - batch_loss: 0.0335\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 202ms/step - batch_loss: 0.0317\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 235ms/step - batch_loss: 0.0276\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 186ms/step - batch_loss: 0.0250\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 192ms/step - batch_loss: 0.0247\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 236ms/step - batch_loss: 0.0228\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 173ms/step - batch_loss: 0.0200\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 195ms/step - batch_loss: 0.0189\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 163ms/step - batch_loss: 0.0175\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 220ms/step - batch_loss: 0.0157\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 182ms/step - batch_loss: 0.0143\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 193ms/step - batch_loss: 0.0140\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 180ms/step - batch_loss: 0.0122\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 224ms/step - batch_loss: 0.0116\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 228ms/step - batch_loss: 0.0110\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 182ms/step - batch_loss: 0.0103\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 213ms/step - batch_loss: 0.0102\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 230ms/step - batch_loss: 0.0097\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 179ms/step - batch_loss: 0.0093\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 225ms/step - batch_loss: 0.0087\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 190ms/step - batch_loss: 0.0084\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 172ms/step - batch_loss: 0.0082\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 220ms/step - batch_loss: 0.0076\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 178ms/step - batch_loss: 0.0081\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 221ms/step - batch_loss: 0.0073\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 158ms/step - batch_loss: 0.0071\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 190ms/step - batch_loss: 0.0067\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe645fdce10>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiuJSR0b8lNe",
        "outputId": "56be6dbd-031e-439c-9f8c-0420c07b07c9"
      },
      "source": [
        "losses = []\n",
        "for test_input_batch, test_target_batch in test_dataset:\n",
        "  logs = train_translator_L._test_step([test_input_batch, test_target_batch])\n",
        "  losses.append(logs['batch_loss'].numpy())\n",
        "print(\"Test loss: \",losses)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss:  [0.0071423035]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15SEZQ5062pY"
      },
      "source": [
        "# Create a Translater"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fH9bV6qL_az8"
      },
      "source": [
        "## Translator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pboiGcpcDPww"
      },
      "source": [
        "class Translator(tf.Module):\n",
        "\n",
        "  def __init__(self, encoder, decoder, input_text_processor,\n",
        "               output_text_processor):\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.input_text_processor = input_text_processor\n",
        "    self.output_text_processor = output_text_processor\n",
        "\n",
        "    self.output_token_string_from_index = (\n",
        "        tf.keras.layers.StringLookup(\n",
        "            vocabulary=output_text_processor.get_vocabulary(),\n",
        "            mask_token='',\n",
        "            invert=True))\n",
        "\n",
        "    # The output should never generate padding, unknown, or start.\n",
        "    index_from_string = tf.keras.layers.StringLookup(\n",
        "        vocabulary=output_text_processor.get_vocabulary(), mask_token='')\n",
        "    token_mask_ids = index_from_string(['', '[UNK]', '[START]']).numpy()\n",
        "\n",
        "    token_mask = np.zeros([index_from_string.vocabulary_size()], dtype=np.bool)\n",
        "    token_mask[np.array(token_mask_ids)] = True\n",
        "    self.token_mask = token_mask\n",
        "\n",
        "    self.start_token = index_from_string(tf.constant('[START]'))\n",
        "    self.end_token = index_from_string(tf.constant('[END]'))\n",
        "\n",
        "  def tokens_to_text(self, result_tokens):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(result_tokens, ('batch', 't'))\n",
        "    result_text_tokens = self.output_token_string_from_index(result_tokens)\n",
        "    shape_checker(result_text_tokens, ('batch', 't'))\n",
        "\n",
        "    result_text = tf.strings.reduce_join(result_text_tokens,\n",
        "                                        axis=1, separator=' ')\n",
        "    shape_checker(result_text, ('batch'))\n",
        "\n",
        "    result_text = tf.strings.strip(result_text)\n",
        "    shape_checker(result_text, ('batch',))\n",
        "    return result_text\n",
        "\n",
        "  def sample(self, logits, temperature):\n",
        "    shape_checker = ShapeChecker()\n",
        "    # 't' is usually 1 here.\n",
        "    shape_checker(logits, ('batch', 't', 'vocab'))\n",
        "    shape_checker(self.token_mask, ('vocab',))\n",
        "\n",
        "    token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n",
        "    shape_checker(token_mask, ('batch', 't', 'vocab'), broadcast=True)\n",
        "\n",
        "    # Set the logits for all masked tokens to -inf, so they are never chosen.\n",
        "    logits = tf.where(self.token_mask, -np.inf, logits)\n",
        "\n",
        "    if temperature == 0.0:\n",
        "      new_tokens = tf.argmax(logits, axis=-1)\n",
        "    else: \n",
        "      logits = tf.squeeze(logits, axis=1)\n",
        "      new_tokens = tf.random.categorical(logits/temperature,\n",
        "                                          num_samples=1)\n",
        "\n",
        "    shape_checker(new_tokens, ('batch', 't'))\n",
        "\n",
        "    return new_tokens\n",
        "\n",
        "  def translate_unrolled(self,\n",
        "                       input_text, *,\n",
        "                       max_length=50,\n",
        "                       return_attention=True,\n",
        "                       temperature=1.0):\n",
        "    batch_size = tf.shape(input_text)[0]\n",
        "    input_tokens = self.input_text_processor(input_text)\n",
        "    enc_output, enc_state = self.encoder(input_tokens)\n",
        "\n",
        "    dec_state = enc_state\n",
        "    new_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "\n",
        "    result_tokens = []\n",
        "    attention = []\n",
        "    done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "\n",
        "    for _ in range(max_length):\n",
        "      dec_input = DecoderInput(new_tokens=new_tokens,\n",
        "                              enc_output=enc_output,\n",
        "                              mask=(input_tokens!=0))\n",
        "\n",
        "      dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n",
        "\n",
        "      attention.append(dec_result.attention_weights)\n",
        "\n",
        "      new_tokens = self.sample(dec_result.logits, temperature)\n",
        "\n",
        "      # If a sequence produces an `end_token`, set it `done`\n",
        "      done = done | (new_tokens == self.end_token)\n",
        "      # Once a sequence is done it only produces 0-padding.\n",
        "      new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)\n",
        "\n",
        "      # Collect the generated tokens\n",
        "      result_tokens.append(new_tokens)\n",
        "\n",
        "      if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "        break\n",
        "\n",
        "    # Convert the list of generates token ids to a list of strings.\n",
        "    result_tokens = tf.concat(result_tokens, axis=-1)\n",
        "    result_text = self.tokens_to_text(result_tokens)\n",
        "\n",
        "    if return_attention:\n",
        "      attention_stack = tf.concat(attention, axis=1)\n",
        "      return {'text': result_text, 'attention': attention_stack}\n",
        "    else:\n",
        "      return {'text': result_text}"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afmwjeFX819S"
      },
      "source": [
        "## Translator Predict Some Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4UwhwiNDRU6"
      },
      "source": [
        "#Bad Attention Translator\n",
        "translator_B = Translator(\n",
        "    encoder=train_translator_B.encoder,\n",
        "    decoder=train_translator_B.decoder,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        ")"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_fGKXr49m2Y"
      },
      "source": [
        "#Luong Attention Translator\n",
        "translator_L = Translator(\n",
        "    encoder=train_translator_L.encoder,\n",
        "    decoder=train_translator_L.decoder,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        ")"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5-Ln_ZcQDgI"
      },
      "source": [
        "tel1, tel2, tel3, tel4, tel5, eng1, eng2, eng3, eng4, eng5 = \"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"\n",
        "\n",
        "t1 = 'నా పేరు శ్రీనాథ్'\n",
        "for test_input_batch, test_target_batch in test_dataset:\n",
        "  tel1 = test_input_batch[0].numpy().decode()\n",
        "  eng1 = test_target_batch[0].numpy().decode()\n",
        "  tel2 = test_input_batch[1].numpy().decode()\n",
        "  eng2 = test_target_batch[1].numpy().decode()\n",
        "  tel3 = test_input_batch[6].numpy().decode()\n",
        "  eng3 = test_target_batch[6].numpy().decode()\n",
        "  tel4 = test_input_batch[8].numpy().decode()\n",
        "  eng4 = test_target_batch[8].numpy().decode()\n",
        "  tel5 = test_input_batch[13].numpy().decode()\n",
        "  eng5 = test_target_batch[13].numpy().decode()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcmMwMfkDbAR",
        "outputId": "b57b42cd-5622-4c3f-9d98-166bc7c73dab"
      },
      "source": [
        "%%time\n",
        "input_text = tf.constant([tel1, tel2, tel3, tel4, tel5, t1])\n",
        "\n",
        "result_B = translator_B.translate_unrolled(\n",
        "    input_text = input_text)\n",
        "\n",
        "result_L = translator_L.translate_unrolled(\n",
        "    input_text = input_text)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 777 ms, sys: 6.33 ms, total: 783 ms\n",
            "Wall time: 778 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Yq5nBjmU585"
      },
      "source": [
        "## See some translations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIRuKnDW9fsu",
        "outputId": "a490ba5d-78fb-4cdb-de79-4d5672d6bc33"
      },
      "source": [
        "print(\"Original sentence: \",tel1)\n",
        "print(\"Bahdanau Attention translator: \",result_B['text'][0].numpy().decode())\n",
        "print(\"Luong Attention translator: \",result_L['text'][0].numpy().decode())"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original sentence:  నువ్వు ఈత కొట్టడానికో లేక చేపలు పట్టడానికో వెళ్ళొచ్చు\n",
            "Bahdanau Attention translator:  you may go swimming or fishing .\n",
            "Luong Attention translator:  you may go swimming or fishing .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nmv0oHi--JST",
        "outputId": "a3c1e535-901e-48e2-9e69-779759cf3fba"
      },
      "source": [
        "print(\"Original sentence: \",tel2)\n",
        "print(\"Bahdanau Attention translator: \",result_B['text'][1].numpy().decode())\n",
        "print(\"Luong Attention translator: \",result_L['text'][1].numpy().decode())"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original sentence:  నేనింక నీతో మాట్లాడదల్చుకోవట్లేదు\n",
            "Bahdanau Attention translator:  i dont want to talk to you anymore .\n",
            "Luong Attention translator:  i dont accept it guy .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKK3CNqn-Jdf",
        "outputId": "f3f1b663-54c9-4f8f-e153-b83796b3de3c"
      },
      "source": [
        "print(\"Original sentence: \",t1)\n",
        "print(\"Bahdanau Attention translator: \",result_B['text'][5].numpy().decode())\n",
        "print(\"Luong Attention translator: \",result_L['text'][5].numpy().decode())"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original sentence:  నా పేరు శ్రీనాథ్\n",
            "Bahdanau Attention translator:  its thought all there there was no way this\n",
            "Luong Attention translator:  there dont want to start .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JM4SVkfDE1C"
      },
      "source": [
        "## Weights Analyse"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joqwp1ms_Nua"
      },
      "source": [
        "i=3"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "DwObt7u4EI0c",
        "outputId": "d599f444-abf3-4a8c-de29-1e718e773eac"
      },
      "source": [
        "a_b = result_B['attention'][i]\n",
        "_ = plt.bar(range(len(a_b[0, :])), a_b[0, :])"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "U_Bd7rrz_Bio",
        "outputId": "f58809f1-2939-4da3-edda-44fde6c0ccaa"
      },
      "source": [
        "a_l = result_L['attention'][i]\n",
        "_ = plt.bar(range(len(a_l[0, :])), a_l[0, :])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1YUpD10ERuj"
      },
      "source": [
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "  sentence = tf_lower_and_split_punct(sentence).numpy().decode().split()\n",
        "  predicted_sentence = predicted_sentence.numpy().decode().split() + ['[END]']\n",
        "  fig = plt.figure(figsize=(10, 10))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "\n",
        "  attention = attention[:len(predicted_sentence), :len(sentence)]\n",
        "\n",
        "  ax.matshow(attention, cmap='viridis', vmin=0.0, vmax=1)\n",
        "\n",
        "  fontdict = {'fontsize': 14}\n",
        "\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
        "\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "\n",
        "  ax.set_xlabel('Input text')\n",
        "  ax.set_ylabel('Output text')\n",
        "  plt.suptitle('Attention weights')"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pfcb0ZEfES7i",
        "outputId": "3d05ab54-b434-4e78-8703-633ae4e6586b"
      },
      "source": [
        "# Bahdanau Attention weights plot\n",
        "plot_attention(result_B['attention'][i], input_text[i], result_B['text'][i])\n",
        "print(input_text[i].numpy().decode())"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "నువ్వు చాలా సంతోషంగా ఉన్నట్లున్నావ్\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3112 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3137 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3125 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3149 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3098 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3134 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3122 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3128 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3074 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3108 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3147 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3127 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3095 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3081 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3103 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3112 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3137 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3125 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3149 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3098 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3134 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3122 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3128 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3074 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3108 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3147 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3127 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3095 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3081 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3103 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SjBqlXt5-du4",
        "outputId": "a964ec24-8d0b-4437-f62b-80c54ab7b0ab"
      },
      "source": [
        "# Luong Attention weights plot\n",
        "plot_attention(result_L['attention'][i], input_text[i], result_L['text'][i])\n",
        "print(input_text[i].numpy().decode())"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "నువ్వు చాలా సంతోషంగా ఉన్నట్లున్నావ్\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3112 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3137 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3125 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3149 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3098 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3134 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3122 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3128 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3074 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3108 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3147 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3127 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3095 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3081 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:214: RuntimeWarning: Glyph 3103 missing from current font.\n",
            "  font.set_text(s, 0.0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3112 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3137 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3125 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3149 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3098 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3134 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3122 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3128 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3074 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3108 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3147 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3127 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3095 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3081 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n",
            "/usr/local/lib/python3.7/dist-packages/matplotlib/backends/backend_agg.py:183: RuntimeWarning: Glyph 3103 missing from current font.\n",
            "  font.set_text(s, 0, flags=flags)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1lBga5tbDy4"
      },
      "source": [
        "# Questions & Answers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJlNcedYbJFi"
      },
      "source": [
        "Q1-)Which parts of the sentence are used as a token? Each character, each word, or are some words split up?\n",
        "\n",
        "Ans-) Each word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSFabVhgb6NA"
      },
      "source": [
        "Q-2) Do the same tokens in different language have the same ID?\n",
        "e.g. Would the same token index map to the German word die and to the English word die?\n",
        "\n",
        "\n",
        "Ans-) No. \n",
        "\n",
        "As example we can see below:\n",
        "\n",
        "*  inp = 'die hallo morgen guten tag'\n",
        "*  tar = 'Someone might die because of the situation'\n",
        "*  inp_voc = [0 1 2 3 4 5]\n",
        "*  tar_voc = [0 1 2 3 4 5 6]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43vetYtVdNt0"
      },
      "source": [
        "Q-3)What is the relation between the encoder output and the encoder hidden state which is used to initialize the decoder hidden state (for the architecture used in the tutorial)?\n",
        "\n",
        "Ans-) Encoder ouput is dependent on encoder hidden state whereas vice-versa isn't the same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtXk0eDdfIgC"
      },
      "source": [
        "Q-4) Is the decoder attending to all previous positions, including the previous decoder predictions?\n",
        "\n",
        "Ans-) No it will attend to just the previous decoder state and predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiRXSZ3zfxpc"
      },
      "source": [
        "Q-5) Does the encoder output change in different decoding steps?\n",
        "\n",
        "Ans-) Yes it computes attention weights dynamically for every decoder step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgrMHrqvgNxN"
      },
      "source": [
        "Q-6) Does the context vector change in different decoding steps?\n",
        "\n",
        "Ans-) Yes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "molLOQfNgStB"
      },
      "source": [
        "Q-7) The decoder uses teacher forcing. Does this mean the time steps can be computed in parallel?\n",
        "\n",
        "Ans-) No because even the previous decoder state is also connected to the current decoder state."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnFce_9CgeTR"
      },
      "source": [
        "Q-8) Why is a mask applied to the loss function?\n",
        "\n",
        "Ans-) To skip the zero padded cells in the sequences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5KlAkttgwos"
      },
      "source": [
        "Q-9) When translating the same sentence multiple times, do you get the same result? Why (not)? If not, what changes need to be made to get the same result each time?\n",
        "\n",
        "Ans-) The output is not consistent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGd5aFjjm4zZ"
      },
      "source": [
        "# References\n",
        "\n",
        "\n",
        "\n",
        "1.   https://www.tensorflow.org/text/tutorials/nmt_with_attention\n",
        "2.   https://ovgu-ailab.github.io/idl2021/ass7.html\n",
        "\n"
      ]
    }
  ]
}