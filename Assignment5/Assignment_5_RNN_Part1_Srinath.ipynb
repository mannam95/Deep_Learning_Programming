{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_5_RNN_Part1_Srinath.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9b1ec548",
        "xiB5DU5SAKLG"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mannam95/Deep_Learning_Programming/blob/main/Assignment5/Assignment_5_RNN_Part1_Srinath.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6aef94d"
      },
      "source": [
        "# Team Assignment\n",
        "\n",
        "\n",
        "1.   Srinath Mannam (229750)\n",
        "2.   Meghana Rao (234907)\n",
        "3.   Govind Shukla (235192)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b1ec548"
      },
      "source": [
        "# import statements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85eb7211"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from keras.regularizers import l2\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numba import cuda\n",
        "import sys\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "import pydot\n",
        "import graphviz\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from datetime import datetime\n",
        "from keras.preprocessing import sequence"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c34550c"
      },
      "source": [
        "# Change the directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94b2626e"
      },
      "source": [
        "working_directory = '/content/drive/My Drive/Colab Notebooks/OVGU/Deep_Learning/05_Assignment'\n",
        "def colabDrive():\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "\n",
        "    if os.getcwd() !=  working_directory:\n",
        "      os.chdir(working_directory)\n",
        "    print(os.getcwd())"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8540ed4"
      },
      "source": [
        "#colabDrive()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c715ac7b"
      },
      "source": [
        "# Clears GPU memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "591268b2"
      },
      "source": [
        "def clearGPUMemory():\n",
        "    from numba import cuda \n",
        "    device = cuda.get_current_device()\n",
        "    device.reset()\n",
        "    !nvidia-smi"
      ],
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "caee9b53"
      },
      "source": [
        "#clearGPUMemory()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6mjm447GMHX"
      },
      "source": [
        "# Prepare the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dv0CvhD7Yga"
      },
      "source": [
        "## Load the dataset and remove infrequent words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVE7aMvC4iXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fea0e3d-2a0c-464a-f066-591c2fe24719"
      },
      "source": [
        "num_words = 20000\n",
        "(train_sequences, train_labels), (test_sequences, test_labels) = tf.keras.datasets.imdb.load_data(num_words=num_words)\n",
        "\n",
        "print('Loaded dataset with {} training samples, {} test samples'.format(len(train_sequences), len(test_sequences)))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n",
            "Loaded dataset with 25000 training samples, 25000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc9OZbtI7oPF"
      },
      "source": [
        "## Have some look at train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c07u7Z7s4opk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ccbc10f-89a7-44bf-ab42-45c27293358a"
      },
      "source": [
        "# look at some sequences. words have been replaced with arbitrary index mappings\n",
        "# 1 is a special \"beginning of sequence\" marker\n",
        "# infrequent words have been replaced by the index 2\n",
        "# actual words start with index 4, 3 is never used (???)\n",
        "train_sequences[:3]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
              "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFCZvjGjuy1v",
        "outputId": "1c5d998d-7fd3-4daa-a5af-a0357de68310"
      },
      "source": [
        "print('---review---')\n",
        "print(train_sequences[6])\n",
        "print('---label---')\n",
        "print(train_labels[6])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---review---\n",
            "[1, 6740, 365, 1234, 5, 1156, 354, 11, 14, 5327, 6638, 7, 1016, 10626, 5940, 356, 44, 4, 1349, 500, 746, 5, 200, 4, 4132, 11, 16393, 9363, 1117, 1831, 7485, 5, 4831, 26, 6, 2, 4183, 17, 369, 37, 215, 1345, 143, 2, 5, 1838, 8, 1974, 15, 36, 119, 257, 85, 52, 486, 9, 6, 2, 8564, 63, 271, 6, 196, 96, 949, 4121, 4, 2, 7, 4, 2212, 2436, 819, 63, 47, 77, 7175, 180, 6, 227, 11, 94, 2494, 2, 13, 423, 4, 168, 7, 4, 22, 5, 89, 665, 71, 270, 56, 5, 13, 197, 12, 161, 5390, 99, 76, 23, 2, 7, 419, 665, 40, 91, 85, 108, 7, 4, 2084, 5, 4773, 81, 55, 52, 1901]\n",
            "---label---\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUD_v_L21y2A"
      },
      "source": [
        "## to restore words, load the word-to-index mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYX6F3AX5hpV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "995fdd3c-2970-48ac-c208-8d3c51751423"
      },
      "source": [
        "word2id = tf.keras.datasets.imdb.get_word_index()\n",
        "id2word = {i: word for word, i in word2id.items()}\n",
        "print('---review with words---')\n",
        "print([id2word.get(i, ' ') for i in train_sequences[6]])\n",
        "print('---label---')\n",
        "print(train_sequences[6])\n",
        "print('---label---')\n",
        "print(train_labels[6])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n",
            "---review with words---\n",
            "['the', 'boiled', 'full', 'involving', 'to', 'impressive', 'boring', 'this', 'as', 'murdering', 'naschy', 'br', 'villain', 'council', 'suggestion', 'need', 'has', 'of', 'costumes', 'b', 'message', 'to', 'may', 'of', 'props', 'this', 'echoed', 'concentrates', 'concept', 'issue', 'skeptical', 'to', \"god's\", 'he', 'is', 'and', 'unfolds', 'movie', 'women', 'like', \"isn't\", 'surely', \"i'm\", 'and', 'to', 'toward', 'in', \"here's\", 'for', 'from', 'did', 'having', 'because', 'very', 'quality', 'it', 'is', 'and', 'starship', 'really', 'book', 'is', 'both', 'too', 'worked', 'carl', 'of', 'and', 'br', 'of', 'reviewer', 'closer', 'figure', 'really', 'there', 'will', 'originals', 'things', 'is', 'far', 'this', 'make', 'mistakes', 'and', 'was', \"couldn't\", 'of', 'few', 'br', 'of', 'you', 'to', \"don't\", 'female', 'than', 'place', 'she', 'to', 'was', 'between', 'that', 'nothing', 'dose', 'movies', 'get', 'are', 'and', 'br', 'yes', 'female', 'just', 'its', 'because', 'many', 'br', 'of', 'overly', 'to', 'descent', 'people', 'time', 'very', 'bland']\n",
            "---label---\n",
            "[1, 6740, 365, 1234, 5, 1156, 354, 11, 14, 5327, 6638, 7, 1016, 10626, 5940, 356, 44, 4, 1349, 500, 746, 5, 200, 4, 4132, 11, 16393, 9363, 1117, 1831, 7485, 5, 4831, 26, 6, 2, 4183, 17, 369, 37, 215, 1345, 143, 2, 5, 1838, 8, 1974, 15, 36, 119, 257, 85, 52, 486, 9, 6, 2, 8564, 63, 271, 6, 196, 96, 949, 4121, 4, 2, 7, 4, 2212, 2436, 819, 63, 47, 77, 7175, 180, 6, 227, 11, 94, 2494, 2, 13, 423, 4, 168, 7, 4, 22, 5, 89, 665, 71, 270, 56, 5, 13, 197, 12, 161, 5390, 99, 76, 23, 2, 7, 419, 665, 40, 91, 85, 108, 7, 4, 2084, 5, 4773, 81, 55, 52, 1901]\n",
            "---label---\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWJ6KpLz60sM"
      },
      "source": [
        "## Maximum review length and minimum review length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6LZSJS_62Ye",
        "outputId": "1f21bfa1-0f50-48cf-993b-d88aabff6a82"
      },
      "source": [
        "print('Maximum review length: {}'.format(len(max((train_sequences + test_sequences), key=len))))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum review length: 2697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XMcFfgQ7H-O",
        "outputId": "74bcb687-8ca0-4cd5-b9ba-0ac812b810a1"
      },
      "source": [
        "print('Minimum review length: {}'.format(len(min((train_sequences + test_sequences), key=len))))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum review length: 70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PH1icKQ8fmG"
      },
      "source": [
        "## Overview over the sequence length in the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bpWf-SfA8d0d",
        "outputId": "8dacb1e4-827f-4a7d-e9c7-4a7b602a0178"
      },
      "source": [
        "sequence_lengths = [len(sequence) for sequence in train_sequences]\n",
        "max_len = max(sequence_lengths)\n",
        "max_len\n",
        "\n",
        "plt.hist(sequence_lengths, bins=80)\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUkklEQVR4nO3df4xd5X3n8fen5keqJltMmCLXttZu6qoiK5WgWWCVqMqCYoyzWhOpjYiqYlEkdyUjJVJ/xLR/kCZFIqsmbNGmSE7xxkTZuCg/hEXoUocQRfkD8JA4BkMpEyDCloMnMSGJorIL/e4f9zG6cebHnZk7d+w575d0Ned8z3PufR7f8WfOfe6596SqkCR1wy8tdwckSaNj6EtShxj6ktQhhr4kdYihL0kdcs5yd2A2F110UW3YsGG5uyFJZ5XHH3/8B1U1Nt22Mzr0N2zYwMTExHJ3Q5LOKkm+N9M2p3ckqUMMfUnqEENfkjrE0JekDjH0JalDDH1J6hBDX5I6xNCXpA4x9CWpQ87oT+SO0oZdX/m59Rduf+8y9USSlo5H+pLUIYa+JHWI0zszcLpH0krkkb4kdcjAoZ9kVZJvJ7m/rW9M8miSyST/kOS8Vj+/rU+27Rv67uOWVn8myTXDHowkaXbzOdL/IPB03/rHgTuq6jeBl4GbWv0m4OVWv6O1I8klwPXA24EtwN8lWbW47kuS5mOg0E+yDngv8PdtPcBVwBdak73AdW15W1unbb+6td8G7KuqV6vqeWASuHwYg5AkDWbQI/3/Afw58G9t/a3Aj6rqtbZ+FFjbltcCLwK07a+09m/Up9nnDUl2JJlIMjE1NTWPoUiS5jJn6Cf5L8CJqnp8BP2hqnZX1XhVjY+NTXuJR0nSAg1yyuY7gf+aZCvwJuDfAX8LXJDknHY0vw441tofA9YDR5OcA/wq8MO++in9+0iSRmDOI/2quqWq1lXVBnpvxH6tqv4AeBj4vdZsO3BfW97f1mnbv1ZV1erXt7N7NgKbgMeGNhJJ0pwW8+GsDwP7kvw18G3g7la/G/hskkngJL0/FFTVkST3Ak8BrwE7q+r1RTy+JGme5hX6VfV14Ott+TmmOfumqv4V+P0Z9r8NuG2+nZQkDYefyJWkDjH0JalDDH1J6hBDX5I6xNCXpA4x9CWpQwx9SeoQQ1+SOsTQl6QOMfQlqUMMfUnqEENfkjrE0JekDjH0JalDDH1J6hBDX5I6ZJALo78pyWNJvpPkSJK/avXPJHk+yaF2u7TVk+TOJJNJDie5rO++tid5tt22z/SYkqSlMciVs14FrqqqnyY5F/hmkn9s2/6sqr5wWvtr6V3/dhNwBXAXcEWSC4FbgXGggMeT7K+ql4cxEEnS3Aa5MHpV1U/b6rntVrPssg24p+33CHBBkjXANcCBqjrZgv4AsGVx3ZckzcdAc/pJViU5BJygF9yPtk23tSmcO5Kc32prgRf7dj/aajPVT3+sHUkmkkxMTU3NcziSpNkMFPpV9XpVXQqsAy5P8h+AW4DfBv4jcCHw4WF0qKp2V9V4VY2PjY0N4y4lSc28zt6pqh8BDwNbqup4m8J5FfhfwOWt2TFgfd9u61ptprokaUQGOXtnLMkFbfmXgfcA/9zm6UkS4DrgybbLfuCGdhbPlcArVXUceBDYnGR1ktXA5laTJI3IIGfvrAH2JllF74/EvVV1f5KvJRkDAhwC/ltr/wCwFZgEfgbcCFBVJ5N8DDjY2n20qk4ObyiSpLnMGfpVdRh4xzT1q2ZoX8DOGbbtAfbMs4+SpCHxE7mS1CGGviR1iKEvSR1i6EtShxj6ktQhhr4kdYihL0kdYuhLUocY+pLUIYa+JHWIoS9JHWLoS1KHGPqS1CGGviR1iKEvSR0yyJWz3pTksSTfSXIkyV+1+sYkjyaZTPIPSc5r9fPb+mTbvqHvvm5p9WeSXLNUg5IkTW+QI/1Xgauq6neAS4Et7TKIHwfuqKrfBF4GbmrtbwJebvU7WjuSXAJcD7wd2AL8XbsalyRpROYM/Xbx85+21XPbrYCrgC+0+l5618kF2NbWaduvbtfR3Qbsq6pXq+p5epdTPHUxdUnSCAw0p59kVZJDwAngAPBd4EdV9VprchRY25bXAi8CtO2vAG/tr0+zjyRpBAYK/ap6vaouBdbROzr/7aXqUJIdSSaSTExNTS3Vw0hSJ83r7J2q+hHwMPCfgAuSnLqw+jrgWFs+BqwHaNt/Ffhhf32affofY3dVjVfV+NjY2Hy6J0mawyBn74wluaAt/zLwHuBpeuH/e63ZduC+try/rdO2f62qqtWvb2f3bAQ2AY8NayCSpLmdM3cT1gB725k2vwTcW1X3J3kK2Jfkr4FvA3e39ncDn00yCZykd8YOVXUkyb3AU8BrwM6qen24w5EkzWbO0K+qw8A7pqk/xzRn31TVvwK/P8N93QbcNv9uSpKGwU/kSlKHGPqS1CGGviR1iKEvSR1i6EtShxj6ktQhg5ynL2DDrq+8sfzC7e9dxp5I0sJ5pC9JHWLoS1KHGPqS1CGGviR1iKEvSR1i6EtShxj6ktQhhr4kdYihL0kdMsjlEtcneTjJU0mOJPlgq38kybEkh9pta98+tySZTPJMkmv66ltabTLJrqUZkiRpJoN8DcNrwJ9U1beSvAV4PMmBtu2Oqvqb/sZJLqF3icS3A78OfDXJb7XNn6J3jd2jwMEk+6vqqWEMRJI0t0Eul3gcON6Wf5LkaWDtLLtsA/ZV1avA8+1auacuqzjZLrNIkn2traEvSSMyrzn9JBvoXS/30Va6OcnhJHuSrG61tcCLfbsdbbWZ6qc/xo4kE0kmpqam5tM9SdIcBg79JG8Gvgh8qKp+DNwFvA24lN4rgU8Mo0NVtbuqxqtqfGxsbBh3KUlqBvpq5STn0gv8z1XVlwCq6qW+7Z8G7m+rx4D1fbuvazVmqUuSRmCQs3cC3A08XVWf7Kuv6Wv2PuDJtrwfuD7J+Uk2ApuAx4CDwKYkG5OcR+/N3v3DGYYkaRCDHOm/E/hD4Ikkh1rtL4APJLkUKOAF4I8BqupIknvpvUH7GrCzql4HSHIz8CCwCthTVUeGOBZJ0hwGOXvnm0Cm2fTALPvcBtw2Tf2B2faTJC0tP5ErSR1i6EtShxj6ktQhhr4kdYihL0kdYuhLUocY+pLUIYa+JHWIoS9JHWLoS1KHGPqS1CGGviR1iKEvSR1i6EtShxj6ktQhhr4kdcggl0tcn+ThJE8lOZLkg61+YZIDSZ5tP1e3epLcmWQyyeEkl/Xd1/bW/tkk25duWJKk6QxypP8a8CdVdQlwJbAzySXALuChqtoEPNTWAa6ld13cTcAO4C7o/ZEAbgWuAC4Hbj31h0KSNBpzhn5VHa+qb7XlnwBPA2uBbcDe1mwvcF1b3gbcUz2PABe0i6hfAxyoqpNV9TJwANgy1NFIkmY1rzn9JBuAdwCPAhdX1fG26fvAxW15LfBi325HW22m+umPsSPJRJKJqamp+XRPkjSHgUM/yZuBLwIfqqof92+rqgJqGB2qqt1VNV5V42NjY8O4S0lSc84gjZKcSy/wP1dVX2rll5KsqarjbfrmRKsfA9b37b6u1Y4B7z6t/vWFd335bNj1lZ9bf+H29y5TTyRpfgY5eyfA3cDTVfXJvk37gVNn4GwH7uur39DO4rkSeKVNAz0IbE6yur2Bu7nVJEkjMsiR/juBPwSeSHKo1f4CuB24N8lNwPeA97dtDwBbgUngZ8CNAFV1MsnHgIOt3Uer6uRQRiFJGsicoV9V3wQyw+arp2lfwM4Z7msPsGc+HZQkDY+fyJWkDjH0JalDDH1J6hBDX5I6xNCXpA4x9CWpQwx9SeoQQ1+SOsTQl6QOMfQlqUMMfUnqEENfkjrE0JekDjH0JalDDH1J6hBDX5I6ZJDLJe5JciLJk321jyQ5luRQu23t23ZLkskkzyS5pq++pdUmk+wa/lAkSXMZ5HKJnwH+J3DPafU7qupv+gtJLgGuB94O/Drw1SS/1TZ/CngPcBQ4mGR/VT21iL6fMbxQuqSzxSCXS/xGkg0D3t82YF9VvQo8n2QSuLxtm6yq5wCS7GttV0ToS9LZYjFz+jcnOdymf1a32lrgxb42R1ttpvovSLIjyUSSiampqUV0T5J0uoWG/l3A24BLgePAJ4bVoaraXVXjVTU+NjY2rLuVJDHYnP4vqKqXTi0n+TRwf1s9Bqzva7qu1ZilvixOn4eXpC5Y0JF+kjV9q+8DTp3Zsx+4Psn5STYCm4DHgIPApiQbk5xH783e/QvvtiRpIeY80k/yeeDdwEVJjgK3Au9OcilQwAvAHwNU1ZEk99J7g/Y1YGdVvd7u52bgQWAVsKeqjgx9NJKkWQ1y9s4HpinfPUv724Dbpqk/ADwwr95JkoZqQXP6ZyPn8CXJr2GQpE4x9CWpQwx9SeoQQ1+SOsTQl6QOMfQlqUMMfUnqEENfkjrE0JekDjH0JalDDH1J6pDOfPfOKHnNXElnKo/0JalDDH1J6hBDX5I6ZM7QT7InyYkkT/bVLkxyIMmz7efqVk+SO5NMJjmc5LK+fba39s8m2b40w5EkzWaQI/3PAFtOq+0CHqqqTcBDbR3gWnrXxd0E7ADugt4fCXqXWbwCuBy49dQfCknS6MwZ+lX1DeDkaeVtwN62vBe4rq9+T/U8AlzQLqJ+DXCgqk5W1cvAAX7xD4kkaYktdE7/4qo63pa/D1zcltcCL/a1O9pqM9V/QZIdSSaSTExNTS2we5Kk6Sz6PP2qqiQ1jM60+9sN7AYYHx8f2v0uJ8/bl3SmWOiR/ktt2ob280SrHwPW97Vb12oz1SVJI7TQ0N8PnDoDZztwX1/9hnYWz5XAK20a6EFgc5LV7Q3cza0mSRqhOad3knweeDdwUZKj9M7CuR24N8lNwPeA97fmDwBbgUngZ8CNAFV1MsnHgIOt3Uer6vQ3hyVJS2zO0K+qD8yw6epp2hawc4b72QPsmVfvJElD5SdyJalDDH1J6hBDX5I6xNCXpA7xIirLwA9rSVouHulLUocY+pLUIYa+JHWIoS9JHeIbuWeA/jd2fVNX0lLySF+SOsTQl6QOMfQlqUMMfUnqEENfkjrE0JekDllU6Cd5IckTSQ4lmWi1C5McSPJs+7m61ZPkziSTSQ4nuWwYA5AkDW4Y5+n/56r6Qd/6LuChqro9ya62/mHgWmBTu10B3NV+qo9fxiZpKS3F9M42YG9b3gtc11e/p3oeAS5IsmYJHl+SNIPFhn4B/5Tk8SQ7Wu3iqjrelr8PXNyW1wIv9u17tNV+TpIdSSaSTExNTS2ye5Kkfoud3nlXVR1L8mvAgST/3L+xqipJzecOq2o3sBtgfHx8XvtKkma3qNCvqmPt54kkXwYuB15KsqaqjrfpmxOt+TFgfd/u61pNs3COX9IwLXh6J8mvJHnLqWVgM/AksB/Y3pptB+5ry/uBG9pZPFcCr/RNA0mSRmAxR/oXA19Ocup+/ndV/Z8kB4F7k9wEfA94f2v/ALAVmAR+Bty4iMeWJC3AgkO/qp4Dfmea+g+Bq6epF7BzoY+nHqd7JC2Gn8iVpA4x9CWpQ7xy1lnO6R5J8+GRviR1iKEvSR3i9M4K40XWJc3GI31J6hCP9Fcw3+SVdLoVHfqnh17X+UdAktM7ktQhK/pIX7PzyF/qHkNfb/CPgLTyOb0jSR3ikb5mNJ83wn1VIJ0dDH0tCaeKpDOToa+hmOtVwTA/KTzbY/nHRZrdyEM/yRbgb4FVwN9X1e2j7oOW11yvAnyVIC2dkYZ+klXAp4D3AEeBg0n2V9VTo+yHzizzeZUgaXFGfaR/OTDZLrVIkn3ANsDQ11D4KkGa3ahDfy3wYt/6UeCK/gZJdgA72upPkzyzgMe5CPjBgnp4duviuGcdcz4+wp6Mjs9zdyx03P9+pg1n3Bu5VbUb2L2Y+0gyUVXjQ+rSWaOL43bM3dDFMcPSjHvUH846BqzvW1/XapKkERh16B8ENiXZmOQ84Hpg/4j7IEmdNdLpnap6LcnNwIP0TtncU1VHluChFjU9dBbr4rgdczd0ccywBONOVQ37PiVJZyi/cE2SOsTQl6QOWXGhn2RLkmeSTCbZtdz9GaYkLyR5IsmhJBOtdmGSA0mebT9Xt3qS3Nn+HQ4nuWx5ez+YJHuSnEjyZF9t3mNMsr21fzbJ9uUYy3zMMO6PJDnWnu9DSbb2bbuljfuZJNf01c+a3/8k65M8nOSpJEeSfLDVV+zzPcuYR/dcV9WKudF7c/i7wG8A5wHfAS5Z7n4NcXwvABedVvvvwK62vAv4eFveCvwjEOBK4NHl7v+AY/xd4DLgyYWOEbgQeK79XN2WVy/32BYw7o8AfzpN20va7/b5wMb2O7/qbPv9B9YAl7XltwD/0sa2Yp/vWcY8sud6pR3pv/E1D1X1f4FTX/Owkm0D9rblvcB1ffV7qucR4IIka5ajg/NRVd8ATp5Wnu8YrwEOVNXJqnoZOABsWfreL9wM457JNmBfVb1aVc8Dk/R+98+q3/+qOl5V32rLPwGepvep/RX7fM8y5pkM/bleaaE/3dc8zPYPerYp4J+SPN6+rgLg4qo63pa/D1zcllfSv8V8x7iSxn5zm8rYc2qagxU47iQbgHcAj9KR5/u0McOInuuVFvor3buq6jLgWmBnkt/t31i914Mr+hzcLoyxz13A24BLgePAJ5a3O0sjyZuBLwIfqqof929bqc/3NGMe2XO90kJ/RX/NQ1Udaz9PAF+m9xLvpVPTNu3nidZ8Jf1bzHeMK2LsVfVSVb1eVf8GfJre8w0raNxJzqUXfp+rqi+18op+vqcb8yif65UW+iv2ax6S/EqSt5xaBjYDT9Ib36mzFbYD97Xl/cAN7YyHK4FX+l4yn23mO8YHgc1JVreXyZtb7axy2nsw76P3fENv3NcnOT/JRmAT8Bhn2e9/kgB3A09X1Sf7Nq3Y53umMY/0uV7ud7OHfaP3Dv+/0Htn+y+Xuz9DHNdv0HuH/jvAkVNjA94KPAQ8C3wVuLDVQ++CNd8FngDGl3sMA47z8/Re3v4/evOUNy1kjMAf0XvTaxK4cbnHtcBxf7aN63D7D72mr/1ftnE/A1zbVz9rfv+Bd9GbujkMHGq3rSv5+Z5lzCN7rv0aBknqkJU2vSNJmoWhL0kdYuhLUocY+pLUIYa+JHWIoS9JHWLoS1KH/H8BAZvsuL6idgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnxcVXiV7EZy"
      },
      "source": [
        "## Pad Sequences  to some length because the dataset should be in rectangular for feeding to tensors\n",
        "\n",
        "*  all sequences above maxlen will be truncated to that length\n",
        "*  note: pad_sequences has \"pre\" and \"post\" options for both padding and truncation. one may be better than the other!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDFYpy4Q8LH9"
      },
      "source": [
        "max_words = 500\n",
        "train_sequences = sequence.pad_sequences(train_sequences, maxlen=max_words)\n",
        "test_sequences = sequence.pad_sequences(test_sequences, maxlen=max_words)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sxPAMPF9GRf"
      },
      "source": [
        "## Load the dataset into tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1YiFTf89KzS"
      },
      "source": [
        "train_labels = train_labels.reshape(-1).astype(np.int32)\n",
        "test_labels = test_labels.reshape(-1).astype(np.int32)\n",
        "# train_data = tf.data.Dataset.from_tensor_slices((train_sequences, train_labels))\n",
        "# test_data = tf.data.Dataset.from_tensor_slices((test_sequences, test_labels))\n",
        "\n",
        "train_data = tf.data.Dataset.from_tensor_slices((train_sequences, train_labels)).shuffle(25000).batch(128, drop_remainder=True)\n",
        "test_data = tf.data.Dataset.from_tensor_slices((test_sequences, test_labels)).batch(128, drop_remainder=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epD2fyBM-CKA",
        "outputId": "1237e2d6-10f1-44e0-cce7-d0544f7b6319"
      },
      "source": [
        "print(\"Training Dataset Size: \",train_sequences.shape)\n",
        "print(\"Test Dataset Size: \",test_sequences.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset Size:  (25000, 500)\n",
            "Test Dataset Size:  (25000, 500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8NysXi27_Gg"
      },
      "source": [
        "# Model1\n",
        "\n",
        "1.   With 10 Epochs\n",
        "2.   The test accuracy is 50.1%\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiB5DU5SAKLG"
      },
      "source": [
        "## Weight Matrix Initializations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12k45HYkAJY8"
      },
      "source": [
        "W_HH = tf.Variable(tf.random.uniform([1, 100], minval=-0.1, maxval=0.1, dtype=np.float32))\n",
        "b1 = tf.Variable(np.zeros((100, 1), dtype=np.float32))\n",
        "W_IH = tf.Variable(tf.random.uniform([1, 20000], minval=-0.1, maxval=0.1, dtype=np.float32))\n",
        "W_HO = tf.Variable(tf.random.uniform([100, 2], minval=-0.1, maxval=0.1, dtype=np.float32))\n",
        "c1 = tf.Variable(np.zeros((128, 2), dtype=np.float32))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiTvrH56GhH5"
      },
      "source": [
        "## Training, Testing define"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEw-Xlx3_OsU"
      },
      "source": [
        "lr = 0.1\n",
        "def train_loop(epochs):\n",
        "    for epoch in range(epochs):\n",
        "      print(\"Epoch No: \", epoch)\n",
        "      for stepCount, (sequence_batch, label_batch) in enumerate(train_data):\n",
        "          # label_batch = tf.reshape(label_batch, [1])\n",
        "          train_step(stepCount, sequence_batch, label_batch)\n",
        "      print(\"-------------\\n\")\n",
        "\n",
        "def test_loop():\n",
        "    testAcc = []\n",
        "    for stepCount, (sequence_batch, label_batch) in enumerate(test_data):\n",
        "        # label_batch = tf.reshape(label_batch, [1])\n",
        "        testAcc.append(train_step(stepCount, sequence_batch, label_batch, True))\n",
        "\n",
        "    print(\"Final Test Accuracy Average: {} \".format(sum(testAcc)/len(testAcc)))\n",
        "\n",
        "\n",
        "def train_step(step, sequences, labels, testFlag=False):\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = rnn_loop(sequences)\n",
        "        xent = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "            logits=logits, labels=labels))\n",
        "\n",
        "    if testFlag != True:\n",
        "      grads = tape.gradient(xent, [W_HH, b1, W_IH, W_HO, c1])\n",
        "\n",
        "      W_HH.assign_sub(lr * grads[0])\n",
        "      b1.assign_sub(lr * grads[1])\n",
        "      W_IH.assign_sub(lr * grads[2])\n",
        "      W_HO.assign_sub(lr * grads[3])\n",
        "      c1.assign_sub(lr * grads[4])\n",
        "\n",
        "    if not step % 50 and testFlag != True:\n",
        "        print(\"Steps Completed: \", step)\n",
        "        preds = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
        "        acc = tf.reduce_mean(tf.cast(tf.equal(preds, labels), tf.float32))\n",
        "        print(\"Loss: {} Accuracy: {}\".format(xent, acc))\n",
        "    \n",
        "    # For testing the dataset\n",
        "    if testFlag == True:\n",
        "        preds = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
        "        acc = tf.reduce_mean(tf.cast(tf.equal(preds, labels), tf.float32))\n",
        "        return acc\n",
        "\n",
        "\n",
        "def rnn_loop(sequences):\n",
        "    old_state = tf.Variable(np.zeros([100,1], dtype=np.float32))\n",
        "    seq_onehot = tf.one_hot(sequences, depth=num_words)\n",
        "\n",
        "    for step in range(max_words):\n",
        "        x_t = seq_onehot[:,step]\n",
        "        new_state = rnn_step(old_state, x_t)\n",
        "        old_state = new_state\n",
        "\n",
        "    o_t = output_layer(new_state)\n",
        "\n",
        "    return o_t\n",
        "\n",
        "def rnn_step(state, x_t):\n",
        "    at = b1 + tf.matmul(W_HH, state) + tf.matmul(W_IH, tf.transpose(x_t))\n",
        "    tanFun = tf.nn.tanh(at)\n",
        "    \n",
        "    return tanFun\n",
        "\n",
        "\n",
        "def output_layer(new_state):\n",
        "    matMul = tf.matmul(tf.transpose(new_state), W_HO)\n",
        "    ot = c1 + matMul\n",
        "\n",
        "    return ot"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Dig5ns7IItq"
      },
      "source": [
        "## Running"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UlTX6vkIMF2",
        "outputId": "c38282df-b091-4190-d039-06ca13feb551"
      },
      "source": [
        "train_loop(10)\n",
        "test_loop()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch No:  0\n",
            "Steps Completed:  0\n",
            "Loss: 0.6923732161521912 Accuracy: 0.53125\n",
            "Steps Completed:  50\n",
            "Loss: 0.6946759223937988 Accuracy: 0.4296875\n",
            "Steps Completed:  100\n",
            "Loss: 0.6939346790313721 Accuracy: 0.5078125\n",
            "Steps Completed:  150\n",
            "Loss: 0.6942499876022339 Accuracy: 0.46875\n",
            "-------------\n",
            "\n",
            "Epoch No:  1\n",
            "Steps Completed:  0\n",
            "Loss: 0.6919035911560059 Accuracy: 0.5546875\n",
            "Steps Completed:  50\n",
            "Loss: 0.6922401189804077 Accuracy: 0.5625\n",
            "Steps Completed:  100\n",
            "Loss: 0.6942858695983887 Accuracy: 0.4453125\n",
            "Steps Completed:  150\n",
            "Loss: 0.6931699514389038 Accuracy: 0.53125\n",
            "-------------\n",
            "\n",
            "Epoch No:  2\n",
            "Steps Completed:  0\n",
            "Loss: 0.6907498836517334 Accuracy: 0.59375\n",
            "Steps Completed:  50\n",
            "Loss: 0.6977226734161377 Accuracy: 0.453125\n",
            "Steps Completed:  100\n",
            "Loss: 0.6943092346191406 Accuracy: 0.515625\n",
            "Steps Completed:  150\n",
            "Loss: 0.6897859573364258 Accuracy: 0.5390625\n",
            "-------------\n",
            "\n",
            "Epoch No:  3\n",
            "Steps Completed:  0\n",
            "Loss: 0.6922880411148071 Accuracy: 0.5234375\n",
            "Steps Completed:  50\n",
            "Loss: 0.6864200830459595 Accuracy: 0.6171875\n",
            "Steps Completed:  100\n",
            "Loss: 0.6829307079315186 Accuracy: 0.5859375\n",
            "Steps Completed:  150\n",
            "Loss: 0.6741463541984558 Accuracy: 0.578125\n",
            "-------------\n",
            "\n",
            "Epoch No:  4\n",
            "Steps Completed:  0\n",
            "Loss: 0.6792547702789307 Accuracy: 0.609375\n",
            "Steps Completed:  50\n",
            "Loss: 0.6761254072189331 Accuracy: 0.5703125\n",
            "Steps Completed:  100\n",
            "Loss: 2.600276231765747 Accuracy: 0.5\n",
            "Steps Completed:  150\n",
            "Loss: 2.8369064331054688 Accuracy: 0.484375\n",
            "-------------\n",
            "\n",
            "Epoch No:  5\n",
            "Steps Completed:  0\n",
            "Loss: 2.158982276916504 Accuracy: 0.453125\n",
            "Steps Completed:  50\n",
            "Loss: 2.57517147064209 Accuracy: 0.453125\n",
            "Steps Completed:  100\n",
            "Loss: 1.9103648662567139 Accuracy: 0.5\n",
            "Steps Completed:  150\n",
            "Loss: 1.3541467189788818 Accuracy: 0.4921875\n",
            "-------------\n",
            "\n",
            "Epoch No:  6\n",
            "Steps Completed:  0\n",
            "Loss: 2.180415153503418 Accuracy: 0.5390625\n",
            "Steps Completed:  50\n",
            "Loss: 2.2165942192077637 Accuracy: 0.5078125\n",
            "Steps Completed:  100\n",
            "Loss: 2.6868975162506104 Accuracy: 0.546875\n",
            "Steps Completed:  150\n",
            "Loss: 1.8959249258041382 Accuracy: 0.46875\n",
            "-------------\n",
            "\n",
            "Epoch No:  7\n",
            "Steps Completed:  0\n",
            "Loss: 3.0387189388275146 Accuracy: 0.4140625\n",
            "Steps Completed:  50\n",
            "Loss: 2.43223237991333 Accuracy: 0.40625\n",
            "Steps Completed:  100\n",
            "Loss: 2.9005987644195557 Accuracy: 0.4609375\n",
            "Steps Completed:  150\n",
            "Loss: 2.672055244445801 Accuracy: 0.46875\n",
            "-------------\n",
            "\n",
            "Epoch No:  8\n",
            "Steps Completed:  0\n",
            "Loss: 2.345604419708252 Accuracy: 0.546875\n",
            "Steps Completed:  50\n",
            "Loss: 1.9983172416687012 Accuracy: 0.4765625\n",
            "Steps Completed:  100\n",
            "Loss: 3.2382781505584717 Accuracy: 0.546875\n",
            "Steps Completed:  150\n",
            "Loss: 2.812091588973999 Accuracy: 0.4921875\n",
            "-------------\n",
            "\n",
            "Epoch No:  9\n",
            "Steps Completed:  0\n",
            "Loss: 1.6096947193145752 Accuracy: 0.546875\n",
            "Steps Completed:  50\n",
            "Loss: 2.513533115386963 Accuracy: 0.4921875\n",
            "Steps Completed:  100\n",
            "Loss: 2.831737518310547 Accuracy: 0.4609375\n",
            "Steps Completed:  150\n",
            "Loss: 2.5502848625183105 Accuracy: 0.484375\n",
            "-------------\n",
            "\n",
            "Final Test Accuracy Average: 0.5017628073692322 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03qlOMd6Mxtc"
      },
      "source": [
        "# Model2\n",
        "\n",
        "1.   With 20 Epochs\n",
        "2.   The test accuracy is 49.8%\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blbIJEVtMxth"
      },
      "source": [
        "## Weight Matrix Initializations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWdZ3CkrMxth"
      },
      "source": [
        "M2_W_HH = tf.Variable(tf.random.uniform([1, 128], minval=-0.5, maxval=0.5, dtype=np.float32))\n",
        "M2_b1 = tf.Variable(np.zeros((128, 1), dtype=np.float32))\n",
        "M2_W_IH = tf.Variable(tf.random.uniform([1, 20000], minval=-0.5, maxval=0.5, dtype=np.float32))\n",
        "M2_W_HO = tf.Variable(tf.random.uniform([128, 2], minval=-0.5, maxval=0.5, dtype=np.float32))\n",
        "M2_c1 = tf.Variable(np.zeros((128, 2), dtype=np.float32))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T52QkR4kMxth"
      },
      "source": [
        "## Training, Testing define"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nfqp-LpMxth"
      },
      "source": [
        "lr = 0.1\n",
        "def train_loop_m2(epochs):\n",
        "    for epoch in range(epochs):\n",
        "      print(\"Epoch No: \", epoch)\n",
        "      for stepCount, (sequence_batch, label_batch) in enumerate(train_data):\n",
        "          # label_batch = tf.reshape(label_batch, [1])\n",
        "          train_step(stepCount, sequence_batch, label_batch)\n",
        "      print(\"-------------\\n\")\n",
        "\n",
        "def test_loop_m2():\n",
        "    testAcc = []\n",
        "    for stepCount, (sequence_batch, label_batch) in enumerate(test_data):\n",
        "        # label_batch = tf.reshape(label_batch, [1])\n",
        "        testAcc.append(train_step(stepCount, sequence_batch, label_batch, True))\n",
        "\n",
        "    print(\"Final Test Accuracy Average: {} \".format(sum(testAcc)/len(testAcc)))\n",
        "\n",
        "\n",
        "def train_step_m2(step, sequences, labels, testFlag=False):\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = rnn_loop_m2(sequences)\n",
        "        xent = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "            logits=logits, labels=labels))\n",
        "\n",
        "    if testFlag != True:\n",
        "      grads = tape.gradient(xent, [M2_W_HH, M2_b1, M2_W_IH, M2_W_HO, M2_c1])\n",
        "\n",
        "      M2_W_HH.assign_sub(lr * grads[0])\n",
        "      M2_b1.assign_sub(lr * grads[1])\n",
        "      M2_W_IH.assign_sub(lr * grads[2])\n",
        "      M2_W_HO.assign_sub(lr * grads[3])\n",
        "      M2_c1.assign_sub(lr * grads[4])\n",
        "\n",
        "    if not step % 50 and testFlag != True:\n",
        "        print(\"Steps Completed: \", step)\n",
        "        preds = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
        "        acc = tf.reduce_mean(tf.cast(tf.equal(preds, labels), tf.float32))\n",
        "        print(\"Loss: {} Accuracy: {}\".format(xent, acc))\n",
        "    \n",
        "    # For testing the dataset\n",
        "    if testFlag == True:\n",
        "        preds = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
        "        acc = tf.reduce_mean(tf.cast(tf.equal(preds, labels), tf.float32))\n",
        "        return acc\n",
        "\n",
        "\n",
        "def rnn_loop_m2(sequences):\n",
        "    old_state = tf.Variable(np.zeros([100,1], dtype=np.float32))\n",
        "    seq_onehot = tf.one_hot(sequences, depth=num_words)\n",
        "\n",
        "    for step in range(max_words):\n",
        "        x_t = seq_onehot[:,step]\n",
        "        new_state = rnn_step_m2(old_state, x_t)\n",
        "        old_state = new_state\n",
        "\n",
        "    o_t = output_layer_m2(new_state)\n",
        "\n",
        "    return o_t\n",
        "\n",
        "def rnn_step_m2(state, x_t):\n",
        "    at = M2_b1 + tf.matmul(M2_W_HH, state) + tf.matmul(M2_W_IH, tf.transpose(x_t))\n",
        "    tanFun = tf.nn.tanh(at)\n",
        "    \n",
        "    return tanFun\n",
        "\n",
        "\n",
        "def output_layer_m2(new_state):\n",
        "    matMul = tf.matmul(tf.transpose(new_state), M2_W_HO)\n",
        "    ot = M2_c1 + matMul\n",
        "\n",
        "    return ot"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qO3HXsR0Mxti"
      },
      "source": [
        "## Running"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iika-QgyMxti",
        "outputId": "cce91428-8ccd-492e-eb39-d1972511aeff"
      },
      "source": [
        "train_loop_m2(20)\n",
        "test_loop_m2()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch No:  0\n",
            "Steps Completed:  0\n",
            "Loss: 1.7189579010009766 Accuracy: 0.5390625\n",
            "Steps Completed:  50\n",
            "Loss: 2.1390132904052734 Accuracy: 0.4921875\n",
            "Steps Completed:  100\n",
            "Loss: 3.5682075023651123 Accuracy: 0.4765625\n",
            "Steps Completed:  150\n",
            "Loss: 2.493283271789551 Accuracy: 0.5078125\n",
            "-------------\n",
            "\n",
            "Epoch No:  1\n",
            "Steps Completed:  0\n",
            "Loss: 3.0763745307922363 Accuracy: 0.390625\n",
            "Steps Completed:  50\n",
            "Loss: 2.7556538581848145 Accuracy: 0.4921875\n",
            "Steps Completed:  100\n",
            "Loss: 2.0477781295776367 Accuracy: 0.4296875\n",
            "Steps Completed:  150\n",
            "Loss: 2.451489210128784 Accuracy: 0.515625\n",
            "-------------\n",
            "\n",
            "Epoch No:  2\n",
            "Steps Completed:  0\n",
            "Loss: 3.0616815090179443 Accuracy: 0.46875\n",
            "Steps Completed:  50\n",
            "Loss: 2.6844284534454346 Accuracy: 0.484375\n",
            "Steps Completed:  100\n",
            "Loss: 3.9279706478118896 Accuracy: 0.46875\n",
            "Steps Completed:  150\n",
            "Loss: 2.6993408203125 Accuracy: 0.5546875\n",
            "-------------\n",
            "\n",
            "Epoch No:  3\n",
            "Steps Completed:  0\n",
            "Loss: 2.3693151473999023 Accuracy: 0.46875\n",
            "Steps Completed:  50\n",
            "Loss: 1.0983027219772339 Accuracy: 0.546875\n",
            "Steps Completed:  100\n",
            "Loss: 1.7797362804412842 Accuracy: 0.59375\n",
            "Steps Completed:  150\n",
            "Loss: 2.168935775756836 Accuracy: 0.4453125\n",
            "-------------\n",
            "\n",
            "Epoch No:  4\n",
            "Steps Completed:  0\n",
            "Loss: 2.221770763397217 Accuracy: 0.53125\n",
            "Steps Completed:  50\n",
            "Loss: 2.0107789039611816 Accuracy: 0.4140625\n",
            "Steps Completed:  100\n",
            "Loss: 2.247471570968628 Accuracy: 0.4765625\n",
            "Steps Completed:  150\n",
            "Loss: 1.6817724704742432 Accuracy: 0.5\n",
            "-------------\n",
            "\n",
            "Epoch No:  5\n",
            "Steps Completed:  0\n",
            "Loss: 3.8095293045043945 Accuracy: 0.515625\n",
            "Steps Completed:  50\n",
            "Loss: 2.2137374877929688 Accuracy: 0.5546875\n",
            "Steps Completed:  100\n",
            "Loss: 2.4629228115081787 Accuracy: 0.484375\n",
            "Steps Completed:  150\n",
            "Loss: 3.693178653717041 Accuracy: 0.4140625\n",
            "-------------\n",
            "\n",
            "Epoch No:  6\n",
            "Steps Completed:  0\n",
            "Loss: 0.9479951858520508 Accuracy: 0.4765625\n",
            "Steps Completed:  50\n",
            "Loss: 2.426703453063965 Accuracy: 0.5234375\n",
            "Steps Completed:  100\n",
            "Loss: 4.085389614105225 Accuracy: 0.4375\n",
            "Steps Completed:  150\n",
            "Loss: 2.347327709197998 Accuracy: 0.5\n",
            "-------------\n",
            "\n",
            "Epoch No:  7\n",
            "Steps Completed:  0\n",
            "Loss: 1.5181312561035156 Accuracy: 0.4375\n",
            "Steps Completed:  50\n",
            "Loss: 2.7269127368927 Accuracy: 0.515625\n",
            "Steps Completed:  100\n",
            "Loss: 2.6781022548675537 Accuracy: 0.5546875\n",
            "Steps Completed:  150\n",
            "Loss: 3.2858047485351562 Accuracy: 0.4609375\n",
            "-------------\n",
            "\n",
            "Epoch No:  8\n",
            "Steps Completed:  0\n",
            "Loss: 1.3732101917266846 Accuracy: 0.4375\n",
            "Steps Completed:  50\n",
            "Loss: 2.3363428115844727 Accuracy: 0.515625\n",
            "Steps Completed:  100\n",
            "Loss: 3.0057339668273926 Accuracy: 0.53125\n",
            "Steps Completed:  150\n",
            "Loss: 3.020214080810547 Accuracy: 0.515625\n",
            "-------------\n",
            "\n",
            "Epoch No:  9\n",
            "Steps Completed:  0\n",
            "Loss: 2.8534584045410156 Accuracy: 0.4453125\n",
            "Steps Completed:  50\n",
            "Loss: 2.3863046169281006 Accuracy: 0.6015625\n",
            "Steps Completed:  100\n",
            "Loss: 3.223714828491211 Accuracy: 0.4375\n",
            "Steps Completed:  150\n",
            "Loss: 2.911752939224243 Accuracy: 0.53125\n",
            "-------------\n",
            "\n",
            "Epoch No:  10\n",
            "Steps Completed:  0\n",
            "Loss: 1.617022156715393 Accuracy: 0.515625\n",
            "Steps Completed:  50\n",
            "Loss: 2.487940549850464 Accuracy: 0.4921875\n",
            "Steps Completed:  100\n",
            "Loss: 2.625218629837036 Accuracy: 0.515625\n",
            "Steps Completed:  150\n",
            "Loss: 2.382362127304077 Accuracy: 0.46875\n",
            "-------------\n",
            "\n",
            "Epoch No:  11\n",
            "Steps Completed:  0\n",
            "Loss: 2.738508701324463 Accuracy: 0.53125\n",
            "Steps Completed:  50\n",
            "Loss: 1.8477885723114014 Accuracy: 0.5\n",
            "Steps Completed:  100\n",
            "Loss: 2.5689868927001953 Accuracy: 0.53125\n",
            "Steps Completed:  150\n",
            "Loss: 2.968923807144165 Accuracy: 0.4453125\n",
            "-------------\n",
            "\n",
            "Epoch No:  12\n",
            "Steps Completed:  0\n",
            "Loss: 1.7869820594787598 Accuracy: 0.53125\n",
            "Steps Completed:  50\n",
            "Loss: 2.044978141784668 Accuracy: 0.4921875\n",
            "Steps Completed:  100\n",
            "Loss: 2.428290843963623 Accuracy: 0.5390625\n",
            "Steps Completed:  150\n",
            "Loss: 2.2108049392700195 Accuracy: 0.4375\n",
            "-------------\n",
            "\n",
            "Epoch No:  13\n",
            "Steps Completed:  0\n",
            "Loss: 2.3022642135620117 Accuracy: 0.5546875\n",
            "Steps Completed:  50\n",
            "Loss: 1.678393006324768 Accuracy: 0.625\n",
            "Steps Completed:  100\n",
            "Loss: 0.9254698157310486 Accuracy: 0.515625\n",
            "Steps Completed:  150\n",
            "Loss: 2.1331353187561035 Accuracy: 0.5\n",
            "-------------\n",
            "\n",
            "Epoch No:  14\n",
            "Steps Completed:  0\n",
            "Loss: 2.980703830718994 Accuracy: 0.5\n",
            "Steps Completed:  50\n",
            "Loss: 2.218785285949707 Accuracy: 0.4765625\n",
            "Steps Completed:  100\n",
            "Loss: 2.1574149131774902 Accuracy: 0.4453125\n",
            "Steps Completed:  150\n",
            "Loss: 2.280305862426758 Accuracy: 0.53125\n",
            "-------------\n",
            "\n",
            "Epoch No:  15\n",
            "Steps Completed:  0\n",
            "Loss: 4.009909152984619 Accuracy: 0.4765625\n",
            "Steps Completed:  50\n",
            "Loss: 1.7063417434692383 Accuracy: 0.53125\n",
            "Steps Completed:  100\n",
            "Loss: 2.1143836975097656 Accuracy: 0.5546875\n",
            "Steps Completed:  150\n",
            "Loss: 1.5758591890335083 Accuracy: 0.578125\n",
            "-------------\n",
            "\n",
            "Epoch No:  16\n",
            "Steps Completed:  0\n",
            "Loss: 2.065742254257202 Accuracy: 0.5703125\n",
            "Steps Completed:  50\n",
            "Loss: 1.8389297723770142 Accuracy: 0.546875\n",
            "Steps Completed:  100\n",
            "Loss: 2.1475234031677246 Accuracy: 0.546875\n",
            "Steps Completed:  150\n",
            "Loss: 2.7293546199798584 Accuracy: 0.515625\n",
            "-------------\n",
            "\n",
            "Epoch No:  17\n",
            "Steps Completed:  0\n",
            "Loss: 2.9711923599243164 Accuracy: 0.453125\n",
            "Steps Completed:  50\n",
            "Loss: 2.747535228729248 Accuracy: 0.5390625\n",
            "Steps Completed:  100\n",
            "Loss: 2.361100912094116 Accuracy: 0.578125\n",
            "Steps Completed:  150\n",
            "Loss: 3.6832523345947266 Accuracy: 0.40625\n",
            "-------------\n",
            "\n",
            "Epoch No:  18\n",
            "Steps Completed:  0\n",
            "Loss: 3.2890820503234863 Accuracy: 0.484375\n",
            "Steps Completed:  50\n",
            "Loss: 1.684952735900879 Accuracy: 0.53125\n",
            "Steps Completed:  100\n",
            "Loss: 1.448878288269043 Accuracy: 0.5078125\n",
            "Steps Completed:  150\n",
            "Loss: 1.5114855766296387 Accuracy: 0.5\n",
            "-------------\n",
            "\n",
            "Epoch No:  19\n",
            "Steps Completed:  0\n",
            "Loss: 1.7845430374145508 Accuracy: 0.4765625\n",
            "Steps Completed:  50\n",
            "Loss: 2.2473204135894775 Accuracy: 0.5234375\n",
            "Steps Completed:  100\n",
            "Loss: 1.7979680299758911 Accuracy: 0.578125\n",
            "Steps Completed:  150\n",
            "Loss: 1.9867801666259766 Accuracy: 0.46875\n",
            "-------------\n",
            "\n",
            "Final Test Accuracy Average: 0.4981570541858673 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQBIv51UX9E-"
      },
      "source": [
        "# Model3\n",
        "\n",
        "1.   With 20 Epochs\n",
        "2.   The test accuracy is 49.8%\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkA2ykYGX9FH"
      },
      "source": [
        "## Weight Matrix Initializations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smsAyek8X9FH"
      },
      "source": [
        "M3_W_HH = tf.Variable(tf.random.uniform([1, 128], minval=-0.5, maxval=0.5, dtype=np.float32))\n",
        "M3_b1 = tf.Variable(np.zeros((128, 1), dtype=np.float32))\n",
        "M3_W_IH = tf.Variable(tf.random.uniform([1, 20000], minval=-0.5, maxval=0.5, dtype=np.float32))\n",
        "M3_W_HO = tf.Variable(tf.random.uniform([128, 2], minval=-0.5, maxval=0.5, dtype=np.float32))\n",
        "M3_c1 = tf.Variable(np.zeros((128, 2), dtype=np.float32))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJrJ00zDX9FH"
      },
      "source": [
        "## Training, Testing define"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NswthqefX9FI"
      },
      "source": [
        "lr = 0.1\n",
        "def train_loop_m3(epochs):\n",
        "    for epoch in range(epochs):\n",
        "      print(\"Epoch No: \", epoch)\n",
        "      for stepCount, (sequence_batch, label_batch) in enumerate(train_data):\n",
        "          # label_batch = tf.reshape(label_batch, [1])\n",
        "          train_step(stepCount, sequence_batch, label_batch)\n",
        "      print(\"-------------\\n\")\n",
        "\n",
        "def test_loop_m3():\n",
        "    testAcc = []\n",
        "    for stepCount, (sequence_batch, label_batch) in enumerate(test_data):\n",
        "        # label_batch = tf.reshape(label_batch, [1])\n",
        "        testAcc.append(train_step(stepCount, sequence_batch, label_batch, True))\n",
        "\n",
        "    print(\"Final Test Accuracy Average: {} \".format(sum(testAcc)/len(testAcc)))\n",
        "\n",
        "\n",
        "def train_step_m3(step, sequences, labels, testFlag=False):\n",
        "    with tf.GradientTape() as tape:\n",
        "        logits = rnn_loop_m3(sequences)\n",
        "        xent = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "            logits=logits, labels=labels))\n",
        "\n",
        "    if testFlag != True:\n",
        "      grads = tape.gradient(xent, [M3_W_HH, M3_b1, M3_W_IH, M3_W_HO, M3_c1])\n",
        "\n",
        "      M3_W_HH.assign_sub(lr * grads[0])\n",
        "      M3_b1.assign_sub(lr * grads[1])\n",
        "      M3_W_IH.assign_sub(lr * grads[2])\n",
        "      M3_W_HO.assign_sub(lr * grads[3])\n",
        "      M3_c1.assign_sub(lr * grads[4])\n",
        "\n",
        "    if not step % 50 and testFlag != True:\n",
        "        print(\"Steps Completed: \", step)\n",
        "        preds = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
        "        acc = tf.reduce_mean(tf.cast(tf.equal(preds, labels), tf.float32))\n",
        "        print(\"Loss: {} Accuracy: {}\".format(xent, acc))\n",
        "    \n",
        "    # For testing the dataset\n",
        "    if testFlag == True:\n",
        "        preds = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
        "        acc = tf.reduce_mean(tf.cast(tf.equal(preds, labels), tf.float32))\n",
        "        return acc\n",
        "\n",
        "\n",
        "def rnn_loop_m3(sequences):\n",
        "    old_state = tf.Variable(np.zeros([100,1], dtype=np.float32))\n",
        "    seq_onehot = tf.one_hot(sequences, depth=num_words)\n",
        "\n",
        "    for step in range(max_words):\n",
        "        x_t = seq_onehot[:,step]\n",
        "        new_state = rnn_step_m3(old_state, x_t)\n",
        "        old_state = new_state\n",
        "\n",
        "    o_t = output_layer_m3(new_state)\n",
        "\n",
        "    return o_t\n",
        "\n",
        "def rnn_step_m3(state, x_t):\n",
        "    at = M2_b1 + tf.matmul(M2_W_HH, state) + tf.matmul(M2_W_IH, tf.transpose(x_t))\n",
        "    tanFun = tf.nn.tanh(at)\n",
        "    \n",
        "    return tanFun\n",
        "\n",
        "\n",
        "def output_layer_m3(new_state):\n",
        "    matMul = tf.matmul(tf.transpose(new_state), M2_W_HO)\n",
        "    ot = M2_c1 + matMul\n",
        "\n",
        "    return ot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CDX0aBFX9FI"
      },
      "source": [
        "## Running"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aq7BVc8HX9FI",
        "outputId": "cce91428-8ccd-492e-eb39-d1972511aeff"
      },
      "source": [
        "train_loop_m2(20)\n",
        "test_loop_m2()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch No:  0\n",
            "Steps Completed:  0\n",
            "Loss: 1.7189579010009766 Accuracy: 0.5390625\n",
            "Steps Completed:  50\n",
            "Loss: 2.1390132904052734 Accuracy: 0.4921875\n",
            "Steps Completed:  100\n",
            "Loss: 3.5682075023651123 Accuracy: 0.4765625\n",
            "Steps Completed:  150\n",
            "Loss: 2.493283271789551 Accuracy: 0.5078125\n",
            "-------------\n",
            "\n",
            "Epoch No:  1\n",
            "Steps Completed:  0\n",
            "Loss: 3.0763745307922363 Accuracy: 0.390625\n",
            "Steps Completed:  50\n",
            "Loss: 2.7556538581848145 Accuracy: 0.4921875\n",
            "Steps Completed:  100\n",
            "Loss: 2.0477781295776367 Accuracy: 0.4296875\n",
            "Steps Completed:  150\n",
            "Loss: 2.451489210128784 Accuracy: 0.515625\n",
            "-------------\n",
            "\n",
            "Epoch No:  2\n",
            "Steps Completed:  0\n",
            "Loss: 3.0616815090179443 Accuracy: 0.46875\n",
            "Steps Completed:  50\n",
            "Loss: 2.6844284534454346 Accuracy: 0.484375\n",
            "Steps Completed:  100\n",
            "Loss: 3.9279706478118896 Accuracy: 0.46875\n",
            "Steps Completed:  150\n",
            "Loss: 2.6993408203125 Accuracy: 0.5546875\n",
            "-------------\n",
            "\n",
            "Epoch No:  3\n",
            "Steps Completed:  0\n",
            "Loss: 2.3693151473999023 Accuracy: 0.46875\n",
            "Steps Completed:  50\n",
            "Loss: 1.0983027219772339 Accuracy: 0.546875\n",
            "Steps Completed:  100\n",
            "Loss: 1.7797362804412842 Accuracy: 0.59375\n",
            "Steps Completed:  150\n",
            "Loss: 2.168935775756836 Accuracy: 0.4453125\n",
            "-------------\n",
            "\n",
            "Epoch No:  4\n",
            "Steps Completed:  0\n",
            "Loss: 2.221770763397217 Accuracy: 0.53125\n",
            "Steps Completed:  50\n",
            "Loss: 2.0107789039611816 Accuracy: 0.4140625\n",
            "Steps Completed:  100\n",
            "Loss: 2.247471570968628 Accuracy: 0.4765625\n",
            "Steps Completed:  150\n",
            "Loss: 1.6817724704742432 Accuracy: 0.5\n",
            "-------------\n",
            "\n",
            "Epoch No:  5\n",
            "Steps Completed:  0\n",
            "Loss: 3.8095293045043945 Accuracy: 0.515625\n",
            "Steps Completed:  50\n",
            "Loss: 2.2137374877929688 Accuracy: 0.5546875\n",
            "Steps Completed:  100\n",
            "Loss: 2.4629228115081787 Accuracy: 0.484375\n",
            "Steps Completed:  150\n",
            "Loss: 3.693178653717041 Accuracy: 0.4140625\n",
            "-------------\n",
            "\n",
            "Epoch No:  6\n",
            "Steps Completed:  0\n",
            "Loss: 0.9479951858520508 Accuracy: 0.4765625\n",
            "Steps Completed:  50\n",
            "Loss: 2.426703453063965 Accuracy: 0.5234375\n",
            "Steps Completed:  100\n",
            "Loss: 4.085389614105225 Accuracy: 0.4375\n",
            "Steps Completed:  150\n",
            "Loss: 2.347327709197998 Accuracy: 0.5\n",
            "-------------\n",
            "\n",
            "Epoch No:  7\n",
            "Steps Completed:  0\n",
            "Loss: 1.5181312561035156 Accuracy: 0.4375\n",
            "Steps Completed:  50\n",
            "Loss: 2.7269127368927 Accuracy: 0.515625\n",
            "Steps Completed:  100\n",
            "Loss: 2.6781022548675537 Accuracy: 0.5546875\n",
            "Steps Completed:  150\n",
            "Loss: 3.2858047485351562 Accuracy: 0.4609375\n",
            "-------------\n",
            "\n",
            "Epoch No:  8\n",
            "Steps Completed:  0\n",
            "Loss: 1.3732101917266846 Accuracy: 0.4375\n",
            "Steps Completed:  50\n",
            "Loss: 2.3363428115844727 Accuracy: 0.515625\n",
            "Steps Completed:  100\n",
            "Loss: 3.0057339668273926 Accuracy: 0.53125\n",
            "Steps Completed:  150\n",
            "Loss: 3.020214080810547 Accuracy: 0.515625\n",
            "-------------\n",
            "\n",
            "Epoch No:  9\n",
            "Steps Completed:  0\n",
            "Loss: 2.8534584045410156 Accuracy: 0.4453125\n",
            "Steps Completed:  50\n",
            "Loss: 2.3863046169281006 Accuracy: 0.6015625\n",
            "Steps Completed:  100\n",
            "Loss: 3.223714828491211 Accuracy: 0.4375\n",
            "Steps Completed:  150\n",
            "Loss: 2.911752939224243 Accuracy: 0.53125\n",
            "-------------\n",
            "\n",
            "Epoch No:  10\n",
            "Steps Completed:  0\n",
            "Loss: 1.617022156715393 Accuracy: 0.515625\n",
            "Steps Completed:  50\n",
            "Loss: 2.487940549850464 Accuracy: 0.4921875\n",
            "Steps Completed:  100\n",
            "Loss: 2.625218629837036 Accuracy: 0.515625\n",
            "Steps Completed:  150\n",
            "Loss: 2.382362127304077 Accuracy: 0.46875\n",
            "-------------\n",
            "\n",
            "Epoch No:  11\n",
            "Steps Completed:  0\n",
            "Loss: 2.738508701324463 Accuracy: 0.53125\n",
            "Steps Completed:  50\n",
            "Loss: 1.8477885723114014 Accuracy: 0.5\n",
            "Steps Completed:  100\n",
            "Loss: 2.5689868927001953 Accuracy: 0.53125\n",
            "Steps Completed:  150\n",
            "Loss: 2.968923807144165 Accuracy: 0.4453125\n",
            "-------------\n",
            "\n",
            "Epoch No:  12\n",
            "Steps Completed:  0\n",
            "Loss: 1.7869820594787598 Accuracy: 0.53125\n",
            "Steps Completed:  50\n",
            "Loss: 2.044978141784668 Accuracy: 0.4921875\n",
            "Steps Completed:  100\n",
            "Loss: 2.428290843963623 Accuracy: 0.5390625\n",
            "Steps Completed:  150\n",
            "Loss: 2.2108049392700195 Accuracy: 0.4375\n",
            "-------------\n",
            "\n",
            "Epoch No:  13\n",
            "Steps Completed:  0\n",
            "Loss: 2.3022642135620117 Accuracy: 0.5546875\n",
            "Steps Completed:  50\n",
            "Loss: 1.678393006324768 Accuracy: 0.625\n",
            "Steps Completed:  100\n",
            "Loss: 0.9254698157310486 Accuracy: 0.515625\n",
            "Steps Completed:  150\n",
            "Loss: 2.1331353187561035 Accuracy: 0.5\n",
            "-------------\n",
            "\n",
            "Epoch No:  14\n",
            "Steps Completed:  0\n",
            "Loss: 2.980703830718994 Accuracy: 0.5\n",
            "Steps Completed:  50\n",
            "Loss: 2.218785285949707 Accuracy: 0.4765625\n",
            "Steps Completed:  100\n",
            "Loss: 2.1574149131774902 Accuracy: 0.4453125\n",
            "Steps Completed:  150\n",
            "Loss: 2.280305862426758 Accuracy: 0.53125\n",
            "-------------\n",
            "\n",
            "Epoch No:  15\n",
            "Steps Completed:  0\n",
            "Loss: 4.009909152984619 Accuracy: 0.4765625\n",
            "Steps Completed:  50\n",
            "Loss: 1.7063417434692383 Accuracy: 0.53125\n",
            "Steps Completed:  100\n",
            "Loss: 2.1143836975097656 Accuracy: 0.5546875\n",
            "Steps Completed:  150\n",
            "Loss: 1.5758591890335083 Accuracy: 0.578125\n",
            "-------------\n",
            "\n",
            "Epoch No:  16\n",
            "Steps Completed:  0\n",
            "Loss: 2.065742254257202 Accuracy: 0.5703125\n",
            "Steps Completed:  50\n",
            "Loss: 1.8389297723770142 Accuracy: 0.546875\n",
            "Steps Completed:  100\n",
            "Loss: 2.1475234031677246 Accuracy: 0.546875\n",
            "Steps Completed:  150\n",
            "Loss: 2.7293546199798584 Accuracy: 0.515625\n",
            "-------------\n",
            "\n",
            "Epoch No:  17\n",
            "Steps Completed:  0\n",
            "Loss: 2.9711923599243164 Accuracy: 0.453125\n",
            "Steps Completed:  50\n",
            "Loss: 2.747535228729248 Accuracy: 0.5390625\n",
            "Steps Completed:  100\n",
            "Loss: 2.361100912094116 Accuracy: 0.578125\n",
            "Steps Completed:  150\n",
            "Loss: 3.6832523345947266 Accuracy: 0.40625\n",
            "-------------\n",
            "\n",
            "Epoch No:  18\n",
            "Steps Completed:  0\n",
            "Loss: 3.2890820503234863 Accuracy: 0.484375\n",
            "Steps Completed:  50\n",
            "Loss: 1.684952735900879 Accuracy: 0.53125\n",
            "Steps Completed:  100\n",
            "Loss: 1.448878288269043 Accuracy: 0.5078125\n",
            "Steps Completed:  150\n",
            "Loss: 1.5114855766296387 Accuracy: 0.5\n",
            "-------------\n",
            "\n",
            "Epoch No:  19\n",
            "Steps Completed:  0\n",
            "Loss: 1.7845430374145508 Accuracy: 0.4765625\n",
            "Steps Completed:  50\n",
            "Loss: 2.2473204135894775 Accuracy: 0.5234375\n",
            "Steps Completed:  100\n",
            "Loss: 1.7979680299758911 Accuracy: 0.578125\n",
            "Steps Completed:  150\n",
            "Loss: 1.9867801666259766 Accuracy: 0.46875\n",
            "-------------\n",
            "\n",
            "Final Test Accuracy Average: 0.4981570541858673 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW6u4DcOG2aZ"
      },
      "source": [
        "# References\n",
        "\n",
        "\n",
        "1.   https://towardsdatascience.com/a-beginners-guide-on-sentiment-analysis-with-rnn-9e100627c02e\n",
        "2.   List item\n",
        "\n"
      ]
    }
  ]
}