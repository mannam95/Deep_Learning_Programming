{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_5_RNN_Part1_Srinath.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "9b1ec548",
        "0c34550c",
        "c715ac7b",
        "-dv0CvhD7Yga",
        "Fc9OZbtI7oPF",
        "NUD_v_L21y2A",
        "gWJ6KpLz60sM",
        "7PH1icKQ8fmG",
        "y8NysXi27_Gg",
        "xiB5DU5SAKLG",
        "fiTvrH56GhH5",
        "03qlOMd6Mxtc",
        "blbIJEVtMxth",
        "T52QkR4kMxth",
        "qO3HXsR0Mxti",
        "kQBIv51UX9E-"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mannam95/Deep_Learning_Programming/blob/main/Assignment5/Assignment_5_RNN_Part1_Srinath.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6aef94d"
      },
      "source": [
        "# Team Assignment\n",
        "\n",
        "\n",
        "1.   Srinath Mannam (229750)\n",
        "2.   Meghana Rao (234907)\n",
        "3.   Govind Shukla (235192)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9b1ec548"
      },
      "source": [
        "# import statements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85eb7211"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from keras.regularizers import l2\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from numba import cuda\n",
        "import sys\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.python.keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "import pydot\n",
        "import graphviz\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from datetime import datetime\n",
        "from keras.preprocessing import sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c34550c"
      },
      "source": [
        "# Change the directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94b2626e"
      },
      "source": [
        "working_directory = '/content/drive/My Drive/Colab Notebooks/OVGU/Deep_Learning/05_Assignment'\n",
        "def colabDrive():\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "\n",
        "    if os.getcwd() !=  working_directory:\n",
        "      os.chdir(working_directory)\n",
        "    print(os.getcwd())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8540ed4"
      },
      "source": [
        "#colabDrive()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c715ac7b"
      },
      "source": [
        "# Clears GPU memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "591268b2"
      },
      "source": [
        "def clearGPUMemory():\n",
        "    from numba import cuda \n",
        "    device = cuda.get_current_device()\n",
        "    device.reset()\n",
        "    !nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "caee9b53"
      },
      "source": [
        "#clearGPUMemory()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6mjm447GMHX"
      },
      "source": [
        "# Prepare the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dv0CvhD7Yga"
      },
      "source": [
        "## Load the dataset and remove infrequent words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVE7aMvC4iXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f6ec0d6-0703-4d29-e089-8c5c4369c178"
      },
      "source": [
        "num_words = 20000\n",
        "(train_sequences, train_labels), (test_sequences, test_labels) = tf.keras.datasets.imdb.load_data(num_words=num_words)\n",
        "\n",
        "print('Loaded dataset with {} training samples, {} test samples'.format(len(train_sequences), len(test_sequences)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n",
            "Loaded dataset with 25000 training samples, 25000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc9OZbtI7oPF"
      },
      "source": [
        "## Have some look at train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c07u7Z7s4opk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8613ec0-5a12-4857-ab95-13fb9c460686"
      },
      "source": [
        "# look at some sequences. words have been replaced with arbitrary index mappings\n",
        "# 1 is a special \"beginning of sequence\" marker\n",
        "# infrequent words have been replaced by the index 2\n",
        "# actual words start with index 4, 3 is never used (???)\n",
        "train_sequences[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
              "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
              "       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFCZvjGjuy1v",
        "outputId": "e5657ce0-8fd4-4e11-9ada-f82dc4003648"
      },
      "source": [
        "print('---review---')\n",
        "print(train_sequences[6])\n",
        "print('---label---')\n",
        "print(train_labels[6])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---review---\n",
            "[1, 6740, 365, 1234, 5, 1156, 354, 11, 14, 5327, 6638, 7, 1016, 10626, 5940, 356, 44, 4, 1349, 500, 746, 5, 200, 4, 4132, 11, 16393, 9363, 1117, 1831, 7485, 5, 4831, 26, 6, 2, 4183, 17, 369, 37, 215, 1345, 143, 2, 5, 1838, 8, 1974, 15, 36, 119, 257, 85, 52, 486, 9, 6, 2, 8564, 63, 271, 6, 196, 96, 949, 4121, 4, 2, 7, 4, 2212, 2436, 819, 63, 47, 77, 7175, 180, 6, 227, 11, 94, 2494, 2, 13, 423, 4, 168, 7, 4, 22, 5, 89, 665, 71, 270, 56, 5, 13, 197, 12, 161, 5390, 99, 76, 23, 2, 7, 419, 665, 40, 91, 85, 108, 7, 4, 2084, 5, 4773, 81, 55, 52, 1901]\n",
            "---label---\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUD_v_L21y2A"
      },
      "source": [
        "## to restore words, load the word-to-index mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYX6F3AX5hpV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffb729ea-f33d-4a57-aff5-70fe125e36c7"
      },
      "source": [
        "word2id = tf.keras.datasets.imdb.get_word_index()\n",
        "id2word = {i: word for word, i in word2id.items()}\n",
        "print('---review with words---')\n",
        "print([id2word.get(i, ' ') for i in train_sequences[6]])\n",
        "print('---label---')\n",
        "print(train_sequences[6])\n",
        "print('---label---')\n",
        "print(train_labels[6])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n",
            "---review with words---\n",
            "['the', 'boiled', 'full', 'involving', 'to', 'impressive', 'boring', 'this', 'as', 'murdering', 'naschy', 'br', 'villain', 'council', 'suggestion', 'need', 'has', 'of', 'costumes', 'b', 'message', 'to', 'may', 'of', 'props', 'this', 'echoed', 'concentrates', 'concept', 'issue', 'skeptical', 'to', \"god's\", 'he', 'is', 'and', 'unfolds', 'movie', 'women', 'like', \"isn't\", 'surely', \"i'm\", 'and', 'to', 'toward', 'in', \"here's\", 'for', 'from', 'did', 'having', 'because', 'very', 'quality', 'it', 'is', 'and', 'starship', 'really', 'book', 'is', 'both', 'too', 'worked', 'carl', 'of', 'and', 'br', 'of', 'reviewer', 'closer', 'figure', 'really', 'there', 'will', 'originals', 'things', 'is', 'far', 'this', 'make', 'mistakes', 'and', 'was', \"couldn't\", 'of', 'few', 'br', 'of', 'you', 'to', \"don't\", 'female', 'than', 'place', 'she', 'to', 'was', 'between', 'that', 'nothing', 'dose', 'movies', 'get', 'are', 'and', 'br', 'yes', 'female', 'just', 'its', 'because', 'many', 'br', 'of', 'overly', 'to', 'descent', 'people', 'time', 'very', 'bland']\n",
            "---label---\n",
            "[1, 6740, 365, 1234, 5, 1156, 354, 11, 14, 5327, 6638, 7, 1016, 10626, 5940, 356, 44, 4, 1349, 500, 746, 5, 200, 4, 4132, 11, 16393, 9363, 1117, 1831, 7485, 5, 4831, 26, 6, 2, 4183, 17, 369, 37, 215, 1345, 143, 2, 5, 1838, 8, 1974, 15, 36, 119, 257, 85, 52, 486, 9, 6, 2, 8564, 63, 271, 6, 196, 96, 949, 4121, 4, 2, 7, 4, 2212, 2436, 819, 63, 47, 77, 7175, 180, 6, 227, 11, 94, 2494, 2, 13, 423, 4, 168, 7, 4, 22, 5, 89, 665, 71, 270, 56, 5, 13, 197, 12, 161, 5390, 99, 76, 23, 2, 7, 419, 665, 40, 91, 85, 108, 7, 4, 2084, 5, 4773, 81, 55, 52, 1901]\n",
            "---label---\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWJ6KpLz60sM"
      },
      "source": [
        "## Maximum review length and minimum review length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6LZSJS_62Ye",
        "outputId": "717baa1c-f660-4e85-fca1-bfc8264db75b"
      },
      "source": [
        "print('Maximum review length: {}'.format(len(max((train_sequences + test_sequences), key=len))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum review length: 2697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XMcFfgQ7H-O",
        "outputId": "1584ea62-ab29-47f5-f21d-ea68335449fd"
      },
      "source": [
        "print('Minimum review length: {}'.format(len(min((train_sequences + test_sequences), key=len))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum review length: 70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PH1icKQ8fmG"
      },
      "source": [
        "## Overview over the sequence length in the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpWf-SfA8d0d",
        "outputId": "8ef16f61-2219-49bf-b4b7-0292e65ff72f"
      },
      "source": [
        "sequence_lengths = [len(sequence) for sequence in train_sequences]\n",
        "max_len = max(sequence_lengths)\n",
        "max_len\n",
        "\n",
        "plt.hist(sequence_lengths, bins=80)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnxcVXiV7EZy"
      },
      "source": [
        "## Pad Sequences  to some length because the dataset should be in rectangular for feeding to tensors\n",
        "\n",
        "*  all sequences above maxlen will be truncated to that length\n",
        "*  note: pad_sequences has \"pre\" and \"post\" options for both padding and truncation. one may be better than the other!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDFYpy4Q8LH9"
      },
      "source": [
        "max_words = 300\n",
        "train_sequences = sequence.pad_sequences(train_sequences, maxlen=max_words, padding = \"post\", truncating = \"post\")\n",
        "test_sequences = sequence.pad_sequences(test_sequences, maxlen=max_words, padding = \"post\", truncating = \"post\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-sxPAMPF9GRf"
      },
      "source": [
        "## Load the dataset into tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1YiFTf89KzS"
      },
      "source": [
        "train_labels = train_labels.reshape(-1).astype(np.int32)\n",
        "test_labels = test_labels.reshape(-1).astype(np.int32)\n",
        "# train_data = tf.data.Dataset.from_tensor_slices((train_sequences, train_labels))\n",
        "# test_data = tf.data.Dataset.from_tensor_slices((test_sequences, test_labels))\n",
        "\n",
        "train_data = tf.data.Dataset.from_tensor_slices((train_sequences, train_labels)).shuffle(25000).batch(128, drop_remainder=True)\n",
        "test_data = tf.data.Dataset.from_tensor_slices((test_sequences, test_labels)).batch(128, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epD2fyBM-CKA",
        "outputId": "208e27e9-c876-4fba-b33e-41df02b9f7c9"
      },
      "source": [
        "print(\"Training Dataset Size: \",train_sequences.shape)\n",
        "print(\"Test Dataset Size: \",test_sequences.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset Size:  (25000, 300)\n",
            "Test Dataset Size:  (25000, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiB5DU5SAKLG"
      },
      "source": [
        "# Models Config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7TIRqNmFSXS"
      },
      "source": [
        "## Model1 Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12k45HYkAJY8"
      },
      "source": [
        "modelConfig1 = {\n",
        "    \"epochs\" : 10,\n",
        "    \"learning_rate\" : 0.1,\n",
        "\n",
        "    ##Input to hidden(U)\n",
        "    \"W_Inp_Hid\":  tf.Variable(tf.random.uniform([20000, 64], minval=-0.1, maxval=0.1, dtype=np.float32)),\n",
        "    ##Initial Previous hidden(ht-1)\n",
        "    \"Init_Prev_Hidden\":  tf.Variable(np.zeros([1,64], dtype=np.float32)),\n",
        "    ##Hidden to hidden(W)\n",
        "    \"W_Hid_Hid\":  tf.Variable(tf.random.uniform([64, 64], minval=-0.1, maxval=0.1, dtype=np.float32)),\n",
        "    ##bias(b)\n",
        "    \"b\": tf.Variable(np.zeros((1, 64), dtype=np.float32)),\n",
        "    ##Hidden to hidden(W)\n",
        "    \"W_Hid_Out\":  tf.Variable(tf.random.uniform([64, 2], minval=-0.1, maxval=0.1, dtype=np.float32)),\n",
        "    ##bias(c)\n",
        "    \"c\": tf.Variable(np.zeros((128, 2), dtype=np.float32))\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiTvrH56GhH5"
      },
      "source": [
        "# Generic Function for training, testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYP3UFTgN5gq"
      },
      "source": [
        "## RNN Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JheLUJCjN4Eb"
      },
      "source": [
        "def rnn_loop(sequences, modelConfig):\n",
        "    old_state = modelConfig['Init_Prev_Hidden']\n",
        "    seq_onehot = tf.one_hot(sequences, depth=num_words)\n",
        "\n",
        "    for step in range(max_words):\n",
        "        x_t = seq_onehot[:,step]\n",
        "        at = modelConfig['b'] + tf.matmul(old_state, modelConfig['W_Hid_Hid']) + tf.matmul(x_t, modelConfig['W_Inp_Hid'])\n",
        "        new_state = tf.nn.tanh(at)\n",
        "        old_state = new_state\n",
        "\n",
        "    o_t = modelConfig['c'] + tf.matmul(new_state, modelConfig['W_Hid_Out'])\n",
        "\n",
        "    return o_t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2o29F7hN7mI"
      },
      "source": [
        "## Training and Test Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEw-Xlx3_OsU"
      },
      "source": [
        "def train_loop(modelConfig):\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=modelConfig['learning_rate'])\n",
        "    for epoch in range(modelConfig['epochs']):\n",
        "      print(\"Epoch No: \", epoch)\n",
        "      for step, (sequence_batch, label_batch) in enumerate(train_data):\n",
        "          # label_batch = tf.reshape(label_batch, [1])\n",
        "          with tf.GradientTape() as tape:\n",
        "              logits = rnn_loop(sequence_batch, modelConfig)\n",
        "              xent = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "                  logits=logits, labels=label_batch))\n",
        "\n",
        "          ## Gradients calculation and update weights\n",
        "          grads = tape.gradient(xent, [modelConfig['W_Inp_Hid'], modelConfig['W_Hid_Hid'], modelConfig['b'], modelConfig['W_Hid_Out'], modelConfig['c']])\n",
        "          optimizer.apply_gradients(zip(grads, [modelConfig['W_Inp_Hid'], modelConfig['W_Hid_Hid'], modelConfig['b'], modelConfig['W_Hid_Out'], modelConfig['c']]))\n",
        "\n",
        "\n",
        "          if not step % 50:\n",
        "              print(\"Steps Completed: \", step)\n",
        "              preds = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
        "              acc = tf.reduce_mean(tf.cast(tf.equal(preds, label_batch), tf.float32))\n",
        "              print(\"Loss: {} Accuracy: {}\".format(xent, acc))\n",
        "          \n",
        "      print(\"-------------\\n\")\n",
        "\n",
        "    #Testing\n",
        "    print(\"Working on test dataset\")\n",
        "    testAcc = []\n",
        "    for step, (sequence_batch, label_batch) in enumerate(test_data):\n",
        "        if not step % 50:\n",
        "          print(\"Steps Completed: \", step)\n",
        "        logits = rnn_loop(sequence_batch, modelConfig)\n",
        "        preds = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
        "        acc = tf.reduce_mean(tf.cast(tf.equal(preds, label_batch), tf.float32))\n",
        "        testAcc.append(acc)\n",
        "\n",
        "    print(\"Final Test Accuracy Average: {} \".format(sum(testAcc)/len(testAcc)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8NysXi27_Gg"
      },
      "source": [
        "# Different Models Running\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJ2rkiuXOJTn"
      },
      "source": [
        "## Model1\n",
        "\n",
        "1.   With 10 Epochs\n",
        "2.   The test accuracy is 49.6%\n",
        "3.   Batch Size of 128\n",
        "4.   Hidden layer neurons are 64\n",
        "5.   Max corpus length 20000\n",
        "6.   Max words 300, padding post, truncating post"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soqgTuHHOIxk",
        "outputId": "09df6c38-70b4-4217-b64b-b89126896a38"
      },
      "source": [
        "train_loop(modelConfig1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch No:  0\n",
            "Steps Completed:  0\n",
            "Loss: 0.696199357509613 Accuracy: 0.4609375\n",
            "Steps Completed:  50\n",
            "Loss: 0.9726694822311401 Accuracy: 0.484375\n",
            "Steps Completed:  100\n",
            "Loss: 0.7283741235733032 Accuracy: 0.53125\n",
            "Steps Completed:  150\n",
            "Loss: 0.746300995349884 Accuracy: 0.53125\n",
            "-------------\n",
            "\n",
            "Epoch No:  1\n",
            "Steps Completed:  0\n",
            "Loss: 0.8708627223968506 Accuracy: 0.5703125\n",
            "Steps Completed:  50\n",
            "Loss: 0.7043036818504333 Accuracy: 0.5546875\n",
            "Steps Completed:  100\n",
            "Loss: 0.8352829217910767 Accuracy: 0.484375\n",
            "Steps Completed:  150\n",
            "Loss: 0.7988328337669373 Accuracy: 0.5390625\n",
            "-------------\n",
            "\n",
            "Epoch No:  2\n",
            "Steps Completed:  0\n",
            "Loss: 0.6984706521034241 Accuracy: 0.5859375\n",
            "Steps Completed:  50\n",
            "Loss: 0.6942040920257568 Accuracy: 0.59375\n",
            "Steps Completed:  100\n",
            "Loss: 0.6530992388725281 Accuracy: 0.609375\n",
            "Steps Completed:  150\n",
            "Loss: 0.8190151453018188 Accuracy: 0.46875\n",
            "-------------\n",
            "\n",
            "Epoch No:  3\n",
            "Steps Completed:  0\n",
            "Loss: 0.7579739093780518 Accuracy: 0.5234375\n",
            "Steps Completed:  50\n",
            "Loss: 0.7478058934211731 Accuracy: 0.4765625\n",
            "Steps Completed:  100\n",
            "Loss: 0.7769534587860107 Accuracy: 0.4765625\n",
            "Steps Completed:  150\n",
            "Loss: 0.7120305299758911 Accuracy: 0.4921875\n",
            "-------------\n",
            "\n",
            "Epoch No:  4\n",
            "Steps Completed:  0\n",
            "Loss: 0.8354402780532837 Accuracy: 0.4375\n",
            "Steps Completed:  50\n",
            "Loss: 0.7821717262268066 Accuracy: 0.5078125\n",
            "Steps Completed:  100\n",
            "Loss: 0.7646347284317017 Accuracy: 0.5\n",
            "Steps Completed:  150\n",
            "Loss: 0.7192972302436829 Accuracy: 0.484375\n",
            "-------------\n",
            "\n",
            "Epoch No:  5\n",
            "Steps Completed:  0\n",
            "Loss: 0.7207278609275818 Accuracy: 0.53125\n",
            "Steps Completed:  50\n",
            "Loss: 0.7831155061721802 Accuracy: 0.4609375\n",
            "Steps Completed:  100\n",
            "Loss: 0.883648693561554 Accuracy: 0.5078125\n",
            "Steps Completed:  150\n",
            "Loss: 0.7884370684623718 Accuracy: 0.515625\n",
            "-------------\n",
            "\n",
            "Epoch No:  6\n",
            "Steps Completed:  0\n",
            "Loss: 0.7322415113449097 Accuracy: 0.53125\n",
            "Steps Completed:  50\n",
            "Loss: 0.7204431891441345 Accuracy: 0.6015625\n",
            "Steps Completed:  100\n",
            "Loss: 0.7217613458633423 Accuracy: 0.53125\n",
            "Steps Completed:  150\n",
            "Loss: 0.7292568683624268 Accuracy: 0.5\n",
            "-------------\n",
            "\n",
            "Epoch No:  7\n",
            "Steps Completed:  0\n",
            "Loss: 0.7257785797119141 Accuracy: 0.5390625\n",
            "Steps Completed:  50\n",
            "Loss: 0.7618244290351868 Accuracy: 0.5\n",
            "Steps Completed:  100\n",
            "Loss: 0.7485902905464172 Accuracy: 0.421875\n",
            "Steps Completed:  150\n",
            "Loss: 0.7179251909255981 Accuracy: 0.5\n",
            "-------------\n",
            "\n",
            "Epoch No:  8\n",
            "Steps Completed:  0\n",
            "Loss: 0.7179141640663147 Accuracy: 0.453125\n",
            "Steps Completed:  50\n",
            "Loss: 0.8544270992279053 Accuracy: 0.4609375\n",
            "Steps Completed:  100\n",
            "Loss: 0.9200974702835083 Accuracy: 0.5078125\n",
            "Steps Completed:  150\n",
            "Loss: 0.7902131080627441 Accuracy: 0.5078125\n",
            "-------------\n",
            "\n",
            "Epoch No:  9\n",
            "Steps Completed:  0\n",
            "Loss: 0.8069676756858826 Accuracy: 0.5703125\n",
            "Steps Completed:  50\n",
            "Loss: 0.8043767213821411 Accuracy: 0.4609375\n",
            "Steps Completed:  100\n",
            "Loss: 0.7284603118896484 Accuracy: 0.4921875\n",
            "Steps Completed:  150\n",
            "Loss: 0.7533402442932129 Accuracy: 0.5\n",
            "-------------\n",
            "\n",
            "Working on test dataset\n",
            "Steps Completed:  0\n",
            "Steps Completed:  50\n",
            "Steps Completed:  100\n",
            "Steps Completed:  150\n",
            "Final Test Accuracy Average: 0.49655449390411377 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aW6u4DcOG2aZ"
      },
      "source": [
        "# References\n",
        "\n",
        "\n",
        "1.   https://towardsdatascience.com/a-beginners-guide-on-sentiment-analysis-with-rnn-9e100627c02e\n",
        "2.   List item\n",
        "\n"
      ]
    }
  ]
}