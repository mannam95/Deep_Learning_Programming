{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_6_RNN2_IDL_Meghana.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mannam95/Deep_Learning_Programming/blob/main/Assignment6/Assignment_6_RNN2_IDL_Meghana.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCiXbg2NTH8O"
      },
      "source": [
        "#Team Assignment\n",
        "\n",
        "\n",
        "1.   Srinath Mannam (229750)\n",
        "2.   Meghana Rao (234907)\n",
        "3.   Govind Shukla (235192)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOGo_uKlQT6J"
      },
      "source": [
        "#### Import Statements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4P-6H7NMdmc"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4_D07cb5-5K"
      },
      "source": [
        "#### Model Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SS7SD6wBSVzm"
      },
      "source": [
        "class Model:\n",
        "\n",
        "  def __init__(self, **kwargs):\n",
        "     super().__init__(**kwargs)\n",
        "     self.vocab_size = 20000\n",
        "     #self.vocab_size = 40000\n",
        "     (self.train_sequences, self.train_labels), (self.test_sequences, self.test_labels) = tf.keras.datasets.imdb.load_data(num_words= self.vocab_size)\n",
        "\n",
        "     print(self.train_sequences[:4])\n",
        "     print(self.train_labels[:4])\n",
        "\n",
        "     self.word_to_index = tf.keras.datasets.imdb.get_word_index()\n",
        "     self.index_to_word = dict((index, word) for (word, index) in self.word_to_index.items())\n",
        "\n",
        "     self.sequence_lengths = [len(sequence) for sequence in self.train_sequences]\n",
        "     self.max_len = max(self.sequence_lengths)\n",
        "     self.min_len = min(self.sequence_lengths)\n",
        "     print(\"Max sequence length:\", self.max_len)\n",
        "     print(\"Min sequence length:\", self.min_len)\n",
        "     plt.hist(self.sequence_lengths, bins=100)\n",
        "     plt.show()\n",
        "\n",
        "\n",
        "  def gen_train(self):\n",
        "    for sequence, label in zip(self.train_sequences, self.train_labels):\n",
        "        yield sequence, label\n",
        "\n",
        "\n",
        "  def gen_test(self):\n",
        "    for sequence, label in zip(self.test_sequences, self.test_labels):\n",
        "        yield sequence, label\n",
        "\n",
        "  #-----Bucket by sequence length\n",
        "  def set_train_test_data_1(self):\n",
        "    buckets = [50, 100, 150, 200, 250, 300, 350, 400, 450, 500]\n",
        "    #buckets = [100, 200, 300, 400, 500]\n",
        "    bucket_batch_size = [32] * (len(buckets) + 1)\n",
        "    train_data = tf.data.Dataset.from_generator(self.gen_train, output_signature=(tf.TensorSpec(shape=(None,), \n",
        "                                                                                                dtype=tf.int32), tf.TensorSpec(shape=(), dtype=tf.int32)))\n",
        "    train_data = train_data.bucket_by_sequence_length(lambda sequence, label: tf.shape(sequence)[0], bucket_boundaries=buckets, bucket_batch_sizes=bucket_batch_size, drop_remainder= True)\n",
        "    test_data = tf.data.Dataset.from_generator(self.gen_test, output_signature=(tf.TensorSpec(shape=(None,), \n",
        "                                                                                              dtype=tf.int32), tf.TensorSpec(shape=(), dtype=tf.int32)))\n",
        "    test_data = test_data.bucket_by_sequence_length(lambda sequence, label: tf.shape(sequence)[0], bucket_boundaries=buckets, bucket_batch_sizes=bucket_batch_size, drop_remainder= True)\n",
        "     \n",
        "    return train_data, test_data\n",
        "\n",
        "  #----Ragged Tensors\n",
        "  def set_train_test_data_2(self):\n",
        "    r_train_data = tf.ragged.constant(self.train_sequences)\n",
        "    r_test_data = tf.ragged.constant(self.test_sequences)\n",
        "    print(r_train_data.shape)\n",
        "    print(r_train_data.bounding_shape())\n",
        "\n",
        "    train_data=tf.data.Dataset.from_tensor_slices((r_train_data,self.train_labels)).shuffle(25000).batch(32)\n",
        "    test_data=tf.data.Dataset.from_tensor_slices((r_test_data,self.test_labels)).batch(32)\n",
        "\n",
        "    return train_data, test_data\n",
        "\n",
        "  #-----LSTM\n",
        "  def set_model_1(self):\n",
        "    layer_list = [tf.keras.layers.Embedding(self.vocab_size, 32, mask_zero=True),\n",
        "                 tf.keras.layers.LSTM(12, return_sequences=True),\n",
        "                 tf.keras.layers.LSTM(15),\n",
        "                 tf.keras.layers.Dense(1)]\n",
        "\n",
        "    model = tf.keras.Sequential(layer_list)\n",
        "    loss_fn = tf.losses.BinaryCrossentropy(from_logits=True)\n",
        "    optimizer = tf.optimizers.Adam() \n",
        "\n",
        "    epochs = 2\n",
        "\n",
        "    return model, loss_fn, optimizer, epochs\n",
        "\n",
        "  #----GRU\n",
        "  def set_model_2(self):\n",
        "    layer_list = [tf.keras.layers.Embedding(self.vocab_size, 32, mask_zero=True),\n",
        "                 tf.keras.layers.GRU(100),\n",
        "                 tf.keras.layers.Dense(1)]\n",
        "\n",
        "    model = tf.keras.Sequential(layer_list)\n",
        "    loss_fn = tf.losses.BinaryCrossentropy(from_logits=True)\n",
        "    optimizer = tf.optimizers.Adam() \n",
        "\n",
        "    epochs = 2\n",
        "  \n",
        "  #----GRU and LSTM\n",
        "  def set_model_3(self):\n",
        "    layer_list = [tf.keras.layers.Embedding(self.vocab_size, 32, mask_zero=True),\n",
        "                 tf.keras.layers.GRU(512, return_sequences=True),\n",
        "                 tf.keras.layers.LSTM(512),\n",
        "                 tf.keras.layers.Dense(1)]\n",
        "\n",
        "    model = tf.keras.Sequential(layer_list)\n",
        "    loss_fn = tf.losses.BinaryCrossentropy(from_logits=True)\n",
        "    optimizer = tf.optimizers.Adam() \n",
        "\n",
        "    epochs = 5\n",
        "\n",
        "    return model, loss_fn, optimizer, epochs\n",
        "\n",
        "  #----Bidirectional \n",
        "  def set_model_4(self):\n",
        "    layer_list = [tf.keras.layers.Embedding(self.vocab_size, 32, mask_zero=True),\n",
        "                 tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(60, return_sequences=True)),\n",
        "                 tf.keras.layers.LSTM(15),\n",
        "                 tf.keras.layers.Dense(1)]\n",
        "\n",
        "    model = tf.keras.Sequential(layer_list)\n",
        "    loss_fn = tf.losses.BinaryCrossentropy(from_logits=True)\n",
        "    optimizer = tf.optimizers.Adam() \n",
        "\n",
        "    epochs = 3\n",
        "\n",
        "    return model, loss_fn, optimizer, epochs\n",
        "\n",
        "  #----LSTM \n",
        "  def set_model_5(self):\n",
        "    layer_list = [tf.keras.layers.Input(shape=[None], dtype=tf.int32, ragged=True),\n",
        "                  tf.keras.layers.Embedding(self.vocab_size, 32),\n",
        "                  tf.keras.layers.LSTM(32, use_bias=False),\n",
        "                  tf.keras.layers.Dense(32),\n",
        "                  tf.keras.layers.Activation(tf.nn.relu),\n",
        "                  tf.keras.layers.Dense(1)]\n",
        "\n",
        "    model = tf.keras.Sequential(layer_list)\n",
        "    loss_fn = tf.losses.BinaryCrossentropy(from_logits=True)\n",
        "    optimizer = tf.optimizers.Adam() \n",
        "\n",
        "    epochs = 2\n",
        "\n",
        "    return model, loss_fn, optimizer, epochs\n",
        "\n",
        "  #---RNN  \n",
        "  def set_model_6(self):\n",
        "    layer_list = [tf.keras.layers.Embedding(self.vocab_size, 32, mask_zero=True),\n",
        "                 tf.keras.layers.RNN(tf.keras.layers.SimpleRNNCell(12)),\n",
        "                 tf.keras.layers.Dense(2)]\n",
        "\n",
        "    model = tf.keras.Sequential(layer_list)\n",
        "    loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    optimizer = tf.optimizers.Adam() \n",
        "\n",
        "    epochs = 3\n",
        "\n",
        "    return model, loss_fn, optimizer, epochs\n",
        "\n",
        "  #----Bidirectional forward and custom backward layer\n",
        "  def set_model_7(self):\n",
        "\n",
        "    forward_layer = tf.keras.layers.LSTM(10, return_sequences=True)\n",
        "    backward_layer = tf.keras.layers.LSTM(10, return_sequences=True, go_backwards=True)\n",
        "    layer_list = [tf.keras.layers.Embedding(self.vocab_size, 32),\n",
        "                  tf.keras.layers.Bidirectional(forward_layer, backward_layer=backward_layer),\n",
        "                  tf.keras.layers.LSTM(15),\n",
        "                  tf.keras.layers.Dense(1)]\n",
        "\n",
        "    model = tf.keras.Sequential(layer_list)\n",
        "    loss_fn = tf.losses.BinaryCrossentropy(from_logits=True)\n",
        "    optimizer = tf.optimizers.Adam() \n",
        "\n",
        "    epochs = 2\n",
        "\n",
        "    return model, loss_fn, optimizer, epochs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yd_mRQpy3Gis"
      },
      "source": [
        "#### Model Compile, Fit, Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5smnNrUuy4uS"
      },
      "source": [
        "def model_compile_fit_evaluate(train_data, test_data, model, loss_func, optimizer, epochs):\n",
        "  #---model compile------\n",
        "  model.compile(loss = loss_func,\n",
        "                optimizer = optimizer,\n",
        "                metrics = ['accuracy'])\n",
        "  \n",
        "  #---model fit------\n",
        "  train_scores = model.fit(train_data, epochs=epochs)\n",
        "\n",
        "  #---model evaluate----\n",
        "  test_scores = model.evaluate(test_data)\n",
        "  print(\"Test loss:\", test_scores[0])\n",
        "  print(\"Test accuracy:\", test_scores[1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lk8n-U2cg621"
      },
      "source": [
        "#### Train and Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "QPf-1BKVMwp4",
        "outputId": "a401b316-c268-41c1-f6f5-e62a86da019f"
      },
      "source": [
        "model = Model()\n",
        "train_data, test_data = model.set_train_test_data_1()\n",
        "#train_data, test_data= model.set_train_test_data_2()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 19193, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 10311, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 12118, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32])\n",
            " list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 10156, 4, 1153, 9, 194, 775, 7, 8255, 11596, 349, 2637, 148, 605, 15358, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])\n",
            " list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113])\n",
            " list([1, 4, 18609, 16085, 33, 2804, 4, 2040, 432, 111, 153, 103, 4, 1494, 13, 70, 131, 67, 11, 61, 15305, 744, 35, 3715, 761, 61, 5766, 452, 9214, 4, 985, 7, 2, 59, 166, 4, 105, 216, 1239, 41, 1797, 9, 15, 7, 35, 744, 2413, 31, 8, 4, 687, 23, 4, 2, 7339, 6, 3693, 42, 38, 39, 121, 59, 456, 10, 10, 7, 265, 12, 575, 111, 153, 159, 59, 16, 1447, 21, 25, 586, 482, 39, 4, 96, 59, 716, 12, 4, 172, 65, 9, 579, 11, 6004, 4, 1615, 5, 2, 7, 5168, 17, 13, 7064, 12, 19, 6, 464, 31, 314, 11, 2, 6, 719, 605, 11, 8, 202, 27, 310, 4, 3772, 3501, 8, 2722, 58, 10, 10, 537, 2116, 180, 40, 14, 413, 173, 7, 263, 112, 37, 152, 377, 4, 537, 263, 846, 579, 178, 54, 75, 71, 476, 36, 413, 263, 2504, 182, 5, 17, 75, 2306, 922, 36, 279, 131, 2895, 17, 2867, 42, 17, 35, 921, 18435, 192, 5, 1219, 3890, 19, 2, 217, 4122, 1710, 537, 2, 1236, 5, 736, 10, 10, 61, 403, 9, 2, 40, 61, 4494, 5, 27, 4494, 159, 90, 263, 2311, 4319, 309, 8, 178, 5, 82, 4319, 4, 65, 15, 9225, 145, 143, 5122, 12, 7039, 537, 746, 537, 537, 15, 7979, 4, 18665, 594, 7, 5168, 94, 9096, 3987, 15242, 11, 2, 4, 538, 7, 1795, 246, 2, 9, 10161, 11, 635, 14, 9, 51, 408, 12, 94, 318, 1382, 12, 47, 6, 2683, 936, 5, 6307, 10197, 19, 49, 7, 4, 1885, 13699, 1118, 25, 80, 126, 842, 10, 10, 2, 18223, 4726, 27, 4494, 11, 1550, 3633, 159, 27, 341, 29, 2733, 19, 4185, 173, 7, 90, 16376, 8, 30, 11, 4, 1784, 86, 1117, 8, 3261, 46, 11, 2, 21, 29, 9, 2841, 23, 4, 1010, 2, 793, 6, 13699, 1386, 1830, 10, 10, 246, 50, 9, 6, 2750, 1944, 746, 90, 29, 16376, 8, 124, 4, 882, 4, 882, 496, 27, 2, 2213, 537, 121, 127, 1219, 130, 5, 29, 494, 8, 124, 4, 882, 496, 4, 341, 7, 27, 846, 10, 10, 29, 9, 1906, 8, 97, 6, 236, 11120, 1311, 8, 4, 2, 7, 31, 7, 2, 91, 2, 3987, 70, 4, 882, 30, 579, 42, 9, 12, 32, 11, 537, 10, 10, 11, 14, 65, 44, 537, 75, 11876, 1775, 3353, 12716, 1846, 4, 11286, 7, 154, 5, 4, 518, 53, 13243, 11286, 7, 3211, 882, 11, 399, 38, 75, 257, 3807, 19, 18223, 17, 29, 456, 4, 65, 7, 27, 205, 113, 10, 10, 2, 4, 2, 10359, 9, 242, 4, 91, 1202, 11377, 5, 2070, 307, 22, 7, 5168, 126, 93, 40, 18223, 13, 188, 1076, 3222, 19, 4, 13465, 7, 2348, 537, 23, 53, 537, 21, 82, 40, 18223, 13, 2, 14, 280, 13, 219, 4, 2, 431, 758, 859, 4, 953, 1052, 12283, 7, 5991, 5, 94, 40, 25, 238, 60, 2, 4, 15812, 804, 2, 7, 4, 9941, 132, 8, 67, 6, 22, 15, 9, 283, 8, 5168, 14, 31, 9, 242, 955, 48, 25, 279, 2, 23, 12, 1685, 195, 25, 238, 60, 796, 13713, 4, 671, 7, 2804, 5, 4, 559, 154, 888, 7, 726, 50, 26, 49, 7008, 15, 566, 30, 579, 21, 64, 2574])]\n",
            "[1 0 0 1]\n",
            "Max sequence length: 2494\n",
            "Min sequence length: 11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnfyFpJYhPhb"
      },
      "source": [
        "#### **Model 1**\n",
        "\n",
        "*   LSTM (12) + LSTM (12) + Dense (1)\n",
        "*   Loss Func: BinaryCrossentropy\n",
        "*   Optimizer: Adam\n",
        "*   Using from_generator, bucket_by_sequence_length, mask_zero = True\n",
        "*   Vocab_size: 20000\n",
        "*   Epochs: 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EOG5GCQtv_k",
        "outputId": "0d2399eb-5c52-4fa9-9743-09fced3ee730"
      },
      "source": [
        "model1, model1_loss_fn, model1_optimizer, model1_epochs = model.set_model_1()\n",
        "model1.summary()\n",
        "model_compile_fit_evaluate(train_data, test_data, model1, model1_loss_fn, model1_optimizer, model1_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, None, 32)          640000    \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, None, 12)          2160      \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 15)                1680      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 16        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 643,856\n",
            "Trainable params: 643,856\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "775/775 [==============================] - 94s 105ms/step - loss: 0.4050 - accuracy: 0.8024\n",
            "Epoch 2/2\n",
            "775/775 [==============================] - 81s 104ms/step - loss: 0.2085 - accuracy: 0.9212\n",
            "776/776 [==============================] - 39s 46ms/step - loss: 0.3324 - accuracy: 0.8647\n",
            "Test loss: 0.33243218064308167\n",
            "Test accuracy: 0.8646504282951355\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgAcH8th3ucA"
      },
      "source": [
        "#### **Model 2**\n",
        "\n",
        "*   GRU (100) + Dense (1)\n",
        "*   Loss Func: BinaryCrossentropy\n",
        "*   Optimizer: Adam\n",
        "*   Using from_generator, bucket_by_sequence_length, mask_zero = True\n",
        "*   Vocab_size: 20000\n",
        "*   Epochs: 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTqBJDAS3wsY",
        "outputId": "baa2ede5-a961-4a73-f31c-56c9c13bde52"
      },
      "source": [
        "model2, model2_loss_fn, model2_optimizer, model2_epochs = model.set_model_2()\n",
        "model2.summary()\n",
        "model_compile_fit_evaluate(train_data, test_data, model2, model2_loss_fn, model2_optimizer, model2_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_10 (Embedding)    (None, None, 32)          640000    \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 100)               40200     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 680,301\n",
            "Trainable params: 680,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "775/775 [==============================] - 60s 71ms/step - loss: 0.4711 - accuracy: 0.7444\n",
            "Epoch 2/2\n",
            "775/775 [==============================] - 54s 70ms/step - loss: 0.2271 - accuracy: 0.9110\n",
            "776/776 [==============================] - 27s 32ms/step - loss: 0.3224 - accuracy: 0.8453\n",
            "Test loss: 0.3224427103996277\n",
            "Test accuracy: 0.8453205823898315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blddmSTFL8cU"
      },
      "source": [
        "#### **Model 3**\n",
        "\n",
        "*   GRU (512) + LSTM (512) + Dense (1)\n",
        "*   Loss Func: BinaryCrossentropy\n",
        "*   Optimizer: Adam\n",
        "*   Using from_generator, bucket_by_sequence_length, mask_zero = True\n",
        "*   Vocab_size: 20000\n",
        "*   Epochs: 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIyPHOcnL7a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2caf02f-dc42-476e-98fe-c48f13e3f253"
      },
      "source": [
        "model3, model3_loss_fn, model3_optimizer, model3_epochs = model.set_model_3()\n",
        "model3.summary()\n",
        "model_compile_fit_evaluate(train_data, test_data, model3, model3_loss_fn, model3_optimizer, model3_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 32)          640000    \n",
            "                                                                 \n",
            " gru (GRU)                   (None, None, 512)         838656    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 512)               2099200   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,578,369\n",
            "Trainable params: 3,578,369\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "775/775 [==============================] - 203s 245ms/step - loss: 0.6529 - accuracy: 0.5737\n",
            "Epoch 2/5\n",
            "775/775 [==============================] - 189s 244ms/step - loss: 0.3661 - accuracy: 0.8309\n",
            "Epoch 3/5\n",
            "775/775 [==============================] - 189s 244ms/step - loss: 0.1920 - accuracy: 0.9249\n",
            "Epoch 4/5\n",
            "775/775 [==============================] - 188s 243ms/step - loss: 0.1321 - accuracy: 0.9514\n",
            "Epoch 5/5\n",
            "775/775 [==============================] - 189s 244ms/step - loss: 0.0975 - accuracy: 0.9661\n",
            "776/776 [==============================] - 80s 99ms/step - loss: 0.5290 - accuracy: 0.8341\n",
            "Test loss: 0.5289714336395264\n",
            "Test accuracy: 0.8341253399848938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K967L0w9PghD"
      },
      "source": [
        "#### **Model 4**\n",
        "\n",
        "*   Bidirectional LSTM (60) + LSTM (15) + Dense (1)\n",
        "*   Loss Func: BinaryCrossentropy\n",
        "*   Optimizer: Adam\n",
        "*   Using from_generator, bucket_by_sequence_length, mask_zero = True\n",
        "*   Vocab_size: 20000\n",
        "*   Epochs: 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wns24KfNPjvD",
        "outputId": "afd4f3ce-07c4-464b-d116-ec219a3f61aa"
      },
      "source": [
        "model4, model4_loss_fn, model4_optimizer, model4_epochs = model.set_model_4()\n",
        "model4.summary()\n",
        "model_compile_fit_evaluate(train_data, test_data, model4, model4_loss_fn, model4_optimizer, model4_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, None, 32)          640000    \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, None, 120)        44640     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 15)                8160      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 16        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 692,816\n",
            "Trainable params: 692,816\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "775/775 [==============================] - 123s 140ms/step - loss: 0.4328 - accuracy: 0.7885\n",
            "Epoch 2/3\n",
            "775/775 [==============================] - 104s 134ms/step - loss: 0.2663 - accuracy: 0.8912\n",
            "Epoch 3/3\n",
            "775/775 [==============================] - 104s 134ms/step - loss: 0.1802 - accuracy: 0.9325\n",
            "776/776 [==============================] - 61s 72ms/step - loss: 0.3651 - accuracy: 0.8519\n",
            "Test loss: 0.3650728464126587\n",
            "Test accuracy: 0.851884663105011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vK5cCf4gzp8"
      },
      "source": [
        "#### **Model 5**\n",
        "\n",
        "*   LSTM (32) + Dense (32) + Dense (1)\n",
        "*   Loss Func: BinaryCrossentropy\n",
        "*   Optimizer: Adam\n",
        "*   Using Ragged Tensors\n",
        "*   Vocab_size: 20000\n",
        "*   Epochs: 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSNlOerUg3TM",
        "outputId": "ec8de0e9-9df2-4a7d-c3db-f6ca2dbfdf79"
      },
      "source": [
        "model5, model5_loss_fn, model5_optimizer, model5_epochs = model.set_model_5()\n",
        "model5.summary()\n",
        "model_compile_fit_evaluate(train_data, test_data, model5, model5_loss_fn, model5_optimizer, model5_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 32)          640000    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 32)                8192      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                1056      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 649,281\n",
            "Trainable params: 649,281\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential/lstm/RaggedToTensor/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential/lstm/RaggedToTensor/boolean_mask/GatherV2:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential/lstm/RaggedToTensor/Shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 1835s 2s/step - loss: 0.4829 - accuracy: 0.7279\n",
            "Epoch 2/2\n",
            "782/782 [==============================] - 1800s 2s/step - loss: 0.2263 - accuracy: 0.9117\n",
            "782/782 [==============================] - 224s 286ms/step - loss: 0.3292 - accuracy: 0.8625\n",
            "Test loss: 0.32919812202453613\n",
            "Test accuracy: 0.8624799847602844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6GsiFtbmruF"
      },
      "source": [
        "#### **Model 6**\n",
        "\n",
        "*   RNN (12) + Dense (2)\n",
        "*   Loss Func: SparseCategoricalCrossentropy\n",
        "*   Optimizer: Adam\n",
        "*   Using from_generator, bucket_by_sequence_length, mask_zero = True\n",
        "*   Vocab_size: 20000\n",
        "*   Epochs: 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3v_SV4Imto0",
        "outputId": "e1fb1e5b-7c2b-4202-b7c4-d7024d15cbec"
      },
      "source": [
        "model6, model6_loss_fn, model6_optimizer, model6_epochs = model.set_model_6()\n",
        "model6.summary()\n",
        "model_compile_fit_evaluate(train_data, test_data, model6, model6_loss_fn, model6_optimizer, model6_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 32)          640000    \n",
            "                                                                 \n",
            " rnn (RNN)                   (None, 12)                540       \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 26        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 640,566\n",
            "Trainable params: 640,566\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "775/775 [==============================] - 459s 589ms/step - loss: 0.5526 - accuracy: 0.7087\n",
            "Epoch 2/3\n",
            "775/775 [==============================] - 456s 589ms/step - loss: 0.4409 - accuracy: 0.8013\n",
            "Epoch 3/3\n",
            "775/775 [==============================] - 450s 581ms/step - loss: 0.2798 - accuracy: 0.8884\n",
            "776/776 [==============================] - 40s 51ms/step - loss: 0.4921 - accuracy: 0.8018\n",
            "Test loss: 0.49210458993911743\n",
            "Test accuracy: 0.8017880320549011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlRvqZVfSIpb"
      },
      "source": [
        "#### **Model 7**\n",
        "\n",
        "*   Model 1 config\n",
        "*   Increased vocab_size = 40000\n",
        "*   Changed bucket size\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVzBkgFQSPDR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6785bba7-c3d7-40a7-d833-c80fa1a72454"
      },
      "source": [
        "model7, model7_loss_fn, model7_optimizer, model7_epochs = model.set_model_1()\n",
        "model7.summary()\n",
        "model_compile_fit_evaluate(train_data, test_data, model7, model7_loss_fn, model7_optimizer, model7_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_13 (Embedding)    (None, None, 32)          1280000   \n",
            "                                                                 \n",
            " lstm_28 (LSTM)              (None, None, 12)          2160      \n",
            "                                                                 \n",
            " lstm_29 (LSTM)              (None, 15)                1680      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 16        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,283,856\n",
            "Trainable params: 1,283,856\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "779/779 [==============================] - 95s 110ms/step - loss: 0.3962 - accuracy: 0.8048\n",
            "Epoch 2/2\n",
            "779/779 [==============================] - 86s 110ms/step - loss: 0.1864 - accuracy: 0.9316\n",
            "778/778 [==============================] - 42s 50ms/step - loss: 0.3549 - accuracy: 0.8516\n",
            "Test loss: 0.3549347221851349\n",
            "Test accuracy: 0.8515825867652893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tl0CskDxuEnq"
      },
      "source": [
        "#### **Model 8**\n",
        "*   Bidirectional LSTM forward (10) , LSTM backward (15) + LSTM (15) + Dense (1)\n",
        "*   Loss Func: BinaryCrossentropy\n",
        "*   Optimizer: Adam\n",
        "*   Using from_generator, bucket_by_sequence_length, mask_zero = True\n",
        "*   Vocab_size: 20000\n",
        "*   Epochs: 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k28rc6qvuIyK",
        "outputId": "dfa04869-9e4a-4037-f6c4-4b79776df27e"
      },
      "source": [
        "model8, model8_loss_fn, model8_optimizer, model8_epochs = model.set_model_7()\n",
        "model8.summary()\n",
        "model_compile_fit_evaluate(train_data, test_data, model8, model8_loss_fn, model8_optimizer, model8_epochs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_22 (Embedding)    (None, None, 32)          640000    \n",
            "                                                                 \n",
            " bidirectional_21 (Bidirecti  (None, None, 20)         3440      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " lstm_54 (LSTM)              (None, 15)                2160      \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 1)                 16        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 645,616\n",
            "Trainable params: 645,616\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n",
            "775/775 [==============================] - 125s 155ms/step - loss: 0.5935 - accuracy: 0.6660\n",
            "Epoch 2/2\n",
            "775/775 [==============================] - 120s 155ms/step - loss: 0.4078 - accuracy: 0.8359\n",
            "776/776 [==============================] - 58s 73ms/step - loss: 0.4025 - accuracy: 0.8472\n",
            "Test loss: 0.40247583389282227\n",
            "Test accuracy: 0.8471729755401611\n"
          ]
        }
      ]
    }
  ]
}