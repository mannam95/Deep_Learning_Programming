{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_3_IDL_Meghana.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mannam95/Deep_Learning_Programming/blob/main/Assignment3/Assignment_3_IDL_Meghana.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80gHRZjMbnnV"
      },
      "source": [
        "# Team Assignment\n",
        "\n",
        "\n",
        "1.   Srinath Mannam (229750)\n",
        "2.   Meghana Rao (234907)\n",
        "3.   Govind Shukla (235192)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naz8ames-VNI"
      },
      "source": [
        "####Import Statements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "575v4RTX-KZ_"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtJGoi9zZTFD"
      },
      "source": [
        "#### Main function calling all the models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmKibIUf-5ET"
      },
      "source": [
        "def main():\n",
        "\n",
        "  train_steps = 3000\n",
        "\n",
        "  #---------MNIST------------ \n",
        "  dataset_mnist = Dataset_MNIST()\n",
        "  mnist_train_data, mnist_test_data = dataset_mnist.set_train_test_data()\n",
        "\n",
        "  ## model_config_1\n",
        "  mnist_model_1, mnist_model_1_optimizer, mnist_model_1_loss_fn, mnist_model_1_train_acc_metric, mnist_model_1_test_acc_metric = dataset_mnist.set_conv_model_1()\n",
        "  print(\"-------MNIST model_1 Summary----------\")\n",
        "  mnist_model_1.summary()\n",
        "  print(\"---------MNIST Model Train-----------\")\n",
        "  start_conv_model_train(train_steps, mnist_train_data, mnist_model_1, mnist_model_1_loss_fn, mnist_model_1_optimizer, mnist_model_1_train_acc_metric)\n",
        "  print(\"---------MNIST Model Test-----------\")\n",
        "  start_conv_model_test(mnist_test_data, mnist_model_1, mnist_model_1_test_acc_metric)\n",
        "\n",
        "  #--------Fashion MNIST-----------\n",
        "  dataset_fashion_mnist = Dataset_Fashion_MNIST()\n",
        "  fmnist_train_data, fmnist_test_data = dataset_fashion_mnist.set_train_test_data()\n",
        "  \n",
        "  ## model_config_1\n",
        "  fmnist_model_1, fmnist_model_1_optimizer, fmnist_model_1_loss_fn, fmnist_model_1_train_acc_metric, fmnist_model_1_test_acc_metric = dataset_fashion_mnist.set_conv_model_1()\n",
        "  print(\"-------Fashion MNIST model_1 Summary----------\")\n",
        "  fmnist_model_1.summary()\n",
        "  print(\"---------Fashion MNIST Model Train-----------\")\n",
        "  start_conv_model_train(train_steps, fmnist_train_data, fmnist_model_1, fmnist_model_1_loss_fn, fmnist_model_1_optimizer, fmnist_model_1_train_acc_metric)\n",
        "  print(\"---------Fashion MNIST Model Test-----------\")\n",
        "  start_conv_model_test(fmnist_test_data, fmnist_model_1, fmnist_model_1_test_acc_metric)\n",
        "\n",
        "  # --------CIFAR10------------\n",
        "  cifar_10 = Dataset_Cifar10()\n",
        "  cifar_10_train_data, cifar_10_test_data = cifar_10.set_train_test_data()\n",
        "  \n",
        "  ## model_config_1\n",
        "  cifar_10_model_1, cifar_10_model_1_optimizer, cifar_10_model_1_loss_fn, cifar_10_model_1_train_acc_metric, cifar_10_model_1_test_acc_metric = cifar_10.set_conv_model_1()\n",
        "  print(\"-------Cifar10 model_1 Summary----------\")\n",
        "  cifar_10_model_1.summary()\n",
        "  print(\"---------Cifar10 Model1 Train-----------\")\n",
        "  start_conv_model_train(train_steps, cifar_10_train_data, cifar_10_model_1, cifar_10_model_1_loss_fn, cifar_10_model_1_optimizer, cifar_10_model_1_train_acc_metric)\n",
        "  print(\"---------Cifar10 Model1 Test-----------\")\n",
        "  start_conv_model_test(cifar_10_test_data, cifar_10_model_1, cifar_10_model_1_test_acc_metric)\n",
        "\n",
        "  ## model_config_2\n",
        "  cifar_10_train_data_aug, cifar_10_test_data_aug = cifar_10.set_train_test_data_with_data_aug()\n",
        "  cifar_10_model_2, cifar_10_model_2_optimizer, cifar_10_model_2_loss_fn, cifar_10_model_2_train_acc_metric, cifar_10_model_2_test_acc_metric = cifar_10.set_conv_model_2()\n",
        "  print(\"-------Cifar10 model_2 Summary----------\")\n",
        "  cifar_10_model_2.summary()\n",
        "  print(\"---------Cifar10 Model2 Train-----------\")\n",
        "  start_conv_model_train(train_steps, cifar_10_train_data_aug, cifar_10_model_2, cifar_10_model_2_loss_fn, cifar_10_model_2_optimizer, cifar_10_model_2_train_acc_metric)\n",
        "  print(\"---------Cifar10 Model2 Test-----------\")\n",
        "  start_conv_model_test(cifar_10_test_data_aug, cifar_10_model_2, cifar_10_model_2_test_acc_metric)\n",
        "      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGA0WCahZcyS"
      },
      "source": [
        "####MNIST Dataset\n",
        "\n",
        "#####Train Accuracy: 0.9952343702316284\n",
        "#####Test acc: 0.9911999702453613"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIrhfmr3-6y5"
      },
      "source": [
        "class Dataset_MNIST:\n",
        "\n",
        "  def __init__(self, **kwargs):\n",
        "     super().__init__(**kwargs)\n",
        "     self.mnist = tf.keras.datasets.mnist\n",
        "     (self.train_images, self.train_labels), (self.test_images, self.test_labels) = self.mnist.load_data()\n",
        "     self.input_shape = (28, 28, 1)\n",
        "     self.num_classes = 10\n",
        "     print(self.train_labels[0])\n",
        "     plt.imshow(self.train_images[0])\n",
        "  \n",
        "  def set_train_test_data(self):\n",
        "    train_data = tf.data.Dataset.from_tensor_slices((self.train_images.reshape([-1, 28, 28, 1]).astype(np.float32) / 255, self.train_labels.astype(np.int32)))\n",
        "    train_data = train_data.shuffle(buffer_size=60000).batch(128).repeat()\n",
        "    test_data = tf.data.Dataset.from_tensor_slices((self.test_images.reshape([-1, 28, 28, 1]).astype(np.float32) / 255, self.test_labels.astype(np.int32))).batch(128)\n",
        "\n",
        "    return train_data, test_data\n",
        "  \n",
        "  def set_conv_model_1(self):\n",
        "    layer_list = [tf.keras.layers.Conv2D(32,(3, 3), padding='same', activation='relu',input_shape=self.input_shape),\n",
        "                  tf.keras.layers.MaxPool2D(),\n",
        "                  tf.keras.layers.Conv2D(64,(3, 3), padding='same', activation='relu'),\n",
        "                  tf.keras.layers.MaxPool2D(),                 \n",
        "                  tf.keras.layers.Flatten(),\n",
        "                  tf.keras.layers.Dropout(0.3),\n",
        "                  tf.keras.layers.Dense(64, activation=tf.nn.leaky_relu),\n",
        "                  tf.keras.layers.Dense(32, activation=tf.nn.leaky_relu),\n",
        "                  tf.keras.layers.Dense(self.num_classes)]\n",
        "    model = tf.keras.Sequential(layer_list)\n",
        "    optimizer = tf.optimizers.Adam()  # tune this\n",
        "    loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)# from_logits = True!! #neverforget\n",
        "    train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "    test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "    return model, optimizer, loss_fn, train_acc_metric, test_acc_metric\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3gFxNUbZkPC"
      },
      "source": [
        "####Fashion MNIST Dataset\n",
        "\n",
        "#####Train Accuracy: 0.9312499761581421\n",
        "#####Test acc: 0.9126999974250793"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCVNUNIKE0KL"
      },
      "source": [
        "class Dataset_Fashion_MNIST:\n",
        "\n",
        "  def __init__(self, **kwargs):\n",
        "     super().__init__(**kwargs)\n",
        "     self.fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "     (self.train_images, self.train_labels), (self.test_images, self.test_labels) = self.fashion_mnist.load_data()\n",
        "     self.input_shape = (28, 28, 1)\n",
        "     self.num_classes = 10\n",
        "     print(self.train_labels[0])\n",
        "     plt.imshow(self.train_images[0])\n",
        "  \n",
        "  def set_train_test_data(self):\n",
        "    train_data = tf.data.Dataset.from_tensor_slices((self.train_images.reshape([-1, 28, 28, 1]).astype(np.float32) / 255, self.train_labels.astype(np.int32)))\n",
        "    train_data = train_data.shuffle(buffer_size=60000).batch(128).repeat()\n",
        "    test_data = tf.data.Dataset.from_tensor_slices((self.test_images.reshape([-1, 28, 28, 1]).astype(np.float32) / 255, self.test_labels.astype(np.int32))).batch(128)\n",
        "    \n",
        "    return train_data, test_data\n",
        "  \n",
        "  def set_conv_model_1(self):\n",
        "    layer_list = [tf.keras.layers.Conv2D(32,(3, 3), padding='same', activation='relu',input_shape=self.input_shape),\n",
        "                  tf.keras.layers.MaxPool2D(),\n",
        "                  tf.keras.layers.Conv2D(64,(3, 3), padding='same', activation='relu'),\n",
        "                  tf.keras.layers.MaxPool2D(),                 \n",
        "                  tf.keras.layers.Flatten(),\n",
        "                  tf.keras.layers.Dropout(0.3),\n",
        "                  tf.keras.layers.Dense(64, activation=tf.nn.leaky_relu),\n",
        "                  tf.keras.layers.Dense(32, activation=tf.nn.leaky_relu),\n",
        "                  tf.keras.layers.Dense(self.num_classes)]  # default is no activation\n",
        "    model = tf.keras.Sequential(layer_list)\n",
        "    optimizer = tf.optimizers.Adam()  # tune this\n",
        "    loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True) # from_logits = True!! #neverforget\n",
        "    train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "    test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "    return model, optimizer, loss_fn, train_acc_metric, test_acc_metric \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDzWriV7ZtpQ"
      },
      "source": [
        "####Cifar10 Dataset\n",
        "\n",
        "#####Train Accuracy: 0.8618749976158142\n",
        "#####Test acc: 0.7452999949455261"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT6xtUQfE0sj"
      },
      "source": [
        "class Dataset_Cifar10:\n",
        "\n",
        "  def __init__(self, **kwargs):\n",
        "     super().__init__(**kwargs)\n",
        "     self.cifar10 = tf.keras.datasets.cifar10\n",
        "     (self.train_images, self.train_labels), (self.test_images, self.test_labels) = self.cifar10.load_data()\n",
        "     self.input_shape = (32, 32, 3)\n",
        "     self.num_classes = 10\n",
        "     self.datagen = ImageDataGenerator(\n",
        "              rotation_range=15,\n",
        "              horizontal_flip=True,\n",
        "              width_shift_range=0.1,\n",
        "              height_shift_range=0.1)\n",
        "     print(self.train_labels[0])\n",
        "     plt.imshow(self.train_images[0])\n",
        "  \n",
        "  def set_train_test_data(self):\n",
        "    train_data = tf.data.Dataset.from_tensor_slices((self.train_images.reshape([-1, 32, 32, 3]).astype(np.float32) / 255, self.train_labels.astype(np.int32)))\n",
        "    train_data = train_data.shuffle(buffer_size=60000).batch(128).repeat(30)\n",
        "    test_data = tf.data.Dataset.from_tensor_slices((self.test_images.reshape([-1, 32, 32, 3]).astype(np.float32) / 255, self.test_labels.astype(np.int32))).batch(128)\n",
        "    \n",
        "    return train_data, test_data\n",
        "  \n",
        "  def set_conv_model_1(self):\n",
        "    layer_list = [tf.keras.layers.Conv2D(32,(3, 3), padding='same', activation='relu',input_shape=self.input_shape),\n",
        "                  tf.keras.layers.MaxPool2D(),\n",
        "                  tf.keras.layers.Conv2D(64,(3, 3), padding='same', activation='relu'),\n",
        "                  tf.keras.layers.MaxPool2D(),\n",
        "                  tf.keras.layers.Conv2D(128,(3, 3), padding='same', activation='relu'),\n",
        "                  tf.keras.layers.MaxPool2D(),\n",
        "                  tf.keras.layers.Conv2D(256,(3, 3), padding='same', activation='relu'),\n",
        "                  tf.keras.layers.MaxPool2D(),\n",
        "                  tf.keras.layers.Conv2D(512,(3, 3), padding='same', activation='relu'),\n",
        "                  tf.keras.layers.MaxPool2D(),                  \n",
        "                  tf.keras.layers.Flatten(),\n",
        "                  tf.keras.layers.Dropout(0.3),\n",
        "                  tf.keras.layers.Dense(64, activation=tf.nn.leaky_relu),\n",
        "                  tf.keras.layers.Dense(32, activation=tf.nn.leaky_relu),\n",
        "                  tf.keras.layers.Dense(self.num_classes)]   # default is no activation\n",
        "    model = tf.keras.Sequential(layer_list)\n",
        "    optimizer = tf.optimizers.Adam()  # tune this\n",
        "    loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)# from_logits = True!! #neverforget\n",
        "    train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "    test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "    return model, optimizer, loss_fn, train_acc_metric, test_acc_metric\n",
        "\n",
        "  def set_train_test_data_with_data_aug(self):\n",
        "\n",
        "    self. datagen.fit(self.train_images)\n",
        "    train_data = tf.data.Dataset.from_tensor_slices((self.train_images.reshape([-1, 32, 32, 3]).astype(np.float32) / 255, self.train_labels.astype(np.int32)))\n",
        "    train_data = train_data.shuffle(buffer_size=60000).batch(128).repeat(30)\n",
        "    test_data = tf.data.Dataset.from_tensor_slices((self.test_images.reshape([-1, 32, 32, 3]).astype(np.float32) / 255, self.test_labels.astype(np.int32))).batch(128)\n",
        "\n",
        "    return train_data, test_data\n",
        "\n",
        "  def set_conv_model_2(self):\n",
        "    layer_list = [tf.keras.layers.Conv2D(32,(3, 3), padding='same', activation='relu',input_shape=self.input_shape),\n",
        "                  tf.keras.layers.MaxPool2D(),\n",
        "                  tf.keras.layers.Conv2D(64,(3, 3), padding='same', activation='relu'),\n",
        "                  tf.keras.layers.MaxPool2D(),\n",
        "                  tf.keras.layers.Conv2D(128,(3, 3), padding='same', activation='relu'),\n",
        "                  tf.keras.layers.MaxPool2D(),\n",
        "                  tf.keras.layers.Conv2D(256,(3, 3), padding='same', activation='relu'),\n",
        "                  tf.keras.layers.MaxPool2D(),\n",
        "                  tf.keras.layers.Conv2D(512,(3, 3), padding='same', activation='relu'),\n",
        "                  tf.keras.layers.MaxPool2D(),                  \n",
        "                  tf.keras.layers.Flatten(),\n",
        "                  tf.keras.layers.Dropout(0.3),\n",
        "                  tf.keras.layers.Dense(64, activation=tf.nn.leaky_relu),\n",
        "                  tf.keras.layers.Dense(32, activation=tf.nn.leaky_relu),\n",
        "                  tf.keras.layers.Dense(self.num_classes)]   # default is no activation\n",
        "    model = tf.keras.Sequential(layer_list)\n",
        "    optimizer = tf.optimizers.Adam()  # tune this\n",
        "    loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)# from_logits = True!! #neverforget\n",
        "    train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "    test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "    return model, optimizer, loss_fn, train_acc_metric, test_acc_metric\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCQB4dTTZ0FX"
      },
      "source": [
        "####Model Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCquQ_cfJeKs"
      },
      "source": [
        "def start_conv_model_train(train_steps, train_data, model, loss_fn, optimizer, train_acc_metric):\n",
        "  for step, (image_batch, label_batch) in enumerate(train_data):\n",
        "    if step > train_steps:\n",
        "        break\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "      logits = model(image_batch)\n",
        "      loss = loss_fn(label_batch, logits)# loss format is generally: first argument targets, second argument outputs\n",
        "\n",
        "    # if you didn't build the model, it is important that you get the variables\n",
        "    # AFTER the model has been called the first time\n",
        "    variables = model.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "      \n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "    \n",
        "    train_acc_metric(label_batch, logits)\n",
        "    \n",
        "    if not step % 100:\n",
        "        # this is different from before. there, we only evaluated accuracy\n",
        "        # for one batch. Now, we always average over 100 batches\n",
        "        print(\"Loss: {} Accuracy: {}\".format(loss, train_acc_metric.result()))\n",
        "        train_acc_metric.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jqf18eNNZ5kX"
      },
      "source": [
        "####Model Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UI_K6G-eNJMz"
      },
      "source": [
        "def start_conv_model_test(test_data, model, test_acc_metric):\n",
        "  for image_batch, label_batch in test_data:\n",
        "    test_acc_metric(label_batch, model(image_batch))\n",
        "  print(\"Test acc: {}\".format(test_acc_metric.result()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hunn9K4rZ71P"
      },
      "source": [
        "####Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4lnPK6g-d0H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b60f3be4-557e-4aa4-c243-fd272f07fd3f"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "5\n",
            "-------MNIST model_1 Summary----------\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                200768    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 221,994\n",
            "Trainable params: 221,994\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------MNIST Model Train-----------\n",
            "Loss: 2.2968037128448486 Accuracy: 0.109375\n",
            "Loss: 0.18689271807670593 Accuracy: 0.8189062476158142\n",
            "Loss: 0.16446243226528168 Accuracy: 0.9499218463897705\n",
            "Loss: 0.07359246909618378 Accuracy: 0.9674218893051147\n",
            "Loss: 0.045568354427814484 Accuracy: 0.9731249809265137\n",
            "Loss: 0.07871029525995255 Accuracy: 0.9751722812652588\n",
            "Loss: 0.0424860417842865 Accuracy: 0.9813281297683716\n",
            "Loss: 0.01859882101416588 Accuracy: 0.9810156226158142\n",
            "Loss: 0.01898106373846531 Accuracy: 0.9821093678474426\n",
            "Loss: 0.09285887330770493 Accuracy: 0.9834374785423279\n",
            "Loss: 0.03905337303876877 Accuracy: 0.9866071343421936\n",
            "Loss: 0.06911377608776093 Accuracy: 0.9871875047683716\n",
            "Loss: 0.029723424464464188 Accuracy: 0.9859374761581421\n",
            "Loss: 0.0470055416226387 Accuracy: 0.9877343773841858\n",
            "Loss: 0.029459964483976364 Accuracy: 0.9877343773841858\n",
            "Loss: 0.033357784152030945 Accuracy: 0.9920112490653992\n",
            "Loss: 0.021690409630537033 Accuracy: 0.9899218678474426\n",
            "Loss: 0.025668952614068985 Accuracy: 0.9907812476158142\n",
            "Loss: 0.044521182775497437 Accuracy: 0.9892187714576721\n",
            "Loss: 0.04391450434923172 Accuracy: 0.9896616339683533\n",
            "Loss: 0.0025368689093738794 Accuracy: 0.9921875\n",
            "Loss: 0.02113162912428379 Accuracy: 0.9932812452316284\n",
            "Loss: 0.036018356680870056 Accuracy: 0.9914844036102295\n",
            "Loss: 0.018076365813612938 Accuracy: 0.9930468797683716\n",
            "Loss: 0.012949255295097828 Accuracy: 0.9930294752120972\n",
            "Loss: 0.006152455694973469 Accuracy: 0.9932812452316284\n",
            "Loss: 0.01740941032767296 Accuracy: 0.9932031035423279\n",
            "Loss: 0.011245190165936947 Accuracy: 0.9940624833106995\n",
            "Loss: 0.001147682312875986 Accuracy: 0.9921093583106995\n",
            "Loss: 0.008597852662205696 Accuracy: 0.9946742057800293\n",
            "Loss: 0.0027482109144330025 Accuracy: 0.9952343702316284\n",
            "---------MNIST Model Test-----------\n",
            "Test acc: 0.9911999702453613\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n",
            "9\n",
            "-------Fashion MNIST model_1 Summary----------\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_2 (Conv2D)            (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                200768    \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 221,994\n",
            "Trainable params: 221,994\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------Fashion MNIST Model Train-----------\n",
            "Loss: 2.3036110401153564 Accuracy: 0.078125\n",
            "Loss: 0.47834068536758423 Accuracy: 0.6782812476158142\n",
            "Loss: 0.5182011723518372 Accuracy: 0.8267968893051147\n",
            "Loss: 0.39081138372421265 Accuracy: 0.8520312309265137\n",
            "Loss: 0.3825119435787201 Accuracy: 0.8630468845367432\n",
            "Loss: 0.2915429174900055 Accuracy: 0.8689693212509155\n",
            "Loss: 0.3105631470680237 Accuracy: 0.8853906393051147\n",
            "Loss: 0.3006640374660492 Accuracy: 0.8789843916893005\n",
            "Loss: 0.291640967130661 Accuracy: 0.8854687213897705\n",
            "Loss: 0.25522440671920776 Accuracy: 0.8932812213897705\n",
            "Loss: 0.34799009561538696 Accuracy: 0.8951284289360046\n",
            "Loss: 0.24004971981048584 Accuracy: 0.9025781154632568\n",
            "Loss: 0.37889769673347473 Accuracy: 0.9034374952316284\n",
            "Loss: 0.1926509439945221 Accuracy: 0.9028906226158142\n",
            "Loss: 0.1654977798461914 Accuracy: 0.9053906202316284\n",
            "Loss: 0.2372531145811081 Accuracy: 0.9096177816390991\n",
            "Loss: 0.20148879289627075 Accuracy: 0.912890613079071\n",
            "Loss: 0.2556944191455841 Accuracy: 0.9135156273841858\n",
            "Loss: 0.17063137888908386 Accuracy: 0.9124218821525574\n",
            "Loss: 0.22050540149211884 Accuracy: 0.9129855632781982\n",
            "Loss: 0.23057280480861664 Accuracy: 0.9215624928474426\n",
            "Loss: 0.19334381818771362 Accuracy: 0.9205468893051147\n",
            "Loss: 0.1711249202489853 Accuracy: 0.9217968583106995\n",
            "Loss: 0.18236976861953735 Accuracy: 0.9197656512260437\n",
            "Loss: 0.35801658034324646 Accuracy: 0.9231672883033752\n",
            "Loss: 0.19436167180538177 Accuracy: 0.931640625\n",
            "Loss: 0.14128968119621277 Accuracy: 0.9314844012260437\n",
            "Loss: 0.19176170229911804 Accuracy: 0.9242187738418579\n",
            "Loss: 0.10894548892974854 Accuracy: 0.9263281226158142\n",
            "Loss: 0.1915079653263092 Accuracy: 0.934053897857666\n",
            "Loss: 0.22011339664459229 Accuracy: 0.9312499761581421\n",
            "---------Fashion MNIST Model Test-----------\n",
            "Test acc: 0.9126999974250793\n",
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n",
            "170508288/170498071 [==============================] - 11s 0us/step\n",
            "[6]\n",
            "-------Cifar10 model_1 Summary----------\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 2, 2, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 1,603,818\n",
            "Trainable params: 1,603,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------Cifar10 Model1 Train-----------\n",
            "Loss: 2.3049068450927734 Accuracy: 0.140625\n",
            "Loss: 1.7799981832504272 Accuracy: 0.23132812976837158\n",
            "Loss: 1.5226619243621826 Accuracy: 0.36585938930511475\n",
            "Loss: 1.2904828786849976 Accuracy: 0.44843751192092896\n",
            "Loss: 1.4055365324020386 Accuracy: 0.5105081796646118\n",
            "Loss: 1.4063383340835571 Accuracy: 0.5467968583106995\n",
            "Loss: 1.1262286901474 Accuracy: 0.5793750286102295\n",
            "Loss: 1.1256226301193237 Accuracy: 0.6039843559265137\n",
            "Loss: 1.188093900680542 Accuracy: 0.621314287185669\n",
            "Loss: 0.8966374397277832 Accuracy: 0.6580469012260437\n",
            "Loss: 1.0550193786621094 Accuracy: 0.669921875\n",
            "Loss: 0.8513273000717163 Accuracy: 0.677734375\n",
            "Loss: 0.7828694581985474 Accuracy: 0.6889115571975708\n",
            "Loss: 0.7745036482810974 Accuracy: 0.7285937666893005\n",
            "Loss: 0.844897985458374 Accuracy: 0.727734386920929\n",
            "Loss: 0.8318666219711304 Accuracy: 0.7347656488418579\n",
            "Loss: 0.6192569732666016 Accuracy: 0.7507842183113098\n",
            "Loss: 0.7279419898986816 Accuracy: 0.7704687714576721\n",
            "Loss: 0.58758145570755 Accuracy: 0.7678124904632568\n",
            "Loss: 0.8653061389923096 Accuracy: 0.7621093988418579\n",
            "Loss: 0.6437944173812866 Accuracy: 0.7834064960479736\n",
            "Loss: 0.6859453916549683 Accuracy: 0.8121874928474426\n",
            "Loss: 0.5206231474876404 Accuracy: 0.8053905963897705\n",
            "Loss: 0.6243245005607605 Accuracy: 0.7938281297683716\n",
            "Loss: 0.46956735849380493 Accuracy: 0.8245765566825867\n",
            "Loss: 0.4787313938140869 Accuracy: 0.83984375\n",
            "Loss: 0.406078040599823 Accuracy: 0.8310937285423279\n",
            "Loss: 0.48899200558662415 Accuracy: 0.8331249952316284\n",
            "Loss: 0.3124050796031952 Accuracy: 0.8619040250778198\n",
            "Loss: 0.3519305884838104 Accuracy: 0.869921863079071\n",
            "Loss: 0.40932324528694153 Accuracy: 0.8618749976158142\n",
            "---------Cifar10 Model1 Test-----------\n",
            "Test acc: 0.7452999949455261\n",
            "-------Cifar10 model_2 Summary----------\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 4, 4, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 4, 4, 256)         295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 2, 2, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 1,603,818\n",
            "Trainable params: 1,603,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "---------Cifar10 Model2 Train-----------\n",
            "Loss: 2.298442840576172 Accuracy: 0.1015625\n",
            "Loss: 1.8180570602416992 Accuracy: 0.24320311844348907\n",
            "Loss: 1.4816498756408691 Accuracy: 0.40062499046325684\n",
            "Loss: 1.383340835571289 Accuracy: 0.4723437428474426\n",
            "Loss: 1.1891679763793945 Accuracy: 0.5308971405029297\n",
            "Loss: 1.3583096265792847 Accuracy: 0.560546875\n",
            "Loss: 1.0816822052001953 Accuracy: 0.5897656083106995\n",
            "Loss: 1.033298373222351 Accuracy: 0.6124218702316284\n",
            "Loss: 1.2338142395019531 Accuracy: 0.6370765566825867\n",
            "Loss: 1.0731245279312134 Accuracy: 0.6708593964576721\n",
            "Loss: 0.8717416524887085 Accuracy: 0.6735937595367432\n",
            "Loss: 0.7381488084793091 Accuracy: 0.6885937452316284\n",
            "Loss: 0.6310786008834839 Accuracy: 0.6998118162155151\n",
            "Loss: 0.7086846828460693 Accuracy: 0.7278125286102295\n",
            "Loss: 0.838576078414917 Accuracy: 0.7329687476158142\n",
            "Loss: 0.7695227265357971 Accuracy: 0.7426562309265137\n",
            "Loss: 0.756898045539856 Accuracy: 0.751254677772522\n",
            "Loss: 0.7420243620872498 Accuracy: 0.7708593606948853\n",
            "Loss: 0.7405991554260254 Accuracy: 0.7788281440734863\n",
            "Loss: 0.6735498905181885 Accuracy: 0.7742968797683716\n",
            "Loss: 0.6242842078208923 Accuracy: 0.8033249974250793\n",
            "Loss: 0.5626347064971924 Accuracy: 0.8174999952316284\n",
            "Loss: 0.6125478744506836 Accuracy: 0.8036718964576721\n",
            "Loss: 0.5032950639724731 Accuracy: 0.8049218654632568\n",
            "Loss: 0.34932154417037964 Accuracy: 0.8339083790779114\n",
            "Loss: 0.48400166630744934 Accuracy: 0.8575780987739563\n",
            "Loss: 0.4688378870487213 Accuracy: 0.8400781154632568\n",
            "Loss: 0.5088400840759277 Accuracy: 0.8304687738418579\n",
            "Loss: 0.29775434732437134 Accuracy: 0.8715495467185974\n",
            "Loss: 0.35642462968826294 Accuracy: 0.8690624833106995\n",
            "Loss: 0.3637019395828247 Accuracy: 0.8755468726158142\n",
            "---------Cifar10 Model2 Test-----------\n",
            "Test acc: 0.7402999997138977\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}