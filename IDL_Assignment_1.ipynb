{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IDL Assignment 1.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOHhDDip/K82qiVqpgsnjxa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mannam95/Deep_Learning_Programming/blob/main/IDL_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDUczixLbcZz"
      },
      "source": [
        "###Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gk1xGJOOgpTS"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDo-6-0rv81f"
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "print('Training images shape: {}'.format(train_images.shape))\n",
        "print('Test images shape: {}'.format(test_images.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKCNCa7Kyui5"
      },
      "source": [
        "for i in range(10):\n",
        "  plt.subplot(4, 5, i + 1)\n",
        "  plt.imshow(train_images[i], cmap='gray_r')\n",
        "  plt.title('Labels : {}'.format(train_labels[i]))\n",
        "  plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k3bpYQdwq5w"
      },
      "source": [
        "class MNISTDataset:\n",
        "    \"\"\"'Bare minimum' class to wrap MNIST numpy arrays into a dataset.\"\"\"\n",
        "    def __init__(self, train_imgs, train_lbs, test_imgs, test_lbls, batch_size,\n",
        "                 to01=True, shuffle=True, seed=None):\n",
        "        \"\"\"\n",
        "        Use seed optionally to always get the same shuffling (-> reproducible\n",
        "        results).\n",
        "        \"\"\"\n",
        "        self.batch_size = batch_size\n",
        "        self.train_data = train_imgs\n",
        "        self.train_labels = train_lbs.astype(np.int32)\n",
        "        self.test_data = test_imgs\n",
        "        self.test_labels = test_lbls.astype(np.int32)\n",
        "\n",
        "        if to01:\n",
        "            # int in [0, 255] -> float in [0, 1]\n",
        "            self.train_data = self.train_data.astype(np.float32) / 255\n",
        "            self.test_data = self.test_data.astype(np.float32) / 255\n",
        "\n",
        "        self.size = self.train_data.shape[0]\n",
        "\n",
        "        if seed:\n",
        "            np.random.seed(seed)\n",
        "        if shuffle:\n",
        "            self.shuffle_train()\n",
        "        self.shuffle = shuffle\n",
        "        self.current_pos = 0\n",
        "\n",
        "    def next_batch(self):\n",
        "        \"\"\"Either gets the next batch, or optionally shuffles and starts a\n",
        "        new epoch.\"\"\"\n",
        "        end_pos = self.current_pos + self.batch_size\n",
        "        if end_pos < self.size:\n",
        "            batch = (self.train_data[self.current_pos:end_pos],\n",
        "                     self.train_labels[self.current_pos:end_pos])\n",
        "            self.current_pos += self.batch_size\n",
        "        else:\n",
        "            # we return what's left (-> possibly smaller batch!) and prepare\n",
        "            # the start of a new epoch\n",
        "            batch = (self.train_data[self.current_pos:self.size],\n",
        "                     self.train_labels[self.current_pos:self.size])\n",
        "            if self.shuffle:\n",
        "                self.shuffle_train()\n",
        "            self.current_pos = 0\n",
        "            print(\"Starting new epoch...\")\n",
        "        return batch\n",
        "\n",
        "    def shuffle_train(self):\n",
        "        shuffled_inds = np.arange(self.train_data.shape[0])\n",
        "        np.random.shuffle(shuffled_inds)\n",
        "        self.train_data = self.train_data[shuffled_inds]\n",
        "        self.train_labels = self.train_labels[shuffled_inds]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hx7qzxAwITBb"
      },
      "source": [
        "data = MNISTDataset(train_images.reshape([-1, 784]), train_labels, \n",
        "                    test_images.reshape([-1, 784]), test_labels,\n",
        "                    batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bkHNwEfixnHW"
      },
      "source": [
        "###784(Input)-512(Hidden layer)-10(Output)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OmfZXbPIbYs"
      },
      "source": [
        "train_steps = 1000\n",
        "learning_rate = 0.1\n",
        "\n",
        "#Input layer\n",
        "W_0 = tf.Variable(np.random.normal(0, 0.1, size=(784,512)).astype(np.float32))\n",
        "b_0 = tf.Variable(np.random.normal(0, 0.1, size=512).astype(np.float32))\n",
        "\n",
        "#Hidden layer\n",
        "W_1 = tf.Variable(np.random.normal(0, 0.1, size=(512,10)).astype(np.float32))\n",
        "b_1 = tf.Variable(np.random.normal(0, 0.1, size=10).astype(np.float32))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahGAc-c_IhzL"
      },
      "source": [
        "for step in range(train_steps):\n",
        "    img_batch, lbl_batch = data.next_batch()\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "        h_0 = tf.nn.relu(tf.matmul(img_batch, W_0) + b_0)\n",
        "        h_1 = tf.nn.relu(tf.matmul(h_0, W_1) + b_1)\n",
        "        xent = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "            logits=h_1, labels=lbl_batch))\n",
        "\n",
        "    grads = tape.gradient(xent, [W_0,b_0,W_1, b_1])\n",
        "    W_0.assign_sub(learning_rate * grads[0])\n",
        "    b_0.assign_sub(learning_rate * grads[1])\n",
        "    W_1.assign_sub(learning_rate * grads[2])\n",
        "    b_1.assign_sub(learning_rate * grads[3])\n",
        "    \n",
        "    if not step % 100:\n",
        "        preds = tf.argmax(h_1, axis=1, output_type=tf.int32)\n",
        "        acc = tf.reduce_mean(tf.cast(tf.equal(preds, lbl_batch),\n",
        "                             tf.float32))\n",
        "        print(\"Loss: {} Accuracy: {}\".format(xent, acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHqyrtlKJ2k2"
      },
      "source": [
        "test_preds = tf.argmax(tf.matmul(data.test_data, W_0) + b_0, axis=1,\n",
        "                       output_type=tf.int32)\n",
        "acc = tf.reduce_mean(tf.cast(tf.equal(test_preds, data.test_labels),\n",
        "                             tf.float32))\n",
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqsgI89RJ8dO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}